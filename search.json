[{"title":"知识图谱和图数据库","url":"/2019/10/23/知识图谱和图数据库/","content":"\n参考博客：\n\n[知新温故，从知识图谱到图数据库](https://blog.csdn.net/wireless_com/article/details/86486289)\n\n[知识图谱-浅谈RDF、OWL、SPARQL](https://www.jianshu.com/p/9e2bfa9a5a06)\n\n### 知识图谱\n\n#### 需求与定义\n深度学习、机器学习等人工智能技术，要在行业中得到应用，首先要对行业已有的知识有足够的认知。知识图谱可以用来描述真实世界中存在的各种实体和概念，以及他们之间的强关系。构建和完善知识图谱是事物分析学习的基础。\n\n知识图谱可以理解成是由很多知识点和它们之间的关系连接构成的语义网络。也可以简单的将一个知识图谱理解成一个*多关系图*，即图中包含多种类型的节点和多种类型的边。在知识图谱里，通常用*实体*来表达图里的节点，即现实世界中的事物，用*关系*来表达图里的边，即不同事物之间的某种联系，实体和关系也通常拥有各自的属性。\n\n#### 设计与构建\n设计某行业的知识图谱需要对业务本身有足够的理解，从业务逻辑出发，并考虑业务未来可能的变化。要把知识图谱设计成轻量级的存储载体，决定哪些数据需要放在知识图谱中。\n\n构建知识图谱，首先要进行*数据抽取*，即把数据从不同的数据源中提取出来，进行统一的管理，这其中需要用到自然语言处理（Natural Language Processing，NLP）中的一些技术，包括实体命名识别、关系抽取、实体统一、指代消解等。\n\n#### 存储方式\n知识图谱主要有两种存储方式：RDF和图数据库。\n\n##### RDF\n\nRDF，即资源描述框架（Resource Description Framework），是W3C提倡的一个数据模型，用来描述万维网上的资源及其相互间的关系。RDF数据模型的核心包括资源（resource）、属性（property）、RDF陈述（RDF statement）。\n\n*资源*，表示一个具体的事物或抽象的概念。每个资源拥有一个统一资源标识符（URI）来标识。\n\n*属性*，表示资源之间的联系，每个属性也使用唯一的URI来标识。\n\n*RDF陈述*，描述某个资源特定属性及其属性值，表示为（主语——谓语——宾语）的三元组结构。\n\n*RDF图*，由很多RDF三元组组成的一个集合可以构成一个RDF图。RDF图也可以看成是节点和边均带有标签的有向图结构。\n\n##### 图数据库\n\n图数据库是非关系型数据库（Not Only Structured Query Language, NoSQL）的一种，重点描述数据之间关系的数据库。\n\nRDF与图数据库的区别在于，RDF一个重要的设计原则是数据的易发布以及共享，图数据库则把重点放在了高效的图查询和搜索上。其次，RDF以三元组的方式来存储数据而且不包含属性信息，但图数据库一般以属性图为基本的表示形式，所以实体和关系可以包含属性，这就意味着更容易表达现实的业务场景。RDF常应用于学术场景，而图数据库常用于工业场景。\n\n### 图数据库\n\n#### 关系型数据库\n传统的关系型数据库更注重刻画实体内部的属性，实体与实体之间的关系通常都是利用外键来实现，将所有的数据用竖立的堆栈表示，并且保持它们直接的关系，在求解关系的时候通常需要join操作，而join操作通常又是耗时的。常常被优化用于聚合数据，而非高度关联的数据。对于高度关联的数据存储与分析就需要求助于NoSQL了。\n\n#### 非关系型数据库\n非关系型数据库（Not Only Structured Query Language, NoSQL）可以分为4类：key-value，文档型，列存储和图数据库。\n\nKey-Value模型适合用于简单的数据或者列表。当数据之间不断交互关联时，实际上更需要一张图。\n\n文档型NoSQL用来管理文档。在传统的数据库中，信息被分割成离散的数据段，而在文档数据库中，文档是处理信息的基本单位。文档可以很长，可以很复杂，可以是无结构的，与字处理文档类似。一个文档相当于关系数据库中的一条记录。文档型NoSQL用文档进行层次划分，而自由的数据规划也很容易被表示成一颗树。成长为一张图的话，文档之间的关联需要更有代表性的数据结构来存储。\n\n列存储。\n\n从应用开发的角度看，这些NoSQL数据库不处理关系，没有数据结构建模或存储数据关系，没有查询结构支持些数据关系。而且，在应用中连接数据同样需要JOIN，操作 对事务没有 ACID 的支持。因此，这三种 NoSQL 数据库也不适用于有实时价值的数据关系。\n\n#### 图数据库\n图数据库是基于数学里图论的思想和算法而实现的高效处理复杂关系网络的数据库。图形数据库善于高效处理大量的、复杂的、互连的、多变的数据，计算效率远远高于传统的关系型数据库。\n\n图中每个节点代表一个对象，节点之间的连线代表对象之间的关系。节点可带标签，节点和关系都可以带若干属性。关系可以将节点组织成任意的结构，允许一张图被组织成一个列表，一棵树，一张地图，或者一个复杂的实体。这个实体本身也是由复杂的，关系高度关联的结构组成。\n\n#### 现有的图数据库\n\nNeo4j\n\ntitan\n\narangoDB\n\nOrientDB\n\nGUN","tags":["graph database"]},{"title":"CNARW 基于公共邻居感知的快速随机游走","url":"/2019/10/18/CNARW-基于公共邻居感知的快速随机游走/","content":"\n[Yongkun Li, Zhiyong Wu, Shuai Lin, Hong Xie, Min Lv, Yinlong Xu, John C.S. Lui. \"Walking with Perception: Efficient Random Walk Sampling via Common Neighbor Awareness\". 35th IEEE International Conference on Data Engineering (ICDE), Macau, SAR, China, April 2019.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8731555)\n\n### 图中心性分析\n\n#### 应用场景\n\n近年来，对社交网络分析能更准确的进行一些商业活动，比如病毒式营销和产品推荐等。通过分析图上的各种图中心性可以获取社交网络中用户的属性，进而用来促进商品营销。可以通过下面具体的两个例子来直观的说明。\n\n（1）**网络平台投资**，根据病毒式营销中的“口碑效应（word-of-mouth）”，一个用户购买商品时可能会受到其朋友的影响而去买同一件商品。所以利用在线社交网络（OSN）可以很好的进行商品营销。不同的OSN会呈现不同的潜力，比如不同的OSN中用户的活跃性和影响力会有所不同。所以一个商家来说，**选择哪个网络平台进行投资能吸引到最多的用户购买商品？**这个问题可以通过*估算OSN中所有*用户对*之间的平均相似性*来衡量。\n\n（2）**病毒式营销中的捆绑策略**，将多个商品在一起打折捆绑销售也是一种常见的营销策略。但是**具体选择哪些商品放在一起捆绑销售能带来最大的销售额**。这个问题可以通过*估算每个商品在用户之间的兴趣分布，捆绑有相似分布的商品*来解决。\n\n#### 计算挑战\n\n想要准确的计算图上的这些中心性不是件简单的事情，主要有如下挑战。\n\n（1）OSN的图规模通常很大，例如Facebook的用户数已经超过20亿。\n\n（2）为了保护用户的隐私，很多OSN只允许第三方代理通过固定的速度受限的API接口访问网络数据。\n\n为了分析这些大规模图数据，**图采样**是个常用的技术，通过分析采样的一些有代表性的样本，而避免遍历整个网络数据，这样大大减少了对网络的访问开销。\n\n### 随机游走采样\n\n随机游走采样是这类应用场景的一个主流采样算法，因为它扩展性强且实施简单。\n\n#### 简单随机游走\n\n考虑一个无向连通图$G(V,E)$，$N(v)$表示图中节点v的邻居集合，$deg(v)=|N(v)|$表示节点v的度。\n\n图上简单随机游走过程是：首先从图中随机选取一个节点，然后重复从当前节点中随机挑选一个它的邻居节点进行跳转。\n\n这个过程可以看成是一个有限的马尔科夫链，每一步访问的节点id就马尔科夫链的状态。每一步的状态转移概率可以表示成一个$|V|\\times |V|$的概率转移矩阵$P$，$P_{uv}$为从节点u通过一步random walk走到节点v的概率。简单随机游走（Simple Random Walk, SRW）的状态转移矩阵可以表示为$P_{uv}=1/deg(u), \\quad if \\quad v \\in N(u)$，否则$P_{uv}=0$。\n<!-- $P_{uv}= \\begin{cases} 1/deg(u) & \\text{if v \\in N(u)}\\\\0 & \\text{otherwise} \\end{cases}$ -->\n\n很多步以后达到收敛状态，即随机游走访问图中每个节点的概率呈现稳态分布。SRW收敛后的稳态分布可以表示成：$\\pi (u)=deg(u)/(2|E|)$。\n\n#### 随机游走采样\n\n随机游走的采样是在随机游走收敛以后开始采样收集样本。根据收集到的样本和收敛后的稳态分布，我们就可以对感兴趣的一些图测量指标进行无偏估计。\n\n##### 收集样本\n\n收集样本节点时，一般有两种方法：（1）*连续采样*，在图中只开启一条random walk，收敛以后持续采集样本直到收集到足够的样本节点。（2）*独立采样*，在图中同时开启多条random walk，每条walk收敛以后只采集一个样本节点。这两种方法都需要在random walk收敛以后才能开始收集样本，然后根据稳态分布进行无偏估计。\n\n##### 无偏估计\n\n假定图上的一个测量指标可以表示成一个函数$f:V \\to R$，在一个达到稳态分布$\\pi$的随机游走上收集到的足够的样本上应用函数$f$，即可得到一个估计值$E_\\pi[f] \\stackrel{\\mathrm{\\Delta}}{=} \\sum_{u \\in V}{f(u)\\pi(u)}$。该估计值的准确性可由**强大数定律（the Strong Law of Large Numbers, SLLN）**保证。\n\n#### 加速随机游走收敛\n\n从开始到达稳态分布的持续时间称为“the burn-in period”，在真实的OSN中，这个阶段通常需要一个很大的计算开销，因为通常需要很多步以后才能达到收敛。在给定一个采样预算（总共访问的节点数）的情况下，除去收敛开销，我们只能采样少量的有代表性的样本，因此分析的准确性就会收到影响。所以随机游走采样一个重要的问题就是：**如何加速随机游走在大规模图上的收敛？**\n\n现在有两类加速随机游走收敛的方法：\n\n（1）增加图的导通性（conductance），这类方法通常需要全局的图信息，所以在现实场景中通常不可行。\n\n（2）修改每一步walk的转移概率，这类方法通常是利用walk的历史信息，并且只需要访问少量的局部图信息。\n\n### CNARW\n\n这篇论文跟随第二类加速随机游走收敛的方法，提出公共邻居感知的随机游走（Common Neighbor Aware Random Walk）CNARW，通过利用walk前一步访问过的节点信息来优化下一步跳转的邻居选择。具体的，CNARW考虑当前节点和下一跳候选节点的公共邻居数量来进行下一跳的邻居选择。\n\n#### 主旨思想\n\n考虑简单随机游走收敛慢的主要原因：一般的社交网络都有很高的*聚类*特性，即图中形成很多的社区结构，社区内部的节点连接紧密，社区之间连接稀疏。所以简单随机游走的过程中，walker均匀随机地选取当前节点的一个邻居跳转，大概率会选到社区内部的节点，而且很容易陷入当前子图，只在社区内部反复游走在已经访问过的节点，只有很小的概率能走出当前的子图，从而探索到全局的图信息。这大大减慢了简单随机游走的收敛速度。\n\n所以为了加速随机游走的收敛，我们需要尽量减少对已经访问过的节点的频繁的再次访问。该论文提出，在每一步随机游走选择的时候，不同于简单随机游走的均匀随机选择，我们给访问过的节点小一点的访问概率，而给有更大机会能探索更多未访问的节点的那些节点大一点的访问概率。该论文根据下一跳候选节点的信息以及一些历史访问信息，重新设置每一步随机游走的转移概率，具体考虑如下两个方面。\n\n（1）若一个候选节点的*度*，即邻居节点数，越大，则它可能访问到更多未访问的节点的概率也就越大。\n\n（2）若一个候选节点与当前节点的公共邻居数越少，则随机游走通过该候选节点再次回到当前节点的概率也就越小。\n\n所以，在各个候选节点中，我们应该给度数高且与当前节点公共邻居数少的节点更大的转移概率。通过这种加权游走的策略，CNARW可以更快的收敛。\n\n\n#### 算法设计\n\n下面介绍通过一些公式化的表示和理论支持而形成的CNARW的具体算法设计。\n\n**（1）首先引入集合导通性（set conductance）**\n\n**定义：集合导通性（set conductance）**，用$G=(V,E)$表示一个无向图，$C \\in V$是图中的一个节点集，集合$C$的导通性$\\phi (C)$定义为\n$$\\phi (C)=\\phi (C,V-C)=|E_{C,V-C}| / Vol(C),$$\n其中$E_{C,V-C}={(u,v) | u \\in C, v \\in V-C}$，$Vol(C)=\\sum_{u \\in C}{deg(u)} $。\n\n集合导通性可以看成是节点集合$C$和它的差集之间的边数除以$C$内部的边数。一个节点集与图中其他节点的连接数越多，节点集内部的连接数越少，则该节点集的导通性越大，随机游走被困在该节点集中可能性也就越小。\n\n**（2）接下来公式化下一跳的节点选择**\n\n假设随机游走当前停留在节点$u$，定义$S={u} \\cup N(u)$为包含当前节点和它的邻居节点的*边界节点集（frontier nodes）*。则我们可以用$\\phi(S)$来表示随机游走可能被困在$S$的概率程度。而其中一个候选节点$v$对$\\phi(S)$的贡献度可以表示为$\\Delta \\phi_v = \\phi(S)-\\phi(S_{-v})$，其中$\\phi(S_{-v})=S \\setminus {v}$。\n\n$$\\Delta \\phi_v = \\frac{ (1-\\phi(S))-2(C_{uv}+1)/deg(v) }{ (\\sum_{i \\in S}{deg(i)})/deg(v)-1 },$$\n\n其中$deg(v)$表示节点$v$的度，$C_{uv}$表示节点$u$和节点$v$的公共邻居数。在$deg(v)$不变的情况下，$C_{uv}$越大，则$\\Delta \\phi_v$越小。而在固定$C_{uv}$不变的情况下，$deg(v)$越大，则$\\Delta \\phi_v$也越大。\n\n对于每个候选节点$v \\in N(u)$，$\\Delta \\phi_v$可以作为下一跳节点选择合适程度的测量指标。$\\Delta \\phi_v$越大，即度数高且与当前节点公共邻居数少的节点，CNARW给与节点$v$在下一跳邻居选择中更高的权重。\n\n**（3）转移矩阵的设计**\n\n直觉来说，可以将节点$u$到节点$v$的转移概率$P_{uv}$设置为一个正比于$\\Delta \\phi_v$的值，比如为了避免$\\Delta \\phi_v$的复杂计算，我们可以简单的设置为$P_{uv}=1-\\frac{C_{uv}}{deg(v)}$。\n\n但是为了保证随机游走的*可逆性（reversible）*，从而能够简单地获得它的稳态分布。因此，我们设计转移概率时需要保证*对称性（symmetric）*，即$P_{uv}=P_{vu}$，具体CNARW设置为\n\n$$P_{uv} \\varpropto 1-\\frac{C_{uv}}{min(deg(u),deg(v))}.$$\n\n我们也可以考虑其他的形式，比如上式中的分母也可以替换成$deg(u)+deg(v)$或者$max(deg(u),deg(v))$，也能保证对称性。但是使用$min(deg(u),deg(v))$可以避免当$deg(u)$很大时，$P_{uv}$之间差别很小的情况。\n\n**（4）随机游走过程**\n\n为了实现满足上述转移概率的随机游走，且减少计算开销，CNARW采用了一种*带拒绝的随机游走策略*。具体的，在每一步随机游走时：\n\n1）我们首先从当前节点$u$的邻居节点$N(u)$中随机均匀的选取一个候选节点$v$；\n\n2）然后计算节点$v$的接收概率，表示为$q_{uv}=1-\\frac{C_{uv}}{min(deg(u),deg(v))}$；\n\n3）我们以$q_{uv}$的概率接收然后将随机游走跳转到节点$v$，以$1-q_{uv}$拒绝，并重新回到1）选取一个候选节点；\n\n4）重复上述过程直至随机游走成功转发；\n\n这种*带拒绝的随机游走策略*的好处是我们只需要访问被接收的节点$v$及其之前访问过的节点信息，而不需要访问节点$u$的所有邻居，从而减少了查询开销。\n\n**（5）转移概率归一化**\n\n上述的随机游走过程中，会有一定的概率$P_{uu}= 1 - \\frac{1}{deg(u)}\\sum_{v \\in N(u)}{(1-\\frac{C_{uv}}{min(deg(u),deg(v))})}$跳回到当前节点。为了避免这种情况，我们对转移概率进行归一化矫正，$P_{uv}={p'_{uv}/(1-p'_{uv})}$。\n\n#### 稳态分布\n\n**定理（唯一存在性）**：给定无向连通图G(V,E)，在G上运行CNARW存在唯一的一个稳态分布。（不可约）\n\n**定理（节点的稳态分布）**：CNARW的稳态分布$\\pi$满足：$\\frac{\\pi(u)}{\\pi(v)}=\\frac{deg(u)(1-p'_{uu})}{deg(v)(1-p'_{vv})}$，所以我们可以得出$\\pi(u)=Z \\times deg(u) \\times (1-p'_{uu})$，其中Z是一个归一化的常数。\n\n**定理（边的稳态分布）**：CNARW收敛后，$\\pi(e_{uv})=\\pi(u) \\times P_{uv}$。\n\n#### 扩展利用更多历史节点信息\n\n上述介绍的CNARW算法是只利用了当前节点（一步历史）的信息，直观来看，考虑更多的历史信息可以进一步加速随机游走的收敛。所以该论文中也考虑了扩展到考虑多个历史访问节点的的信息，来设计随机游走的转移概率。\n\n我们用H来表示考虑的之前访问的节点个数，$H=0$和$H=1$分别对应SRW和CNARW的场景。$H \\geq 2$时，重新定义*边界节点集（frontier set）*$S = N(x_H) \\cup N(x_{H-1}) \\cup \\dots \\cup N(x_2) \\cup N(u)$。此时，候选节点$v$的对$\\phi(S)$的贡献度$\\Delta \\phi_v^H$为：\n\n$$\\Delta \\phi_v^H = \\frac{((1-\\phi(S))-2(C_{Sv}+1)/deg(v) )}{(\\sum_{i \\in S}{deg(i)})/deg(v)-1}.$$\n\n该论文在实验中测试了H对收敛速度的影响，结果表明$H=1$时的性能提升就已经足够和有力。更大的H带来的进一步的性能提升并不显著。\n\n### 基于CNARW的无偏采样\n\n基于CNARW，这篇论文提出了一种采样算法，并且提供了高效的无偏估计方法并且提供理论证明来保证无偏估计的准确度。\n\n#### 无偏点采样\n\n#### 无偏边采样\n\n\n### 实验 \n\n（1）实验环境和数据集。\n\n服务器：2 Intel Xeon E5-2650 2.60GHz CPUs & 64GB RAM。\n\n数据集：（a）4个大规模数据集：Google Plus, Flickr, DBLP and LiveJournal；（b）3个小规模数据集： Facebook, CaGaQc, and Phy1（用于计算第二大特征值）。\n\n对比算法：SRW, NBRW, CNRW。\n\n（2）性能指标定义。\n\n（3）收敛速度，包括实验统计的收敛需要的步数以及理论计算的第二大特征值。\n\n（4）估算误差和查询开销。\n\n（5）H的影响。\n\n（6）转移矩阵的设计。\n\n（7）具体应用场景。\n\n* 网络平台投资\n\n* 病毒式营销中的捆绑策略\n\n实验结果表明，（1）CNARW最多能将当前的随机游走算法SRW，NBRW，CNRW的收敛所需的步数减少71.9%。（2）在实现相同的准确度的情况下，CNARW最多能减少35.7%的查询开销。\n\n<!-- ### 扩展工作\n\n（1）理论证明CNARW的收敛速度快，即第二大特征值小。\n\n（2）扩展到有向图。\n\n（3）考虑其他转移概率设计（为什么需要对称性）。\n\n### review意见\n\n（1）将所有符号列成一张表。\n\n（2）为什么要采用带拒绝的采样策略？\n\n（3）转移概率设计为什么需要对称？\n\n（4）* 理论证明收敛速度。\n\n（5）相对误差定义。\n\n（6）使用真实数据集，大数据集，比如Epinion。\n\n（7）提出的算法似乎不能在有向图上运行。\n\n（8）有些描述不清晰，比如X_{t}是什么？\n\n（9）更多的讨论MHRW。 -->","tags":["random walks","theoretical analysis"]},{"title":"Deeper Inside PageRank","url":"/2019/10/17/Deeper-Inside-PageRank/","content":"\n[Deeper Inside PageRank, \tLangville A;Meyer C, Internet Mathematics 2004](https://www.internetmathematicsjournal.com/article/1388)\n\n这是一个关于PageRank的综述性的调研报告，包含与PageRank相关所有问题，涵盖了*基础的PageRank模型*，*计算方法*，*稳态分布的存在性和唯一性分析*，*收敛速度*，*存储问题*，*基础模型上的改动*，*传统计算方法的改进*等等。\n\n### PageRank的由来\n\n当前的搜索引擎一般通过一个两步的过程来检索与用户查询相关的页面，1）信息检索（Information Retrieval），检索找出所有相关的页面（通常能找出几千个相关的页面 ）；2）**页面排序**（Page Rank），对检索出的页面按照某种准则进行排序，按照顺序展示给用户。PageRank是一个大家熟知的页面排序算法，它基于网页之间的超链接结构，计算出一个页面的重要程度，用于Google搜索引擎。（实际上在Google会综合考虑IR（Information Retrieval） score和PR（PageRank） score决定最终的网页排序，这里我们只关注于PageRank。）\n\nPage, Lawrence和Brin, Sergey于1998年发表了论文，[Page, Lawrence & Brin, Sergey & Motwani, Rajeev & Winograd, Terry. (WWW1998). The PageRank Citation Ranking: Bringing Order to the Web.](http://web.mit.edu/6.033/2004/wwwdocs/papers/page98pagerank.pdf)，第一次提出PageRank算法，并基于此创办了Google公司。\n\n### 基础的PageRank模型\n\n#### 基本概念\n**马尔可夫链（Markov chain）**，考虑状态空间中，从一个状态到另一个状态的转换的随机过程。某一时刻状态转移的概率只依赖于它的前一个状态。这种特定类型的“无记忆性”称作*马尔可夫性质*。满足*马尔可夫性质*的随机过程称为[*马尔可夫链*](https://blog.csdn.net/bitcarmanlee/article/details/82819860)。\n\n**随机性（stochastic）**，矩阵的随机性表示矩阵中的所有元素都是非负的，且每一行的元素和为1。\n\n**不可约性（irreducible）**，不可约的数学定义是“如果从C 中任一状态出发经有限步转移到另一状态的概率都大于0，则称C为不可约闭集”，即任意一种状态都可能转化到任意另外一种状态，即不存在多余的状态（可减少的状态）。\n\n**素矩阵（primitive matrix）**，素矩阵是指自身的某个次幂为正矩阵的矩阵。设$$A$$为一个$$n \\times n$$的方阵，如果存在正整数k使得矩阵$$A^k>0$$那么，称矩阵A为素矩阵。\n\n#### 状态转移矩阵\n\n考虑网页之间的链接关系，可以看成一个有向图，图中节点表示页面，边代表页面之间的超链接关系。一个用户随机浏览网页的过程可以看做是一个在图上节点之间跳转的*随机游走*过程，也是一个马尔可夫链。\n\n考虑各节点之间的转移概率，可以表示成一个矩阵$$P$$，其中$$P_{ij}$$表示通过一步从页面$$i$$跳转到页面$$j$$的概率。例如，假设从一个页面有相等的概率跳转到它所链接的任意页面，则$$P_{ik}=1/d_i, \\forall k \\in N(i)$$（其中$$d_i$$为节点i的出度，$$N(i)$$为节点i的出边邻居集）。也根据自定义的加权方式设置概率分布$$v^T$$，公式表示为$$P'=P+av^T$$，其中$$a$$为一个构造的向量，其中如果i为悬挂节点，则$$a_i=1$$，否则$$a_i=0$$。\n\n由于图中存在*悬挂节点（dangling node）*，即该节点没有出边邻居，此时$$P_i=0^T$$，使得该转移矩阵不满足*随机性*，当随机游走跳转到悬挂节点时，就会停止。为了修正这种情况，我们修改$$P'_i=1/ne^T$$（其中n为图中的总节点数），或者一个自定义的个性化的的随机向量$$P'_i=v^T$$（personalized vector）。\n\n为了保证该马尔可夫链能够收敛得到一个概率分布的稳态向量（stationary vector），也就是最终算得的PageRank值，该马尔可夫链需要满足*不可约性*。所以需要对该状态转移矩阵做进一步的修改，$$P''= \\alpha P'+(1-\\alpha)ev^T/n, 0 \\leq \\alpha \\leq 1$$。\n\n这样通过修正的状态转移矩阵有:\n\n$P''= \\alpha P'+(1-\\alpha)ev^T/n$，\n\n$ \\quad = \\alpha (P+av^T)+(1-\\alpha)ev^T/n$，\n\n$ \\quad = \\alpha P+(\\alpha a+(1-\\alpha)e)v^T$, 其中$0 \\leq \\alpha \\leq 1$，\n\n图中的每个节点都可以通过一步直接到达另一个节点，使得该马尔可夫链满足不可约的性质。该矩阵是一个素矩阵，即通过幂法(power method)迭代计算可以得到一个收敛的稳态向量$$\\pi^T$$。\n\n### 计算PageRank\n\n上述状态转移矩阵代表的马尔可夫链，最终能达到一个稳定状态，即存在一个稳态分布$$\\pi^T$$，使得$$\\pi^TP''=\\pi^T$$，其中$$\\pi^T$$是一个概率向量，$$\\pi^Te=1$$。通过计算该稳态向量$$\\pi^T$$，即得到各个页面的PageRank值，其中$$\\pi^T_i$$即为页面i的PageRank值。\n\n#### 幂法迭代计算\n\n幂法迭代计算是一个传统的计算特征向量问题的方法。\n\n* 设置一个任意的初始向量$$x^{(0)T}$$，通常$$x^{(0)T}=e^T/n$$。\n* 迭代计算：$$x^{(k)T}=x^{(k-1)T}P''$$，即$x^{(k)T}=\\alpha x^{(k-1)T}P+(\\alpha x^{(k-1)T}a+(1-\\alpha))v^T$。\n\n这样，通过一轮又一轮的*向量矩阵相乘*，迭代计算直至达到终止条件，则可计算出稳态向量$$\\pi^T$$。每一轮计算中，需要的$nnz(P)$次浮点运算，$nnz(P)$为P中非零元素的个数。一般P为一个稀疏矩阵，P中每一行的非零元素的个数即为图中每个节点的度数，一般平均为3-10，所以$\\omicron(nnz(P)) \\approx \\omicron(n)$。Brin和Page在论文中指出，一般幂法迭代运算很快就可以达到收敛，通常只需要50-100次迭代运算。\n\n#### 收敛性\n状态转移矩阵$$P''$$的不可约性（irrducibility）保证了该马尔可夫链的唯一一个稳态分布向量的存在性。\n\n而$$P''$$的素性（primitivity）保证了通过幂法迭代计算能够收敛，算出该稳态分布向量。\n\n#### 收敛速度\n\n[矩阵的谱用于分解一个矩阵](https://blog.csdn.net/qq997843911/article/details/88189426)，对于上述的稳态分布$$\\pi^TP''=\\pi^T$$，$$\\pi^T$$就是$$P''$$的一个特征向量，对应的特征值就是1。对$$P''$$所有的特征向量$$v_i^T$$，有$$v_i^TP''=v_i^T c_i$$，其中$$c_i$$为对应的特征值，对$$v_i^T$$的每一轮更新，所有节点的值变为原来的$$c_i$$倍，当$$0 < c_i < 1$$，所有节点值呈指数衰减，直至趋近于0。\n\n我们可以用谱的方法，将上述马尔可夫链的任意初始状态$$x^{(0)T}$$分解成\n\n$x^{(0)T}=v_1^T+c_2 v_2^T+c_3 v_3^T+\\cdots$\n\n对于状态转移矩阵$$P''$$，其最大特征值为1，对应于特征向量$$v_1^T$$，即稳态向量$$\\pi^T$$。其他特征向量$$v_2^T, v_3^T, \\cdots$$对应于特征值$1>c_2>c_3>\\cdots >-1$。则经过t步迭代计算，到达状态$$x^{(t)T}$$\n\n$x^{(t)T}=v_1^T+c_2^t v_2^T+c_3^t v_3^T+\\cdots$\n\n其中$$v_i^T$$部分的分量保持不变，即为我们所求的稳态向量，其他分量随着t增长而指数衰减，最后整个状态$$x^{(t)T}$$收敛趋近于平衡状态。而这个过程的**收敛速度（rate of convergence）**取决于上述非平衡分量中衰减得最慢的那一个，即**第二大特征值$$c_2$$**。$$c_2$$的大小越接近1，收敛越慢，越接近于0，收敛越快。\n\n而$P''$的第二大特征值取决于$\\alpha$。$\\alpha$设置的越小，收敛速度越快，但是网页之间的链接结构对最终计算结果的贡献程度也越小。考虑权衡，Google创始人Brin和Page使用$\\alpha=0.85$。\n\n#### 收敛判断\n\n幂法迭代计算直至满足一个终止条件，一个传统的终止条件是：当k轮计算后的**残差（residual）**$$x^{(k)T}P''-x^{(k)T}=x^{(k+1)T}-x^{(k)T}$$，小于一个预先定义的**容忍度（tolerance ）**$\\tau$时，迭代终止。此时，可以大致估算收敛所需要迭代计算的轮数为$\\frac{log_{10}\\tau}{log_{10}\\alpha}$。当$\\tau=10^{-6}, \\alpha=0.85$时，大致需要 $\\frac{-6}{log_{10}0.85} \\approx 85$ 次迭代计算。上面说到Brin和Page指出，通常只需要50-100次迭代运算，是指$\\tau$取值为$10^{-3}$ 到 $10^{-6}$。\n\n在实际应用中，我们通常只需要计算出页面之间的正确顺序，并不需要知道他们具体的PageRank值。所以我们只需要通过幂法迭代到PageRank向量的排序收敛就可停止。某篇论文在实验展示，在某些数据集上只需10次迭代就能产生良好的近似排序。\n\n#### 加速幂法计算\n\n（1）减少每一轮的计算时间\n\n* 自适应的PageRank，考虑到图中某些节点收敛快，而有些节点收敛慢。所以我们关注于迭代向量中元素，当某些节点已经收敛后，我们就锁定这些节点，不再对他们进行更新计算。\n\n* 图中存在大量悬挂节点，可以划分悬挂节点和非悬挂节点。因为所有悬挂节点对应的行的转移概率是一样的，可以通过一种汇集的聚合方法高效的处理。\n\n（2）减少迭代的次数\n\n* 扩展的Aitken外推法；\n\n* BlockRank；\n\n* 取消对幂法的限制，高斯-赛德尔法，雅可比法。","tags":["random walks","theoretical analysis"]},{"title":"并发图分析系统","url":"/2019/10/16/并发图分析系统/","content":"\n并发图分析任务：大量的图算法并发的运行在同一平台上对底层同一个图数据进行处理，以对该图数据进行多方位的分析处理，获得各种目的性的分析结果。\n\n### 研究工作\n\n[Yu Zhang's Research](https://www.researchgate.net/scientific-contributions/57497079_Yu_Zhang)\n\n#### CGraph\n基于关联性感知的并发图处理\n\n1. [CGraph: A Correlations-aware Approach for Efficient Concurrent Iterative Graph Processing(ATC'18)](https://www.usenix.org/conference/atc18/presentation/zhang-yu)\n2. [CGraph: A Distributed Storage and Processing System for Concurrent Iterative Graph Analysis Jobs(TOS'19)](https://dl.acm.org/citation.cfm?doid=3326597.3319406)\n\n并发图分析任务之间存在关联性。\n\n（1）空间关联性：多个并发图分析任务需要访问和处理的图数据存在大量的交集。\n\n（2）时间关联性:多个并发图分析任务可能需要同时访问同一个图划分块。\n\n但在此前的图处理系统中进行并发图分析任务时，各个任务对共享图数据的访问相互独立，互不感知。使得各个并发的图分析任务在计算时遇到内存墙（内存性能严重限制CPU）和缓存相互干扰的问题。\n\n这篇工作通过感知各个并发图分析任务之间的关联性，使得各个并发图分析任务之间能有效的共享数据和数据访问。\n\n#### DiGraph\n基于关联依赖的单任务图处理\n\n* [DiGraph: An Efficient Path-based Iterative Directed Graph Processing System on Multiple GPUs(ASPLOS'19)](https://dl.acm.org/citation.cfm?doid=3297858.3304029)\n\n* [Efficient Disk-Based Directed Graph Processing: A Strongly Connected Component Approach(TPDS 2018)](https://ieeexplore.ieee.org/document/8118091)\n\n同一个图分析任务的子任务（处理各图划分块的任务）之间也存在依赖关联性。\n核心图顶点状态收敛所需要的更新次数决定了整个图收敛所需迭代次数。\n\n这篇工作在单个图分析任务场景下，通过感知图中顶点之间的依赖关联性特征进行图划分，使得各个图划分块之前的依赖关联性尽量符合全序关系，尝试使得未收敛的图划分块对已经收敛的图划分块影响最小化。另外通过加速核心顶点之间的状态传递，进一步加速全局的收敛速度。\n\n#### FBSGraph\n基于路径的异步图处理\n\n* [FBSGraph: Accelerating Asynchronous Graph Processing via Forward and Backward Sweeping(TKDE'18)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8170287)","tags":["graph processing system","concurrent graph processing","paper reading"]},{"title":"ASAP(OSDI 2018) 分布式图模式挖掘系统","url":"/2019/10/15/ASAP(OSDI-2018)-分布式图模式挖掘系统/","content":"\nASAP: Fast, Approximate Graph Pattern Mining at Scale. Anand Padmanabha Iyer, Zaoxing, Xin Jin, Shivaram Venkataraman, Vladimir Braverman and Ion Stoica, OSDI 2018. [presentation](https://www.usenix.org/conference/osdi18/presentation/iyer) [paper](https://www.cs.jhu.edu/~xinjin/files/OSDI18_ASAP.pdf)\n<!-- [PPT](https://www.usenix.org/sites/default/files/conference/protected-files/osdi18_slides_iyer.pdf) -->\n\n## 图模式挖掘研究现状\n\n### 图处理算法：\n现有图处理算法可大致分为两类：\n（1）*图分析算法*，e.g. PageRank，社区检测，标签传播。\n（2）*图模式挖掘算法*，e.g. 图形计数（motif counting），频繁子图挖掘（frequent sub-graph mining, FSM），团挖掘（clique mining）。图模式挖掘算法常应用于社交网络中的图元（graphlet）相似性检测，信用卡诈骗侦测等。\n\n现有的图处理系统大多针对图分析算法优化计算，这些系统框架在计算*图分析算法*时，速度很快，并且可以扩展到处理非常大的图数据（e.g. GraM [59] can run one iteration of page rank on a trillionedge graph in 140 seconds in a cluster.）。但是这些系统在计算*图模式挖掘算法*时却很慢，在一个中等大小的图上挖掘简单的模式都需要几个小时。\n\n### 现有图模式挖掘算法\n\n#### 精确计算\n模式挖掘算法中最常用的方法是，从最简单的图模式开始，迭代遍历图中所有可能的*嵌入组合（embeddings）*，检查所有候选的*组合嵌入*，依次修剪掉不能形成最终图模式的*组合嵌入*。\n这个*图模式挖掘算法*的复杂度很大，而且产生的*中间候选集*的大小随着图的规模呈指数增长（1M个节点的图可能就会包含$$10^{17}$$个三角形）。即使在分布式计算中，也需要很大开销来执行**join**来创建和管理这些*中间候选集*。[Arabesque(SOSP 2015)](http://delivery.acm.org/10.1145/2820000/2815410/p425-teixeira.pdf?ip=222.195.68.252&id=2815410&acc=OPENTOC&key=BF85BBA5741FDC6E%2EA4F9C023AC60E700%2E4D4702B0C3E38B35%2E9F04A3A78F7D3B8D&__acm__=1571129497_d7c2b24f90623254ad2b1c0e79d31eb2)针对这个问题，优化了分布式场景下这些*中间候选集*的存储。但是即使经过这些优化，Arabesque依然没有能力处理大规模的图，因为需要*具体化候选集*和*不断在机器间交互候选集数据*。Arabesque在一个由20个256GB内存的机器组成的分布式集群中，统计一个1B个节点的图中的*3节点图模式*，依然需要10个小时。\n\n#### 采样近似计算\n在很多模式挖掘应用中，经常并不需要精确的答案。比如FSM通常只需要输出频繁访问子图出现次数的顺序，图形计数（motif counting）也只需要输出一个指定图形出现的次数。在这些场景下，给出一个近似的答案就已足够。\n\n大数据分析场景下的近似分析已经引起一些关注，这些近似系统的基本思想是：在一小部分抽象的样本数据上执行精确的算法，并根据统计特性进行误差分析。这些系统的一个基础假设是：可以算法的准确性可以由样本的大小决定，并且计算的误差可以推导。\n\n但是，这种假设应用到*图模式挖掘算法*时并不成立。作者通过实验发现，通过减少样本的大小，计算误差和运行效率之间并没有明显的关系，而且即使样本数量设置很大，依然会有很大的计算误差，例如50%的边抽样就会带来大概80%计算误差（详细参见paper中的Figure 1）。\n\n#### 邻居采样\n\n现有的图计算理论中，已经有一些针对特定图模式的近似技术。比如要统计图中三角形的个数，可以从图中随机抽样三条边，看这三条边是否能构成一个三角形，是的话估计值就是$$m^3$$，其中m是图的总边数，否则估计值就是0，通过大量抽样就可以计算平均估计值。这种采样计数理论上确实能达到无偏估计，但是由于m在实际中是很大的，所以随机抽样三条边能构成三角形的概率很小，所以这种采样技术计算的方差非常大，想要达到比较高的近似计算的准确度，需要非常多的抽样估计，从而带来很大的计算和内存开销。\n\n[邻居采样（Neighborhood sampling, VLDB 2013）](http://www.doc88.com/p-3734516936384.html)是最近提出的一种针对*三角形计数（triangle counting）*的近似计算方案。它的基本思想是（边数据以流的形式输入）：\n\n（1）首先从全图随机采样一条边$$l_0$$，采样概率是$$Pr(l_0)=1/m$$；\n\n（2）均匀的从$$l_0$$的邻居边中采样第二条边$$l_1$$，边数据流中，$$l_1$$在$$l_0$$的后面，采样概率是$$Pr(l_1|l_0)=1/c$$，c为边数据流中出现在$$l_0$$后面的$$l_0$$的边邻居数；\n\n（3）在边数据流的$$l_1$$的后面所有边中，找到一条能与$$l_0$$和$$l_1$$构成一个三角形的边$$l_2$$，如果能找到，则这个三角形被采样到的概率是$$Pr(l_0 \\cap l_1 \\cap l_2)=1/mc$$。\n\n上述过程称为一次采样尝试，如果成功采样到一个三角形，则设这次采样计算的图中三角形的个数的估计值为$$e_i=mc$$，否则为0。多次采样，计算平均值（paper中的Figure 2展示了一个五节点完全图的例子）。\n\n#### 依然存在的挑战\n\n1.邻居采样算法只针对一种特定的图模式（三角形），需要扩展到通用的邻居采样方法，使之也能采样其他模式。\n\n2.邻居采样算法是假定图存放在单机的基础上，想要进行大规模的图模式挖掘，需要扩展到分布式图处理。\n\n3.邻居采样算法没有考虑到*属性图*，而现实生活的图模式挖掘通常是针对*属性图*，即节点和边都有类型和属性，因为通常需要*谓词匹配*。\n\n4.需要允许终端用户进行*准确性*和*延迟*之间的权衡。\n\n\n## ASAP中的近似模式挖掘\n\nASAP(A Swift Approximate Pattern-miner)是一个快速、可扩展的分布式近似图模式挖掘系统（paper中的Figure 3展示了ASAP的系统架构）。\n\n### 扩展到通用模式\nASAP推广邻居采样算法到通用的图模式，由两个阶段组成：\n\n（1）采样阶段，在有序的边流中依次采样几条边，分别统计采样概率。\n\n（2）闭合阶段，等待剩下的一条或多条边来构成一个完整的图模式，如果能成功构成，则计算采样到完整图模型的概率，进而计算估计值，否则估计值为0.\n\n对于大于三节点的图模式，有多种采样构成完整图模式的方式，采样概率取决于开发者选择的采样阶段形成的初始模式（paper中的Figure 4展示了采样4-cliques的两种方式）。\n\n#### 通用模式分析\n设$$p*$$为一个$$k$$-节点的图模式，$$p*$$的抽样概率取决于$$k$$和用邻居采样技术采样图模式的不同方式。\n\n* 当$$k=2$$, $$Pr(p=p*,k=2)=1/m$$。\n\n* 当$$k=3$$, $$Pr(p=p*,k=3)=1/m \\cdot c_1$$。\n\n* 当$$k=4$$, $$Pr(p=p*,k=4)=1/m^2$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=4)=1/m \\cdot c_1 \\cdot c_2$$(type 2)。\n\n* 当$$k=5$$, $$Pr(p=p*,k=5)=1/m^2 \\cdot c_1$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m^2 \\cdot c_2$$(type 2)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m \\cdot c_1 \\cdot c_2 \\cdot c_3$$(type 3)\n\n#### 编程接口\n\n* SampleVertex\n\n* SampleEdge\n\n* ConditionalSampleVertex\n\n* ConditionalSampleEdge(subgraph)\n\n* ConditionalClose(subgraph, subgraph)\n\n### 应用到分布式场景\n\nASAP通过2步，将上述图模式挖掘过程扩展到分布式场景：\n\n（1）**并行化采样过程**，由于采样过程中的边数据流没有排序的要求，所以ASAP随机均匀划分节点，使得各个机器上的节点数和边数都尽量均匀。计算时，在多个机器上执行估算任务的多个副本，然后聚合计算结果。\n\n（2）**结合各个机器上的输出结果，修正误差**，由于在分布式集群上计算时，机器之间的边没有办法采样到，所以会导致计算误差。ASAP通过分析误差损失，加权求和纠正误差：$$c=f(w)\\sum^{w-1}_{i=0}{c_i}$$，其中$$w$$为机器个数，$$f(w)$$为纠正权重。以*三角形计数*为例，在全图采样到的所有三角形的三个节点都在同一个机器上的概率是$$1/w^2$$，所以统计三角形个数时，$$f(w)=w^2$$。类似的，统计4-clique时，$$f(w)=w^3$$。\n\n### 属性图中的模式挖掘\n\n#### Predicate Matching\n\n现实生活的图模式挖掘通常是针对*属性图*，因为需要匹配的模式满足一些*谓词*。例如，一个*谓词查询*任务可能会要求统计图中的4-clique，其中clique中每个节点都属于某种特定的类型。ASAP支持两种谓词类型：\n\n（1）**all** ，匹配的模式中*每个*节点和边都满足某个属性。\n（2）**atleast-one**，匹配的模式中*至少有一个*节点和边都满足某个属性。\n\n#### Motif mining\n另一种查询模式是，查找某个特定节点数量的所有模式，称为* motif queries*。\n\n* 3-motif query有2种模式，链式和三角形。\n\n* 4-motif query有6种模式。\n\n其中，有几个模式会有相同的*基础构建块（underlying building block）*。针对这种情况，ASAP节省采样阶段*基础构建块*的构建。\n\n#### 精炼准确度\n有些对图数据的探索性分析场景，需要迭代地完善查询任务。针对这种场景，ASAP保留上一轮的抽样估计结果，在新一轮只需要补充差额。\n\n### 误差延迟配置\n\nASAP提供了两种用户接口，允许用户在准确性和误差之间做权衡，进行误差延迟配置（Error-Latency Profile, ELP）。\n\n* Building Estimator vs. Time Profile。用户指定一个时间预算$$T$$，ASAP返回一个时间$$T$$以内能计算出的最准确的答案，给出误差率保证$$\\epsilon$$和可配置的自信等级（默认95%）。\n\n* Building Estimator vs. Error Profile。用户指定一个误差预算$$\\epsilon$$，ASAP计算出能在最短时间内达到误差范围的答案。\n\n* ASAP也可以实现在动态图场景下快速重建ELP。\n\n\n## 实验\n\n### 实验设置\n\n#### 实现\nASAP部署在Apache Spark上，使用了GraphX中图数据流操作的实现（只使用了简单的map和reduce操作）。ASAP可以实现于任何数据流引擎。\n\n#### 数据集和对比系统\n\n* 数据集：共使用了7个数据集，最大的为UK（106M个节点，3.7B个边）。\n\n* 实验环境：16个Amazon EC2 r4.2xlarge的集群，每个机器有8个虚拟cpu和61GB内存。尽管图能放下一个机器的内存，但是产生的中间状态大大增大了计算的复杂度。\n\n* 使用的模式和指标：3-motifs（2种模式），4-motifs（6种模式），4-cliques。\n\n* 对比系统：Arabesque。\n\n### 对比实验\n\n（1）Overall Performance\n\n* Comparison with Arabesque.\n\n* Scalability on Larger Graphs.\n\n（2）Advanced Pattern Mining\n\n* Motif mining.\n\n* Predicate Matching. \n\n（3）Effectiveness of ELP Techniques\n\n* Time Profile. \n\n* Error Profile. \n\n* Error rate Confidence. \n\n* ELP Building Time. \n\n（4）Scaling ASAP on a Cluster\n\n（5）More Complex Patterns\n\n## 相关工作\n图处理系统\n\n图挖掘系统\n\n近似分析系统\n\n近似图算法\n\n<!-- ## 思考\n思考：分布式图处理系统对网络方面有什么需求?\n\n* 缓存，现有的分布式图计算系统大多数采用*迭代式的计算模型*，一轮计算结束后，机器之间交互信息，然后进行下一轮计算。这一轮传输的信息中可能与上一轮中传输的数据有重合，所以可以考虑缓存？ -->","tags":["graph processing system","paper reading","graph pattern mining"]},{"title":"IMM(SAN) 引入社会活动的影响力最大化问题","url":"/2019/10/10/IMM(SAN)-引入社会活动的影响力最大化问题/","content":"\n[Pengpeng Zhao, Yongkun Li*, Hong Xie, Zhiyong Wu, Yinlong Xu, John C. S. Lui. \"Measuring and Maximizing Influence via Random Walk in Social Activity Networks.\"The 22nd International Conference on Database Systems for Advanced Applications (DASFAA 2017), Suzhou, China, March 2017.](https://link.springer.com/content/pdf/10.1007%2F978-3-319-55699-4_20.pdf).\n\n<!-- ## IMM(SAN) Journal扩展 -- TKDE -->\n\n### 论文大纲\n\n1.**用户活动网络图（SAN），**考虑在线社交网络图（OSN）中用户社交活动的影响，比如对同一个产品的点赞、评论等，基于此提出用户活动网络图（SAN），并提出一种“超图”的概念来表示SAN， 其中一条t型的“超边”连接多个用户，代表这几个用户都参与某种t型活动，比如都对某产品点赞或评高分。\n\n2.**基于RW的影响力中心性，**考虑SAN场景下的影响力最大化问题（IMP(SAN)），采用基于Random Walk的方式来近似估算SAN中大小为k的种子节点集S的影响力，定义为影响力中心性（influence centrality），估算在超图中从每个节点出发进行大量random walks，其中能到达种子节点集S的击中概率（decayed hitting probability）。\n\n3.**贪心算法计算IMP(SAN)，**为计算SAN中的影响力最大化问题（IMP(SAN)），本文采用Monte Carlo框架来估算SAN中的影响力中心性，并提出一种贪心的迭代算法，每一轮选出一个能够带来最大影响力增量的节点，加入到种子节点集S中，具体实现：每一轮，计算每个节点u能够带来的影响力增量，在超图中每个节点出发进行R条L步的random walks，计算这些walks能够访问到$$S\\cup{u}$$的hitting probability。时间复杂度为$$\\omicron(kn^2RL)$$。\n\n4.**算法优化1——并行计算，**每一轮，计算图中每个节点的影响力增量都需要从全图每个节点出发R条L步的random walks，其实这些walk可以共用，即一次性从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，这样可以将时间复杂度优化到$$\\omicron(knRL)$$。\n\n5.**算法优化2——walk复用，**每一轮都需要从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，其实第一轮轮的walk信息可以一直被复用到下一轮中，这样可以将时间复杂度优化到$$\\omicron(nRL)$$，这其中会带来walk更新的问题，详细参加paper 5.2。\n\n6.**实验对比，**本文在三个真实世界的数据集上对比了加入用户活动后带来的在独立级联模型（independent cascade model，IC）的影响力传播模型下影响力的增长，以及对比最新的OSN上的影响力最大化问题的最新算法IMM在不同用户活动权重和不同种子节点集大小的配置下效率的改进和能带来的影响力传播。\n\n\n<!-- ### Journal扩展点\n\n1.**从无权图扩展到加权图，** (1)加权图的应用场景，（2）在加权图上的RW需求，（3）加权图上进行一步RW转发的执行过程，（4）时间复杂度分析，（5）利用二分查找优化加权图上的RW过程以及优化后的时间复杂度。实验章节添加从无权图生成加权图的过程。\n\n2.**增加LT模型下的影响力传播,** 6.4 添加对LT模型的介绍以及在LT模型下的实验。\n\n3.**增加一组多种用户和活动类型的实验,**（1）一种用户一种活动，（2）两种用户一种活动，（3）一种用户两种活动。6.4 添加上述三种场景下的实验结果。 -->\n","tags":["random walks","theoretical analysis"]},{"title":"Hexo的配置和使用","url":"/2019/10/10/Hexo的配置和使用/","content":"\n博客搭建，GitHub Page和Hexo的使用\n\nhttps://www.cnblogs.com/ryanleee/p/8274314.html\n\nHexo 和 Markdown 的基本使用规则\n\nhttps://www.jianshu.com/p/56d99a3049a5\n\n在HEXO主题中添加数学公式支持\n\nhttps://www.cnblogs.com/zhyantao/p/10424874.html\n\nMarkDown公式查阅\n\nhttps://blog.csdn.net/EchoWenyu/article/details/95046618\n\nGitment：使用 GitHub Issues 搭建评论系统\n\nhttps://imsun.net/posts/gitment-introduction/\n\n解决gitment无法登录的问题\n\nhttps://cloud.tencent.com/developer/news/316368","tags":["hexo"]},{"title":"Hexo部署错误","url":"/2019/10/09/Hexo部署错误/","content":"\n## Hexo部署错误\n\n生成和本地测试都能通过\n\n``` bash\n$ hexo g\n$ hexo s\n```\n\n但是部署时出错\n\n``` bash\n$ hexo d\n```\n\n错误提示如下：\n\n>...\n>\n>Connection reset by 13.250.177.223 port 22\n>\n>fatal: Could not read from remote repository. &emsp;\n>\n>Please make sure you have the correct access rights and the repository exists.\n>\n>FATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\n>\n>Error: Spawn failed\n>\n>...\n\n搜索相关信息发现应该是GitHub中SSH没有连接上，测试ssh连接GitHub\n\n``` bash\n$ ssh -T git@github.com\n```\n\n连接不成功：\n\n>Connection reset by 13.229.188.59 port 22\n\n## 尝试过的方法\n\n*新建SSH KEY*\n\n*设置防火墙*\n\n都还是不行。\n\n## 最终解决方案\n\n**校园网网络通端口号切换到1号口**","tags":["hexo","github","ssh"]},{"title":"Hello World","url":"/2019/10/08/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"},{"title":"远程桌面连接","url":"/2019/09/09/远程桌面连接/","content":"\n目标：在本地电脑A通过远程桌面连接控制远程电脑B。\n\n（1）[开启远程电脑B的远程连接](https://jingyan.baidu.com/article/6f2f55a171c4fdb5b93e6c38.html)，这个经验里的第四步的添加用户可不加。\n\n（2）查看远程电脑B的内部IP地址：打开远程电脑B的windows cmd，**ipconfig**命令查看自己的ip地址，一般是192.168.x.x。\n\n（3）在远程电脑B设置外部端口：打开路由器admin，在里面找“虚拟服务器”或者“端口转发”，添加映射关系，内部端口3389，外部端口设置自己喜欢的，内部ip地址就是第二步查出来的。\n\n（4）查看远程电脑B的外部IP地址：打开网络通，找到找到WAN网ip地址，就是主页上显示的那个，一般是222或104等开头。\n\n（5）[在远程电脑B设置静态IP](https://jingyan.baidu.com/article/7f766dafeabc204101e1d0b8.html)，是指第二步查看到的IP，否则下次重启有可能IP地址就变了。\n\n（6）在本地电脑A进行远程连接：打开远程桌面连接，输入**WAN IP:外部端口**，然后输入用户名密码即可登录。\n"},{"title":"Youth","url":"/2019/08/04/Youth/","content":"\n*源于百词斩的一篇阅读分享*\n\nYouth is not a time of life; it is a state of mind;\n\nit is not a matter of rosy cheeks, red lips, and supple knees;\n\nit is a matter of the will, a quality of the imagination, a vigor of the emotions; \n\nit is the freshness of the deep springs of life. \n\nYouth mean a temperamental predominace of courage over timidiity, of the appetite for adventure over the love of ease.\n\nThis often exsits in a man of sixty more than a boy of twenty.\n\nNobody grows old merely by a number of years, \n\nWe grow old by deserting our ideas.\n\nYears may wrinkle the skin, but to give up the enthusiasm wrinkles the soul.\n\nWorry, fear, self-distrust bows the heart and turns the spirit back to dust.\n\nWhether sixty or sixteen, there is in every human being's heart the lure of wonders, the unfailing child-lke appetite of what's next, and the joy of game of living.\n\nIn the center of your heart and my heart, there is a wrieless station;\n\nso long as it receieves the messages of beauty, hope, courage and power from man and from the Infinite, so long as you are young,\n\nWhen the aerials are down, and your spirit is covered with snows of cynicism and ice of pessimism, then you've grown old, even at twenty. but as long as your aerials are up, to catch the waves of optimism, there is hope you may die young at eighty."},{"title":"matlab程序脱离matlab环境运行","url":"/2019/07/01/matlab程序脱离matlab环境运行/","content":"\n我的需求来源于：\n\n* 想用Graph500的图生成器，生成两个大规模的图数据集。在官方github源码中发现了.m文件，测试发现可在matlab中运行生成图数据集。\n\n* 但是，由于我的PC内存容量有限（8GB），最多生成（28，1）的生成图（4GB），即节点数为2^28，边数比节点数为1的子图。\n\n* 我的需求是分别生成一个（30，32）-- 128GB 和（31，128）-- 1TB的生成图，至少需要能够生成（31，1）的子图，然后拼起来，即32GB，内存需求最少为64GB。\n\n* 所以，可以将kronecker_generator.m转成exe可执行文件直接放到64GB服务器上去执行，免去在服务器上装matlab。\n\n\n### 在有matlab的电脑生成.exe可执行文件\n\n1. 生成kronecker_generator.exe文件\n``` bash\nmcc -m kronecker_generator.m\n```\n\n2. 测试：打开cmd命令行，进入kronecker_generator.exe所在目录，运行\n``` bash\nkronecker_generator.exe\n```\n\n3. 带参数运行\n（1）首先在kronecker_generator.exe中添加代码\n\n***\n    function ij = kronecker_generator (SCALE, edgefactor)\n    if (ischar(SCALE))\n        SCALE = str2num(SCALE);\n    end\n    if (ischar(edgefactor))\n        edgefactor = str2num(edgefactor);\n    end\n***\n（2）cmd中测试运行\n``` bash\nkronecker_generator.exe 10 16\n```\n\n### 在另一台电脑上运行\n\n传输可执行文件到目标电脑后执行\n``` bash\nscp -P 5922 kronecker_generator.exe wang@210.45.114.192:/home/wang/code/\nkronecker_generator.exe 10 16\n```\n\n此方法只能用于另一个Windows系统下脱离MATLAB环境运行，Linux中不能直接运行.exe。\n\n要考虑在Linux环境下脱离MATLAB环境运行，需要尝试其他方法，比如将m文件转化为c/c++语言文件，但是还没尝试过。\n\n### 参考\n[matlab程序脱离matlab环境运行-mcc、mbuild和mex命令详解](http://blog.sciencenet.cn/blog-419879-508169.html)","tags":["matlab"]},{"title":"DrunkardMob的编译运行","url":"/2019/06/19/DrunkardMob的编译运行/","content":"\nDrunkardMob部署于Java版本的GraphChi，因为对Java的使用不是很熟练，简单的Java版本的GraphChi的编译和运行折腾了一个多周。这里记录一下编译运行的过程以及其他遇到的问题\n\n#### 安装jdk和mvn\n\n其实简单的apt-get install就可以了\n``` bash\nsudo apt-get install openjdk-8-jdk\nsudo apt-get install maven\n```\n\n所谓后来编译出现的各种问题，就是这里没有装好，我一开始是按照网上一些配置Java运行环境的博客做的，然后配置JAVA_HOME之类的，编译就报各种错，尝试安装了各种版本，还是会有各种奇特的错误。其实这里通过apt-get安装默认是可以不用配置JAVA_HOME环境的。\n\n\n我是先安装的mvn，会自动安装一个jdk，用 java -version看也确实是安装了Java8，但是并没有安装javac，所以编译的时候会找不到编译的包。所以还是需要另外去安装一个jdk。\n\n#### scala版本冲突问题\n\n“class ... is broken”\n\n这里其实是因为作者的pom.xml文件中指定的Scala版本是2.9.0-1， 而实际编译运行需要的Scala的版本是2.11.2.\n\n所以解决办法是：将相应依赖项中scala-lang的版本号改为 2.11.2\n\n***\n    <dependency>\n        <groupId>org.scala-lang</groupId>\n        <artifactId>scala-library</artifactId>\n        <version>2.11.2</version>\n    </dependency>\n***\n\n我上周在这个问题的时候走了很多弯路，看到网上有博客说这个报错是因为需要安装比较老的jdk版本，所以也尝试安装了jdk7和jdk6，mvn的版本也按照作者给的版本重新安装了，总之瞎折腾了很久。\n\n#### 运行找不到类\n\n这个实际上是个很坑的问题，因为后来版本有改进，应该将命令中graphchi-java-0.2-jar-with-dependencies换成graphchi-java-0.2.2-jar-with-dependencies\n\n到这里，不出意外的话，程序应该是可以正常编译，运行起来了，因为最后在403的ccc服务器上，到这里就运行成功了\n\n#### common-math版本冲突\npom.xml中关于common-math有重复定义，可以注释掉其中一个。\n\n#### jdk版本配置\n\n作者用的是jdk1.6，我这边安装的jdk1.8，这里pom.xml文件中maven-compiler-plugin下的configuration中的*source* 和 *target* 应该改为1.8.\n\n\n#### TEST时找不到surefire\n\n解决办法是追加plugin（version要根据报错信息调整，这里应该是2.12.4）\n***\n    <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-surefire-plugin</artifactId>\n        <version>2.12.4</version>\n        <configuration>\n            <useSystemClassLoader>false</useSystemClassLoader>\n        </configuration>\n    </plugin>\n***\n\n#### 在线依赖项\n\n之后遇到的问题是发现修改后的源码，编译后无效，即不能运行编译后的结果。\n又是折腾了两天，发现是因为添加了在线依赖项的原因。。。\n\n即作者的说明文档中，说是要加入的依赖项：\n***\n    For maven, include the following in <dependencies>:\n    <dependency>\n        <groupId>org.graphchi</groupId>\n        <artifactId>graphchi-java_2.11</artifactId>\n        <version>0.2.2</version>\n    </dependency>\n***\n其实是编译好的graphchi-java的库包，被放在的maven的仓库中，添加依赖项就会直接引用在线的库包，从而覆盖了本地的编译的结果。删除掉这项依赖项，可以正常修改然后编译运行了。\n\n#### 版本冲突\n系统不知道什么时候升级了openjdk，导致与pom.xml中声明的版本冲突！\n查看版本：\n``` bash\njava -version\nmvn -version\n```\n\n解决，卸载重装：\n``` bash\nsudo apt-get autoremove openjdk*  //autoremove会卸载所有相关依赖项，慎重使用！！！！\nsudo apt-get autoremove java*\nsudo apt-get install openjdk-8-jdk\n```\n","tags":["Java"]},{"title":"Wukong 基于RDMA的快速并发RDF查询","url":"/2019/02/25/Wukong-基于RDMA的快速并发RDF查询/","content":"\n[Wukong:Fast and Concurrent RDF Queries with RDMA-based Distributed Graph Exploration, JIAXIN SHI, YOUYANG YAO, RONG CHEN, HAIBO CHEN, OSDI16](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/shi)\n\n[可参考博客](https://blog.csdn.net/qq_21125183/article/details/80670024)\n\n### 背景介绍\n\n#### 在线图查询\nOnline graph query plays a vital role for searching, mining and reasoning linked data.\n\n#### RDF and SPARQL\nRDF :  Resource Description Framework 资源描述框架。用于表示网络上链接的数据，例如知识图谱。\n\nRDF is a graph composed by a set of ⟨Subject, Predicate, Object⟩ triples 由<主谓宾>三元组组成的图。\n\nSPARQL ： 针对RDF的标准查询语言。\n\n### 现有查询方法\n\n1、关系型数据库管理（RDBMS）\n\n三元组存储和三元组联接，联接三张表，查询得出结果。\n\n缺点 ：分布式联接开销大 & 会产生大量的中间结果。\n\n2、图处理系统\n\n图存储和图检索，将RDF数据存储为一个图的形式，一步步检索出满足条件的节点关系，最后联接所有查询结果，得出最终结果。\n\n缺点 ：最后联接部分开销非常大 & 查询节点关系需同步执行，比较慢。\n\n## 基于图的RDF数据模型\n\n1. Graph model and indexes\n\n新增协助索引节点（index vertices）：predicate index & type index\n\n原来的节点（normal vertices）：subjects& objects\n\nindex vertices与normal vertices一起参与划分子图和存储\n\n2. Differentiated Graph Partitioning\n受 PowerLyra[ EuroSys15] 启发\n\n1）高度节点 ： 拆分成多个节点，分别存放于不同机器；\n\n2）低度节点 ： 分部存储到不同机器\n\nwukong：\n\n1）index vertices : 拆分；\n\n2）normal vertices ： 分布；\n\n3）在RDF场景下，高度节点的不均匀，并不会很大的影响负载均衡。\n\n3. RDMA-friendly Predicate-based KV store\n\nkey :  \"vid, p/tid, d\"\n\nvalue : the list of neighboring vertex IDs or predicate/type IDs\n\n减少大量计算和网络开销\n\n## wukong查询过程\n\n1. Basic Query Processing\n\n2. Full-history Pruning\n\n3. Migrating Execution or Data\n\n4. Concurrent Query Processing\n","tags":["graph processing system","RDF query","KV graph storage"]}]