[{"title":"动态图数据挖掘与查询算法的研究","url":"/2020/02/26/动态图数据挖掘与查询算法的研究/","content":"\n[动态图数据挖掘与查询算法的研究](http://cdmd.cnki.com.cn/Article/CDMD-10213-1013045186.htm)\n\n杨雅君 《哈尔滨工业大学》 2013年\n\n### 摘要\n\n随着信息科技的高速发展，各个应用领域的的信息量都呈现了爆炸性的增长趋势。因此，不同应用领域所关注的实体对象之间的关系也变得愈加庞大和复杂。在这些复杂关系的背后，往往蕴含着巨大的科学价值和商业价值。近年来，许多领域的研究者都开始专注于实体对象之间关系的研究。“图”作为计算机科学中一般性的数据结构，它可以很好的反映数据对象之间的复杂关系。因此，图数据被广泛地用来刻画现实世界中各种各样实体间的复杂关系。 然而，在现实世界中，实体对象间的关系每时每刻都在发生着变化。例如：在蛋白质交互网络中，各类蛋白质分子相互作用有着先后顺序，这使得整个蛋白质交互过程要随着时间顺序进行；在社会关系网络中，各类人和各类社会团体之间的交互关系会随着时间发生变化；在交通网络中，通过每条公路的时间和费用因交通拥塞的发生而随着时间发生变化。因此，描述实体间关系的图数据也会随着时间发生变化。 动态图是指会随时间发生变化的图数据。动态图可以根据其变化的形式分为两类：(1)图中拓扑结构关系发生变化；(2)图中顶点和边所代表数据对象内容、或者图中某一特定对象的评价方式发生变化。我们分别称之为图的结构变化和图的内容变化。由于动态图在现实世界中广泛存在，因此对动态图上各类问题的研究就有着十分重要的意义。然而，传统静态图数据上解决各类问题的算法无法用于解决动态图数据上的各类问题，主要有以下几个原因：第一，传统的静态图模型无法描述图数据随时间发生演绎与进化的情况；第二，传统的静态图模型上的各类问题的定义在动态图模型上不再适用；第三，图数据的动态性使得各类问题的计算复杂性大大增加，原有的静态图上的各类方法将无法有效地解决这些问题。此外，现有的动态数据管理的研究主要关注于数据流和传统关系数据的动态维护，这些方法无法处理结构复杂的图数据。 本文运用计算复杂性和算法学的理论和知识，分别对基于结构变化和基于内容变化的动态图上的相关问题开展了研究工作，主要研究成果如下： (1)本文研究了动态图上结构变化最频繁子图挖掘问题，提出了一个基于“累积连通度变化”概念的评分函数来评价子图的结构变化的频繁程度。本文提出一个两段式算法来计算动态图中任意一对顶点之间的累积连通度变化。进一步地，本文提出一个基于“划分树”结构的算法挖掘目标子图，该算法逐步地将不属于目标子图中的顶点从全图中移除。本文分析了算法的时间复杂度和空间复杂度。真实数据上的实验结果表明，本文算法所挖掘到的子图在整个动态图中变化最频繁。同时，本文算法具有很高的的时间效率。 (2)本文研究了动态图上连通度变化最大的k-顶点集挖掘问题，提出了一种名为“连通等价类树”的结构，利用该结构可以高效地计算图中所有顶点对之间的连通度变化。本文提出了一个高效的连通等价类树构建算法和更新算法。其中，更新算法是一个逐边增量式算法，当动态图发生变化时，该算法只需要更新图中一小部分顶点之间的连通度即可完成连通等价类树的更新。本文证明，在相同的空间复杂度下，本文提出连通等价类树更新算法的时间复杂度远远小于现有最快的连通度更新算法。进一步地，本文提出一种分支界限算法和三种高效的剪枝策略用于挖掘连通度变化最大的k-顶点集。真实数据上的实验结果表明，本文算法所挖掘到的顶点子集可以良好的反映整张动态图中连通度变化情况，因此，其可以作为动态图连通关系变化的一个概括。同时，实验结果表明，本文中算法具有很高的时间效率。 (3)本文研究了多维代价图上动态最优路径查询问题。本文证明了多维代价图上动态最优路径查询问题是一个NP-难问题，并提出了一个分支界限算法和三种高效的剪枝策略用于计算动态最优路径。进一步地，本文提出了一种新的索引结构，k-簇索引，使得本文算法在大规模图上是时间高效和空间高效的。k-簇索引利用“contour skyline”加速查询进程。本文证明计算“contourskyline”是一个NP-难的问题，并提出一个2-近似的算法。本文证明了不存在近似比小于2的多项式时间算法。同时，本文提出一个顶点过滤算法，该算法可将图中大部分不属于最优路径的顶点过滤掉，进一步提高了算法效率。真实数据上的实验结果表明，本文算法具有非常高的时间效率和空间效率。 (4)本文研究了时间依赖图上满足时间限制的费用代价最优路径查询问题，提出了一个两阶段算法计算满足时间限制的费用代价最优路径。算法在第一阶段计算了起点到终点满足时间限制的最小费用代价，在第二阶段根据最小费用代价计算了起点到终点的最优路径。本文分析了查询算法的时间复杂度和空间复杂度。真实数据上的实验结果表明，本文提出的查询算法具有非常高的时间效率和空间效率。\n【学位授予单位】：哈尔滨工业大学\n【学位级别】：博士\n【学位授予年份】：2013\n【分类号】：TP311.13","tags":["paper reading","dynamic graphs"]},{"title":"Neo4j Graph Database(2007)","url":"/2020/02/18/Neo4j-Graph-Database-2007/","content":"\n**参考文献**：\n\n[[1] 图数据库竞争日趋激烈，淘汰正在进行](https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247500325&idx=2&sn=b828e5a137824eb3c5d44f7fc97270eb&chksm=fbea7beacc9df2fcdba3728949ebb203e89697b481d8d7e2faade508c3c6695352829ae90659&mpshare=1&scene=1&srcid=&sharer_sharetime=1581673402114&sharer_shareid=9d59fa79978018715cd685e03310e51e&key=7545a23db0fbfa9b5f0039cac3b60f89c2ce5b6cd17c7617fe4e09156d4503be9062141d013a723ae3abef3ba1920cac7fb49498aa8162433400cbb458132696ec706f3a9015d6abf70e9f9940764384&ascene=1&uin=MjA1MjM0NjAyMQ%3D%3D&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=AXhym5sv3VTHIiJ5BN9dfag%3D&pass_ticket=nfR9DyVPFn2dHSZyBtvPwZAMprhQskPslekF8pSDwnsA60LS%2FS6yaS%2FSODTBsAd1)\n\n[[2] Neo4j官网](https://neo4j.com/)\n\n[[3] Neo4j 底层存储结构分析](https://sunxiang0918.cn/2015/06/27/neo4j-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/)\n\n[[4] 知识图谱里的知识存储：neo4j的介绍和使用](https://zhuanlan.zhihu.com/p/76544669)\n\n### 背景\n\n#### 图计算与图数据库\n\n*2019 年年初，Gartner 数据与分析峰会上将图列为 2019 年十大数据和分析趋势之一，并预计到 2022 年，全球图处理及图数据的应用将以每年 100% 的速度迅猛增长，2020 年保守估计将达到 80 亿美元*[1]。\n\n**图计算**重点包括两点：1）重点关注在线事务处理(**OLTP**)的**图数据库**，擅长事务性查询，但并不能高效地进行离线分析；2）重点关注离线图分析处理(**AP**)的**图分析引擎**，却不能对属性图进行管理，且不支持实时查询。\n\n大数据时代的业务增长带来的数据关联的复杂化催生了数据库的变革和创新。图数据库由于*提供了对关联数据最直接的表达*，以及*图模型对异构数据天然的包容力*。\n\n#### 挑战\n\n图要实现大规模应用并不是一个简单的问题，从应用层面来看，存在以下几个问题：\n\n1、**技术实现难**：数据加载是性能瓶颈，动态增量图数据不能实时及时更新；超级顶点问题；OLTP与OLAP融合问题；图划分；流式图数据处理问题等。\n\n2、**业务理解难**图数据库的实施流程一般包括：业务理解、图 Schema 设计、业务数据加工、业务验证和监控运维 5 个步骤。但目前企业应用中，数据质量、应用方法不成熟，用户需求不明确。理解业务数据和业务问题，将业务问题映射成图问题，并确认数据来源、存储介质、更新方式、容灾方案等，并匹配相应的软硬件资源等困难。\n\n3、**选择差异大**：从市场竞争角度，很多不同类型的图数据库产品优势不同，差异大，需要从性能、查询能力、计算能力等各方面去考虑。\n\n#### Neo4j\n\nNeo4j是2007年开始的一个开源项目[2]，是不仅利用数据而且利于数据之间的关系来建造的一个高度可伸缩的本地图数据库。使用Neo4j，开发人员可以构建智能应用程序，实时地遍历当今大型的、相互连接的数据集。由本机进行图存储和处理引擎支持，Neo4j为独特的、可操作的见解提供了直观、灵活和安全的数据库。其应用场景包括人工智能、知识图谱、诈骗检测、社交网络和实时推荐系统等等。\n\n### Neo4j的底层存储\n\n#### 存储模型\n\nneo4j的数据存储形式主要是节点（node）和 边（edge）来组织数据。node可以代表知识图谱中的实体，edge可以用来代表实体间的关系，关系可以有方向，两端对应开始节点和结束节点。另外，可以在node上加一个或多个标签（Node Label）表示实体的分类，以及一个键值对集合来表示该实体除了关系属性之外的一些额外属性，关系也可以附带额外的属性[4]。\n\n* **Node的存储**：每个Node保存了第1个Property和第1个Relationship。\n\n---\n| inUse | nextRelId | nextPropId |\n| :-: | :-: | :-: |\n---\n\n* **Relationship的存储**：每个关系通过一个双向链表，保存其源节点和目的节点的Id以及他们的上一个和下一个关系。\n\n---\n| sid | prep | next | tid | prep | next |\n| :-: | :-: | :-: | :-: | :-: | :-: |\n---\n\n* **Property的存储**：Node和Relationship的Property都使用一个基于Key-Value的双向列表来保存。\n\n#### 样例阐述\n\n* 样例图\n\n<!-- ![](/img/neo4j/case_graph.png) -->\n\n<div align=center width=80%>\n  <img width=250 src=\"/img/neo4j/case_graph.png\" >\n</div>\n\n* Node的存储\n\n<!-- ![](/img/neo4j/node.png) -->\n\n<div align=center width=80%>\n  <img width=150 src=\"/img/neo4j/node.png\" >\n</div>\n\n* Relationship的存储\n\n<!-- ![](/img/neo4j/relationship.png) -->\n\n<div align=center width=80%>\n  <img width=300 src=\"/img/neo4j/relationship.png\" >\n</div>\n\n若想要访问某个node的所有邻居节点，首先通过该node找到其第一个relationship，然后通过递归访问当前relationship的next指针找到该node的下一个relationship，直至next指向null。这样可以遍历该node的所有relationship，然后可以到达与其有relationship的第1层Nodes，在通过遍历第1层Nodes的relationship，可以达到第2层Nodes……\n\n#### 存储文件\n\nneo4j中，节点、关系、标签等文件是以**数组**作为核心存储结构，各个类型的每个数据项都会分配一个唯一的ID，在存储时以该ID作为数组的下标。这样，在访问时通过其ID作为下标，实现快速定位。另外，节点和关系的属性采用基于**KV**的存储结构。具体的，Neo4j中由下列存储文件。\n\n---\n**存储 node 的文件**\n\n1.存储节点数据及其序列Id\n\n* neostore.nodestore.db：存储节点数组，数组的下标即是该节点的ID\n* neostore.nodestore.db.id：存储最大的ID及已经free的ID\n\n2.存储节点label及其序列Id\n\n* neostore.nodestore.db.labels：存储节点label数组数据，数组的下标即是该节点label的ID\n* neostore.nodestore.db.labels.id：存储最大的ID及已经free的ID\n\n---\n**存储 relationship 的文件**\n\n1.存储关系数据及其序列Id\n\n* neostore.relationshipstore.db：存储关系record数组数据，数组的下标即是该条关系（边）的ID\n* neostore.relationshipstore.db.id：存储最大的ID及已经free的ID\n\n2.存储关系组数据及其序列Id\n\n* neostore.relationshipgroupstore.db：存储关系group数组数据，数组的下标即是该关系组的ID\n* neostore.relationshipgroupstore.db.id：存储最大的ID及已经free的ID\n\n3.存储关系类型及其序列Id\n\n* neostore.relationshiptypestore.db：存储关系类型数组数据，数组的下标即是该关系类型的ID\n* neostore.relationshiptypestore.db.id：存储最大的ID及已经free的ID\n\n4.存储关系类型的名称及其序列Id\n\n* neostore.relationshiptypestore.db.names：存储关系类型token数组数据，数组的下标即是该关系类型token的ID\n* neostore.relationshiptypestore.db.names.id：存储最大的ID及已经free的ID\n\n---\n**存储 label 的文件**\n\n1.存储label token数据及其序列Id\n\n* neostore.labeltokenstore.db：存储lable token 数组数据，数组的下标即是该label token的ID\n* neostore.labeltokenstore.db.id：存储最大的ID及已经free的ID\n\n2.存储label token名字数据及其序列Id\n\n* neostore.labeltokenstore.db.names：存储label token的names数据，数组的下标即是该label token的name的ID\n* neostore.labeltokenstore.db.names.id：存储最大的ID及已经free的ID\n\n---\n**存储 property 的文件**\n\n1.存储属性数据及其序列Id\n\n* neostore.propertystore.db：存储property数据，数组的下标即是该property的ID\n* neostore.propertystore.db.id：存储最大的ID及已经free的ID\n\n2.存储属性数据中的数组类型数据及其序列Id\n\n* neostore.propertystore.db.arrays：存储property (key-value 结构)的**Value值是数组**的数据。\n* neostore.propertystore.db.arrays.id\n\n3.属性数据为长字符串类型的存储文件及其序列Id\n\n* neostore.propertystore.db.strings：存储property (key-value 结构)的**Value值是字符串**的数据。\n* neostore.propertystore.db.strings.id\n\n4.属性数据的索引数据文件及其序列Id\n\n* neostore.propertystore.db.index：存储property (key-value 结构)的**key的索引数据**。\n* neostore.propertystore.db.index.id\n\n5.属性数据的键值数据存储文件及其序列Id\n\n* neostore.propertystore.db.index.keys：存储property (key-value 结构)的**key的字符串值**。\n* neostore.propertystore.db.index.keys.id\n\n---\n**其他的文件**\n\n1.存储版本信息\n* neostore\n* neostore.id\n\n2.存储 schema 数据\n\n* neostore.schemastore.db\n* neostore.schemastore.db.id\n\n3.活动的逻辑日志\n\n* nioneo_logical.log.active\n\n4.记录当前活动的日志文件名称\n\n* active_tx_log\n\n\n### Cypher查询语言\n\nneo4j采用自己设计的查询语言cypher，其特点和sql有很多相似的地方。match、where、return是最常用到的关键词：\n\n* **match**: 相当于 sql中的select，用来说明查询匹配的数据模式（或者说图模式）；\n\n* **where**: 用来限制node或者关系中部分属性的属性值，从而返回我们想要的数据；\n\n* **return**: 返回节点或者关系。\n\n**查询举例**：找出所有公司中，指向其他公司的连接关系数超过75条的公司。\n\n---\n\nMATCH (c:company)-[r:INTERLOCK]->() WITH c, count(r) as relaNum WHERE relaNum>=75 RETURN c,relaNum\n\n---\n\n**neo4j还内置实现了一套图搜索算法，并提供了相关函数接口。**\n\n* 比如你想查询两个节点之间的最短路径，就可以调用查询语句：shortestPath()。\n\n### 其他图数据库\n\n<div align=center width=80%>\n  <img width=500 src=\"/img/neo4j/gdb.jfif\" >\n</div>\n\n图数据库领域，远没有达到目前传统RDBMS的成熟程度，还处于发展阶段，具体表现在：\n\n* 图数据库产品极大丰富，出现几家具有垄断性地位的玩家，性能和功能全面碾压其他产品。\n\n* 图数据查询语言完成ISO标准化（目前OpenCypher和GSQL处于“绝对赢家”地位），并且大部分产品都遵循这个标准，并出现数据交换标准。\n\n* 用户受到普遍教育，能像使用RDBMS一样很自然地接受图数据库应用，出现大量第三方图应用程序开发商和集成商。\n\n相较之下，图分析引擎的成熟度弱于图数据库，目前偏学术性研究的有不少，但是工业级的产品非常少，并且缺乏专门为图分析设计的框架和产品，目前很多一线公司都还是使用 Spark、Flink、MapReduce 等通用计算框架来做图计算，性能肯定不如专门为图分析设计和优化的系统。","tags":["graph database"]},{"title":"Graph Database Applications and concepts with Neo4j(SAISC 2013)","url":"/2020/02/14/Graph-Database-Applications-and-concepts-with-Neo4j-SAISC-2013/","content":"\n近年来，图数据库成为关系型数据库的一种可行的替代选择。像化学、生物、语义网、社交网络和推荐引擎等应用场景，都可以使用一种更自然的形式来建模表示。\n\n图数据库由于提供了对关联数据最直接的表达，以及图模型对异构数据天然的包容力，使得图数据库迎来飞速发展的状态。\n\n### 背景\n\n#### 关系型数据库\n\n**简介**：关系型数据库大约出现于1960s，它已被证明能稳定地提供持久性、并发控制和集成机制。关系型数据库维护由行列集合定义的表的信息。一行表示一个对象，一列表示对象的一个属性信息。\n\n**不足**：1）关系型数据库很难显示地捕捉需要的语义。涉及复杂的相互关联的信息的大数据问题在科学中越来越普遍，使用传统的关系型数据库来存储、检索和操作这些复杂的数据变得越来越繁重；2）关系型数据库中基于模型的数据类型的定义也限制了如何存储信息，当新类型的数据来临，需要手动调整重新设计数据模式。\n\n对比来说，关系型数据库对聚合数据进行了优化，Neo4j等图数据库对高度连接的数据进行了优化。\n\n#### 图数据库\n\n**图**是由节点和边组成的数据结构。**图数据库**是关注实体之间关系的有效数据建模工具，建模对象和它们之间的关系意味着几乎任何东西都可以在相应的图中表示。\n\n大多数系统支持的常见图类型是**属性图**。属性图可以有效地建模所有其他类型的图。图数据库优化了密集、相关联的数据的高效处理。该设计允许构建预测模型，并检测相关性和模式。这种高度动态的数据模型中，所有节点都通过关系连接，允许在顶点之间的边缘进行快速的遍历。一个特别的好处是，遍历是本地化的，不需要考虑不相关数据的帐户集，这是SQL中一个固有的问题。\n\n#### VS 图处理系统\n\n**图处理系统**区分于图数据库，比如谷歌的Pregel或Apache Hama，致力于解决另一种类型的问题——在线分析处理（online analytical processing, **OLAP**），旨在快速响应高性能处理的多维度分析查询，比如大规模图数据上的一些图算法的快速计算。\n\n**图数据库**比如Neo4j，致力于解决在线事务处理（online transaction processing, **OLTP**）问题，是为了促进和管理面向事务的查询。\n\n### 图数据库的应用场景\n\n图数据库在一些数据互连信息或拓扑结构非常重要的领域非常实用，在这些领域的应用中，数据之间的关系和数据本身同等重要。很多公司为了满足图数据库系统的需求都开发了内部的实现，比如Facebook的Open Graph，Google的Knowledge Graph，Twitter的FlockDB等。\n\n下面介绍一些通过图数据库的方法能带来很多收益的系统场景，这些系统中也可以使用关系型数据库系统（RDBMS），但是功能有限且代价昂贵，其处理能力主要受限于查询朋友的朋友等类型的问题带来的递归连接（JOINs）操作。\n\n* **社交网络**，需要量化个体之间的连接关系，比如查询某个用户的朋友的朋友，在图数据库中只需要沿着连接边进行两层查找；但是在关系型数据库中，遍历图中每一条边都需要一个*连接（JOIN）*操作。连接在RDBMS上是非常昂贵的,而GDB中遍历边成本非常小。\n\n* **推荐系统**，包括*基于内容的过滤（content based filtering）*，侧重于分析项目特征，找到相似的项目，并推荐这些项目；和*协同过滤（collaborative filtering）*一种通过从大样本集中收集信息来自动预测用户兴趣的技术。\n\n* **生物信息学**，生物信息学使用图数据库来联系一个复杂的信息网络，包括基因、蛋白质和酶。\n\n### 软件设计\n\n在软件设计中，通常将项目中的实体建模为图，实体有其属性，实体之间由各种关系连接。\n\n当使用关系型数据库来建模时，由于数据模型的灵活可变性，每当一个新类型的实体加入，就需要提交一个新的表结构，限制了模型的可扩展性。而在图数据库中，支持灵活的各种类型的实体作为新的节点加入图中。\n\n### 数据查询和操作\n\n#### 查询语言\n\n查询语言是操作符或推理规则的集合，这些操作符或推理规则可应用于模型数据结构类型的任何有效实例，其目标是以所需的任何组合操作和查询这些结构中的数据。\n\nRDBMS系统使用一种称为SQL(Structured Query Language，结构化查询语言)的共享标准来进行数据插入、更新和删除、查询以及模式创建和修改。SQL基于关系代数和元组关系计算。这种通用的一致性方法使得从不同RDBMS实现中学习的概念具有极大的可移植性。\n\n图数据库中，遍历是数据检索的基本操作。遍历和SQL查询之间的一个主要区别是遍历是本地化操作，没有全局邻接索引，而是图中的每个顶点和边都存储一个与之连接的对象的“迷你索引”。这意味着图的大小对遍历和SQL中执行的代价高昂的分组操作没有性能影响。（需要注意的是，全局索引确实存在于Neo4J中，但是它们只在尝试查找遍历的起始点时使用。）\n\n图数据库的世界还没有统一的遍历和插入语言。这种标准化的缺乏导致了数据交互的实现和框架的巨大差异。现有的实现包括Neo4j的Java API、REST接口、Gremlin和Cypher。Gremlin和Cypher是用于遍历Neo4J图的两种主要语言。\n\n#### 查询样例\n\n**查询请求**：哪些用户给了《黑衣人》五星?他们给了其他什么电影五星?(只返回5个结果)\n\n**查询命令**：g.V.filter{it.title==\"MeninBlack(1997)\"}.inE('rated').filter{it.getProperty('stars')==5}.outV.outE('rated').filter{it.getProp\nstars')==5}.inV.title[0..4]\n\n**查询步骤**：\n* 1.从节点《黑衣人》开始遍历——g.V.filter{it.title==\"MeninBlack(1997)\"}；\n* 2.获得所以“评分”的入边——inE('rated')；\n* 3.过滤掉那些评分不是5的边——filter{it.getProperty('stars')==5}；\n* 4.获取剩余边的源节点的用户——outV；\n* 5.获取这些用户顶点的“评分”边——outE('rated')；\n* 6.过滤掉那些评分不是5的边——filter{it.getProperty('stars')==5}；\n* 7.获取剩余边的目的顶点的影片——inV；\n* 8.获取这些影片顶点的“标题”——title；\n* 9.只输出前5个标题——[0..4]。\n\n### 可靠性\n\n在数据库存储中，ACID(atomicity, consistency, isolation, durability)是保证事务能被可靠执行的四大限制条件。Neo4j完全兼容这些限制。\n\n* **原子性**：如果事务的任何部分失败，数据库状态将保持不变。\n* **一致性**：任何事务都会使数据库保持一致的状态。\n* **隔离性**：在事务处理期间，修改后的数据不能被其他操作访问。\n* **持久性**：DBMS总是可以恢复已提交的事务的结果。\n\n另外，Neo4j还提供一些其他事务管理的细节，以及高可用性，备份和安全性。\n\n### 结论\n\n图数据库带来了一种新的建模和遍历互联数据的方法，这在信息存储领域是无可比拟的。随着生产级系统(如使用GDB的Neo4j)的出现，可以不用在RDBMS上使用有限的实现来解决问题。图数据库在生物学、语义学、网络和推荐系统中有一个自然的应用，这些系统只需要它们能够提供的数据模型类型。\n\n这个图形数据库准备好完全取代RDBMS了吗?这是一个错误的问题。RDBMS适合大多数数据存储需求。它们得到了良好的文档记录、支持，并被证明是稳定的。使用图形数据库的决定不应该基于不使用RDBMS。如果需要一个表示高度连接数据的动态数据模型，那么图形数据库是最好的解决方案。对于大多数常见的问题，RDMBS是一个更合适的解决方案","tags":["paper reading","graph database"]},{"title":"Survey of Graph Database Models(TR 2005)","url":"/2020/02/10/Survey-of-Graph-Database-Models-TR-2005/","content":"\n## 数据库模型\n\n1. **概念**：表述真实世界中的实体以及实体之间关系的概念性工具的集合。\n\n2. **定义**：一个数据库模型可以定义为下面三个部分的结合：数据结构类型的集合，操作或推导规则的集合以及通用的完整性约束规则的集合。\n\n3. **用途**：数据库模型是重要的抽象工具，比如指定数据的许可类型、数据库的通用设计方法、数据库演变过程的备份等。\n\n4. **发展史**：物理数据模型（分层数据库模型&网络数据库模型） --> 关系型数据库模型 --> 语义数据库模型 --> 面向对象的数据库模型 --> *图数据库模型* --> 半结构化的数据库模型 --> XML。\n\n5. **相关工作**：图视觉化、外存设备的图数据结构和算法、数据库的图方法、通用图数据库系统的实现等。\n\n## 图数据建模\n\n### 图数据模型的定义\n\n一个图数据库模型有下面三个组成部分：\n\n1. **数据结构**：由图表示的数据或模式。\n\n2. **转换语言**：由图形转换来表示的数据操作。\n\n3. **完整性约束**：完整性约束的存在加强了数据的一致性。这些约束可以按照模式实例一致性、身份和引用完整性、功能和包含依赖关系进行分组。\n\n总之，一个图数据库模型是一个 *表达模式或实例的数据结构被建模为一个图，数据操作被表达为图操作和类型构造，并且图结构具有适当的完整性约束* 的模型。\n\n### 为什么需要图数据模型\n\n图数据库模型通常应用于数据之间的关系信息比数据信息本身更重要或者同样重要的场景。具体的，引入*图*作为建模工具有下面几个优点：\n\n（1）图结构对用户可见，允许一种自然的处理应用程序数据的方式，比如超链接和地理数据库。\n\n（2）查询可以直接引用图结构。\n\n（3）图数据库可以为提供特殊的存储图结构以及实现特殊操作的图算法。\n\n### 对比其他数据模型\n\n1. **物理数据模型**：最早用来组织大规模数据集合的数据库模型，接近于物理实现，具有代表性的有分层模型和网络模型。这种模型缺乏好的抽象级别，数据结构很难灵活的应用于非传统的应用场景。\n\n2. **关系型数据模型**：强调抽象级别的概念，引入物理和逻辑级别的分离。关系型数据库模型逐渐地将焦点转移到应用和用户看到的建模数据，当时，应用领域都是些简单的基本类型的数据，比如银行、会计、商业和管理应用。关系型模型为数据建模提供了数学基础，基于简单的关系的表示且结合代数和逻辑，使得关系型模型成为数据库研究的基础模型。关系型数据库的查询语言SQL也成为数据库查询的范例语言。\n\n但是，关系型数据库模型指向简单的结构已知的*记录-类型*的数据，他的模式是固定的且很难扩展。他的查询语言也不能够探索数据之间关系的图结构，比如路径，邻居、图模式等。\n\n3. **语义数据模型**：从用户的角度将一组较丰富的语义纳入数据库，允许数据库设计人员以一种自然和清晰的方式表示对象及其关系(类似于用户查看应用程序的方式)，使用高级抽象概念，比如聚合、分类和实例化、子和超排序、属性继承和层次结构等。与图数据库模型研究相关。\n\n4. **面向对象的数据模型**：用对象和方法来表述数据，追求更丰富的数据结构类型，但是仍然需要所有数据都遵循一个预定义的模式。\n\n5. **半结构化的数据模型**：在半结构化的数据中,结构是不规范的、隐含的、部分的，模式不限制数据，只描述它，是非常大和快速的演进，与模式相关的信息包含在数据中。通常，半结构化的数据通常被表示成树形的结构。\n\n### 应用场景\n\n真实生活的很多场景中，关于它的连接性的信息是一个显著的特征，主要可以分为*经典应用*和*复杂网络应用*。\n\n## 图数据库模型\n\n### 发展概述\n\n围绕图数据库的研究在上世纪九十年代蓬勃发展，之后就几乎消失了，主要原因如下：1）数据库社区逐渐转向半结构化的数据；2）XML的出现吸引了超链接工作的所有注意力；3）图数据的研究者开始转向一些具体的应用场景，比如空间数据，web，文档等；4）树形结构的数据类型对于大多数应用场景已经足够。\n\n### 数据结构\n\n图数据库模型的基础是：实体和关系的表示，实体或对象表示作为单个完整单元存在的事物，关系是在两个或多个实体之间建立连接的属性或谓词。\n\n图数据库最显著的特征是其连接实体之间的关系的表示方式，区分于关系型模型中的属性、语义模型中的标准抽象、面向对象模型中的复合对象或半结构化模型中的组合关系。\n\n所有的图数据库模型都以图的基本数学定义作为它们的形式基础，在这个基本层之上，模型受到语义或面向对象方法的影响，呈现出不同的特性。\n\n#### 实体的表示\n\n模型同时表示实例和模式级别的实体。具体来说，实体类型、关系类型和模式限制与数据库模式的定义相关，实体和关系的实例符合数据库实例。\n\n很多图数据库模型都将模式和实例表示为一个带标签的有向图。\n\n* 一个**模式图**定义了：1）实体类型，表示为标记了类型名称的节点；2）基本实体，表示为标记了实体类型的节点；3）关系，表示为标记了关系名称的边，关系只定义了实体类型(基本实体没有属性)，每个基本实体都有一个相关的常量域。\n\n* 一个**实例图**包含：1）具体实体，表示为标记了实体类型或对象标识符的节点；2）基本值，表示为标记了一个基本实体域内的值；3）关系，表示为标记了对应的关系名称的边。\n\n上述方法在其他模型中得到了扩展，图的基本结构(节点和边)通过使用超节点和超图得到了补充。基于简单模型和基于扩展图结构模型之间的一个共同特征是支持定义非传统数据类型，即通过定义复杂对象获得的特性。\n\n#### 关系的表示\n\n粗略的，我们可以区分图数据库模型中的两种关系：1）简单关系，通过一个简单的语义连接两个实体（比如属性），在图中表示为边的标签；2）复杂关系，使用额外的语义(如组合)来符合关系网络(如层次结构)，其表示取决于每个模型提供的数据结构。\n\n接下来，我们讨论图数据库模型中特定的几种关系类型：\n\n1. **属性**，表示一个属性(单值或多值)直接连接到一个实体。大多数图数据库模型通过使用与节点直接相关的标记边来表示属性。\n\n2. **实体**，如果两个或多个对象的关系概念地描述了一个不同的模型对象,那么这种关系被认为是一个实体。这种方法意味着对高阶关系的支持,即关系之间的关系。\n\n3. **邻居关系**，具有基本图形结构的模型提供了简单的支持和可视化的邻域关系。\n\n4. **标准抽象**，最常用的是聚集（关系的一部分）和他的相反组合（由关系组成），关联以及分组或集合。\n\n5. **衍生和继承**，这些抽象表示为模式级别上的子类和超类的关系以及实例级别上的实例化的关系。\n\n6. **嵌入关系**，由嵌套对象定义的递归指定关系。该特性通过使用超节点或超图结构自然地支持。\n\n### 完整性约束\n\n完整性约束是一般的语句和规则，它定义了一致的数据库状态或状态的改变的集合。\n\n#### 模式-实例一致性\n\n#### 对象标识符和引用完整性约束\n\n#### 函数依赖项\n\n### 查询和操作语言\n\n查询语言是一种操作符的集合，也可以应用于建模的数据结构类型的任何有效实例，目的是在需要的任何组合中操作和查询这些结构中的数据。\n\n在图数据库模型中，有大量的工作集中在查询语言、查询图的问题、结果的可视化显示和图查询语言。\n\n### 现有图数据库模型","tags":["paper reading","graph database"]},{"title":"基于KV的动态图存储优化","url":"/2020/02/09/基于KV的动态图存储优化/","content":"\n\n### 动态图场景下的图处理需求\n\n现实中的很多应用场景都是动态图场景，比如网页链接中插入新网页、电商平台用户购买产品、社交媒体中删除推文和社交网络中好友取消关注等，都会带来节点和边的插入或删除，造成图结构的改变。而一般动态图的处理场景图大多是一种在线实时的处理场景，往往需要实时得到反馈。因此，动态图场景下的图处理的性能需要得到保证。\n\n### 动态图存储的研究现状\n\n#### 图处理系统\n\n现有的图处理系统中大多采用CSR的格式来存储图数据。但是，CSR存储格式只适用于静态图的存储。在动态图场景下，当有新的节点或边数据插入时，想要融入增量图数据，CSR需要重构CSR序列和beg_pos序列的存储内容。而当不断有增量数据插入时，重构的开销就非常大，在真实的场景中往往难以实现。\n\n现在的图处理系统中往往采用一种快照的方式，将静态图数据与动态插入的增量图数据分开存储。这种方式虽然能很快的插入图数据的更新信息，但是在进行图分析计算时，需要分别访问静态图数据以及动态增量图数据，造成额外的查询开销，影响分析计算的性能。而且随着增量图数据的不断增加，也越来越难以维护，存储和计算开销都将变得越来越困难。\n\n#### 图数据库\n\n近年来，传统的关系型数据库已经无法满足日益复杂的关联数据信息的分析需求。因此，一种重点描述数据之间关系的数据库--图数据库应运而生，图数据库善于高效处理大量的、复杂的、互连的、多变的数据，计算效率远远高于传统的关系型数据库。\n\n现有的图数据库有；Neo4j, Titan, arangoDB, OrientDB, GUN等。这些图数据库在底层将不同类型的节点和边分别存储为一个集合，每个集合采用KV的方式进行存储。这些图数据库可以很好的支持动态图场景下节点和边数据的插入，即向对应的集合中增加条目。\n\n图数据库的应用场景主要是面向图数据的查询，比如查询某个节点的邻居节点信息。而且目前的图数据库还尚未成熟，在多维查询的场景下性能会大大下降。因此，目前的图数据库很难应用于一些图算法的计算。\n\n#### KV存储系统\n\n基于key-value的存储系统也是一种新型的非关系型数据库，能实现对数据的快速插入和查询访问。\n\n### Idea\n\n可以设计一种基于KV的存储结构，用于存储图结构。将增量图数据的插入转化为KV对的修改或插入，以实现对大规模动态图数据中节点和边数据的存储管理。\n\n基于设计的存储结构，设计对图数据的快速查询访问机制，以支持上层图分析任务的快速执行。\n\n### 工作计划\n\n1. 读论文，进一步了解目前的图数据库中图数据的存储管理策略。\n2. 尝试从实验上验证：设置key为节点，value为其出边邻居时，增量图数据的插入开销和一些图算法的计算开销。\n","tags":["graph processing system","my work","dynamic graphs","graph database","KV graph storage"]},{"title":"CNARW工作扩展","url":"/2020/02/09/CNARW工作扩展/","content":"\nCNARW的主要思想是利用walk前一步访问过的节点信息来优化下一步跳转的邻居选择。具体的，CNARW考虑当前节点和下一跳候选节点的公共邻居数量来进行下一跳的邻居选择。\n\n### CNARW算法\n目前的CNARW算法采用拒绝采样的策略，主要包含以下两个步骤：\n1. 1> 以随机均匀的选择概率 b_uv = 1/d 随机选择当前节点的一个邻居节点；\n2. 2> 以一个接受概率 q_uv = 1 - C_uv / min(d_u, d_v) 决定是否接受该节点进行跳转。\n（此处接受概率 q_uv的设置需要满足对称性，即 q_uv=q_vu，因为只有在满足对称性的情况下，可以根据可逆公式来推导出马尔科夫链的稳态分布。）\n\n### Journal扩展思路\n\n#### 初步扩展思路\n\n（1）考虑其他转移概率设计（为什么需要对称性）。\n\n（2）扩展到有向图。\n\n（3）理论证明CNARW的收敛速度快，即第二大特征值小。\n\n（4）应用NBRW和CNRW的设计优化到CNARW上，进一步加速收敛。\n\n（5）考虑更多大数据集。\n\n#### review意见\n\n（1）将所有符号列成一张表。\n\n（2）为什么要采用带拒绝的采样策略？\n\n（3）转移概率设计为什么需要对称？\n\n（4）* 理论证明收敛速度。\n\n（5）相对误差定义。\n\n（6）使用真实数据集，大数据集，比如Epinion。\n\n（7）提出的算法似乎不能在有向图上运行。\n\n（8）有些描述不清晰，比如X_{t}是什么？\n\n（9）更多的讨论MHRW。 -->\n\n### 计划扩展点\n目前考虑的可做的有下面三个扩展点：\n\n#### 进一步优化接受概率的设置。\n关于CNARW算法第二步中接受概率q_uv的设计可以引入一个参数 a 来调节C_uv 和  min(d_u, d_v)影响的权重，即设置接受概率为：q_uv = 1 - a*C_uv / min(d_u, d_v)。当 a > 1, C_uv影响更大；当 a < 1, min(d_u, d_v)影响更大。\n可以通过实验验证，对于不同实验环境（比如不同的数据集）下，不同的a的设置对算法收敛速度的影响，总结实验结果，启发式地设置一个合适的a值。\n\n\n#### 将NBRW的思想应用到CNARW算法中。\nNBRW的主要思想是针对随机游走采样容易产生大量重复样本的问题，设计修改随机游走的状态转移概率，避免回到前一步访问过的节点。这样在保证相同准确度的情况下，可以大大减少随机游走采样所需要的样本数目。\n将NBRW的思想融入到CNARW算法，只需修改CNARW算法第一步中的选择概率 b_uv， 即记录随机游走上一步访问的节点为w，设置：b_uv=0, if v = w; b_uv = 1/(d-1), if v != w。\n可以引用NBRW论文中的理论证明，保证该修改做法不会改变其原马尔科夫链的稳态分布。\n\n\n#### 考虑更大的真实世界的数据集。\n比如Epinion。\n\n\n另外，也尽量尝试一下理论证明CNARW算法能带来更快的收敛速度，即CNARW算法的状态转移矩阵具有更小的第二大特征值。（理论证明可能会比较困难，因为状态转移矩阵的第二大特征值与具体的图结构相关，且计算非常复杂。）\n\n","tags":["random walks","theoretical analysis","graph sampling","my work"]},{"title":"支持快速随机游走的大规模图分析系统研究--开题报告","url":"/2019/12/19/支持快速随机游走的大规模图分析系统研究-开题报告/","content":"\n## 研究背景\n\n### 大规模动态图并发图分析场景\n\n图因其可以很好地表达真实世界中实体之间的联系，而在许多领域的广泛应用，比如网页链接[1,2]、社交网络[3,4]、导航系统[5,6]和推荐系统[7,8]等。近年来，随着信息技术和人类社会活动的不断发展，图数据的规模也不断增大，例如很多网络图已经达到数十亿的节点和数千亿的边[9]。随着网络图数据的快速发展及普及，越来越多的大型图分析算法也不断涌现，用来，服务于各个行业，比如网页排序、市场营销、风投分析等。很多这些图分析算法可能并发地从不同方面去分析同一个底层图数据[10]，带来“并发图分析”。此外，图数据本身可能也在不断动态变化[11]，比如社交网络中注册新用户，添加新的好友关系等，带来“动态图分析”。真实世界的应用场景中，同一个数据平台上，超大规模的动态变化的图数据上可能并发地运行着各类图分析算法。\n\n### 基于随机游走的图分析\n\n面对这样大规模的图数据，很多迭代遍历的图算法由于过高的计算复杂度而难以实现，此时通过采样的方法来实现近似计算是一种可行的替代方案，其中基于随机游走的方法能够很好的表达很多算法。随机游走是图数据分析和机器学习中一个重要的分析工具，可以利用图中节点之间的集成路径提取信息，经常被应用于一些重要的图分析、排序和嵌入式算法中，比如个性化的PageRank[12,13]、SimRank[14]、DeepWalk[15]和node2vec[16]等。因而被广泛的应用于很多图分析场景中，例如个性化的PageRank[12,13]、相似性计算[14]、影响力传播[17]以及机器学习等一些其他应用场景[18-22].。近年来，学术界和工业界也有越来越多的工作关注随机游走，根据微软学术的统计结果，2018年就要大约1700篇学术论文是关于随机游走[23]，而工业界的很多大公司比如Facebook、谷歌、微软、阿里巴巴和腾讯等也都使用了随机游走相关的技术。\n\n基于随机游走的算法通常开始时同时启动多个随机游走，每个随机游走具有一定的行走长度，然后图数据系统利用它们的访问模式进行图数据分析。一个随机游走首先从一个初始节点开始，随机选择当前节点的一个邻居节点并跳转到该节点，重复上述过程直至满足预设的终止条件，比如随机游走达到一定的步长或者随机游走在每一步有一定的概率终止。\n\n### 应用案例——个性化的PageRank\n\nPageRank是Google著名的网页排序算法。而该算法一个更为复杂的版本是个性化的PageRank，即根据用户的个性化的偏好，进行个性化的网页排序推荐。通常PageRank算法是可以用幂法迭代进行计算，但是个性化的PageRank，尤其当要对很多用户甚至是全部用户同时进行个性化的PageRank算法计算时，用幂法迭代计算往往需要很高的时间和空间开销，对计算（尤其是大规模图数据上的计算）带来困难。\n\n此时基于随机游走的近似算法是个常用的替代算法，通过在图上模拟一定数量的随机游走，并统计图上各个节点被这些随机游走访问的概率，即可近似得到个性化的PageRank值。具体的算法如下：要计算图上一个节点的个性化的PageRank值，我们从该节点出发，模拟一条很长的基于重启的随机游走（random walk with restart），即随机游走在每一步以一定的概率回到初始节点。随机游走在走到一定的步数后会到达收敛状态，在其收敛以后，统计该条随机游走访问各个节点的访问频率，近似计算的得到该节点的个性化的PageRank值。\n\n为了达到收敛以保证近似计算的准确度，从该节点出发的基于重启的随机游走的步数通常需要很长，对于一些大规模的图数据，甚至需要成千上万步随机游走，这也给计算带来了很大的时间开销，尤其是针对基于磁盘的大规模图数据的处理场景。所以一种常见的做法是，将这一条很长的基于重启的随机游走，在其每次重启的地方切割，转换成很多条很短的随机游走，然后通过并发执行来提升计算效率。具体的算法执行过程可修改如下：要计算图上一个节点的个性化的PageRank值，我们从该节点同时出发很多条的基于重启的随机游走，并将每条随机游走的重启条件变成终止条件。这样我们就可以快速得到很多短的随机游走，我们统计这些随机游走对图中各个节点的访问频率，即可快速近似计算的得到该节点的个性化的PageRank值。理论上可以证明这种基于拆分拼接的方法不会带来任何计算误差。\n\n这种基于拼接的随机游走方法，将一条很长的随机游走的计算转换成了很多条短随机游走的并发计算，大大提升了计算效率。但与此同时，这种方法也给图上带来了大量并发的随机游走，尤其是需要同时计算多个节点的个性化的PageRank，甚至是同时计算所有节点的个性化的PageRank的时候，更是进一步加倍了图上并发的随机游走的个数。\n\n如何在大规模的图数据上进行这样大规模的并发随机游走？如何管理这样大规模的图数据和walk数据？目前有一些针对通用图算法的基于磁盘的单机图处理系统，但是这些系统在支持随机游走时可能会表现出一些局限性，比如I/O效率低，walk管理开销大等问题。所以需要一个支持快速随机游走的大规模图分析系统来支持这些基于随机游走应用的计算效率。\n\n### 复杂图分析场景带来的问题\n\n虽然基于随机游走的算法降低了图分析的时间复杂度，但是复杂的图分析场景依然给基于随机游走的图分析带来很多实现上的问题，主要包含以下几个方面。\n\n#### I/O是性能瓶颈\n\n这些超大规模的图数据很难放入一台机器的内存中，必须存储在磁盘上。由于图数据中节点之间连接紧密且复杂，会带来对磁盘的大量的随机I/O，而随机游走本身的随机邻居选择更增加了对图数据的访问的随机性。图3展示了一个样例图的随机游走对图中节点和边的随机访问过程。其中图3（a）表示样例图上的一个6步长的随机游走，游走轨迹为；图3（b）和图3（c）分别表示样例图的节点列表和边列表，图中的箭头代表访问数据的顺序。从图中可以看出，随机游走对图中节点和边的访问都会带来大量的随机访问。当这些数据放在磁盘上的时候，就会带来对磁盘的大量随机I/O。因此分析这些需要驻留在磁盘中的大规模图数据非常耗时，对于某些应用，需要运行几个小时甚至几天的时间才能得到一些计算结果。\n\n目前的图分析系统通常采用一种基于迭代的计算模型，当一个图太大而不能放入内存时，它们会根据顶点或边将整个图划分成许多区间，并将每个区间作为一个块存储在磁盘上。为了进行图形分析，他们采用了基于迭代的模型。在每个迭代中，一个块被依次加载到内存中，然后与加载的子图相关的分析被执行。通过这种方式，它们将大量的随机访问转化为对磁盘的一系列连续访问，大大降低一些算法的运算开销。但是我们发现这些基于迭代模型的图系统更适用于那些需要整个图数据的算法和应用，而不能有效地支持基于随机游走的图算法。原因有两个方面：（1）随机游走过程中的随机的邻居选择进一步加剧了算法对图数据的随机访问，且对各个子图分区访问很不均衡；（2）许多在线图数据查询算法也是基于随机游走实现的，此时随机游走只需要访问整个图数据的一部分，而基于迭代的模型迭代的加载整个图数据信息，在执行基于随机游走的算法时I/O效率不高。\n\n我们通过实验观察一个典型的图处理系统GraphChi[24]的I/O效率。我们定义I/O利用率为被随机游走使用的边数除以系统一次加载的图数据中的总边数，通过真实世界的数据集上的实验发现，GraphChi在Friendster数据集[25]上运行一亿条10步的随机游走，平均I/O利用率只有，当walk数目更少时，每次I/O的利用率将更低。这意味着每次系统花费很多时间读入大量的图数据块，但是其中真正被用来计算随机游走的部分却很少。而大量花费在I/O上的时间造成了整个计算过程的性能瓶颈。\n\n#### 并发图处理任务间相互影响性能\n\n很多基于随机游走的图分析算法可能并发地从不同方面去分析同一个底层图数据，带来“基于随机游走的并发图分析”。根据一个真实大型社交网络平台的追踪结果，平均就有大约10个并发图处理任务提交到这一个公共数据平台，分发的分析同一个图数据，而在峰值的时候更是有超过20个并发图分析任务[10]。\n在并发图分析场景下，各个并发图分析任务之间竞争CPU、I/O及内存等资源，并且相互干扰缓存，所以各并发图分析任务的性能都会因为相互影响而下降。图4展示了四个基于随机游走的图分析任务的标准化后的执行开销，从中可以看出，将四个算法并发执行后，总的时间开销有一点点下降，但是单个图分析任务的时间开销却显著增加。并且CGraph[10]中指出，随着并发图分析任务的数量的进一步增加，各个图分析任务的平均执行时间进一步显著延长，而他们延长的时间开销主要来源于更高的数据访问成本。\n\n#### 动态图场景下响应不及时\n\n现实中的很多应用场景都是动态图场景，比如网页链接中插入新网页、电商平台用户购买产品、社交媒体中删除推文和社交网络中好友取消关注等，都会带来节点和边的插入或删除，造成图结构的改变。而一般动态图的处理场景图大多是一种在线实时的处理场景，往往需要实时得到反馈。但目前来说，大多数系统考虑的是静态图的处理场景，不能很好的支持动态增量图数据的实时插入和更新。一种通用的方式是采用快照的方式单独存储动态图场景下的增量数据，即静态图数据与动态增量图数据分离存储。这种方式虽然能很快的插入图数据的更新信息，但是在进行图分析计算时，需要分别访问静态图数据以及动态增量图数据，造成额外的查询开销，影响分析计算的性能。\n\n### 国内外研究现状和发展趋势\n\n近年来，人们提出了许多图形系统，来提高这种大规模图数据的分析性能。其中有一部分是基于分布式集群的图处理，比如[26-34]。然而，分布式图数据系统通常需要高效的图数据划分和机器之间低成本的通信和同步。另一种做法就是将大规模的图数据存放在单个机器的磁盘上，比如HDD或SSD，并通过合适的存储模型、I/O调度策略和计算模型，在单机上也能实现对大规模图数据很好的处理性能。因此，基于单机的磁盘驻留图的图处理系统也备受关注[24,35-43]。接下来，我们分别介绍这些单机图处理系统在I/O性能优化、并发图分析优化和动态图场景优化这三个方面的研究现状和发展趋势。\n\n#### I/O与计算性能优化\n\n针对图分析算法对磁盘驻留图的大量随机I/O问题，很多基于磁盘的单机图处理系统提出I/O优化方法。GraphChi是这类工作的先驱，我们首先以GraphChi[24]为例介绍这类工作的存储和计算过程。\n\n1. **图的划分与存储**，当图数据太大，无法放入内存时，GraphChi将所有顶点分割成P个不相交的区间，并为每个区间与关联一个”shard”，存储目标顶点位于此区间内的所有边。每个shard中的边根据它们的源顶点ID进行排序。图5(a)显示了图3(a)中的示例图的shard的数据组织。\n\n2. **子图加载**，GraphChi每一次将一个区间节点所对应的子图加载到内存中进行分析。为了加载子图，它首先从相应的shard加载入边，然后从其他P – 1个shard中加载出边，如图5(b)所示。由于在每个shard中都是根据源顶点来对边排序的，所以总共只需要P个连续的磁盘读取来加载一个区间对应的子图。通过这种方式，GraphChi将对磁盘的随机访问转换为一系列连续的访问，极大地提高了磁盘驻留图数据处理的性能。\n\n3. **子图上的分析计算**，GraphChi使用一个以顶点为中心的计算模型，该模型在Pregel中首次提出[38]。它遍历所加载的子图上的所有顶点，对于每个顶点v，首先从v的入边收集（Gather）信息，然后执行（Apply）顶点v上定义的更新函数f(v)，最后将更新后的信息通过出边散播（Scatter）出去，这种方法也被称为以顶点为中心的GAS计算模型。另一个计算模型是X-Stream[44]中提出的以边为中心的模型，它通过遍历边来工作。图6分别展示了以点为中心的计算模型和以边为中心的计算模型，这是分布式和单机图处理系统中最常用的两种模型。\n\n4. **基于迭代的子图调度**，为了同步各个节点上计算任务的进度，GraphChi使用基于迭代的模型加载所有的子图，在GraphChi中称为并行滑动窗口(parallel slide window, PSW)，如图5(b)所示。在每个迭代中，它按顺序循环加载子图，这保证了整个图上所有计算任务之间的同步。这种基于迭代的模型在许多图数据系统中得到了广泛的应用。\n\n随后，有很多研究工作在GraphChi的基础上进一步优化基于磁盘的单机图处理的性能。X-Stream[35]通过将对图数据的存储转化为边数据流的方式，进一步减少了随机I/O，并且避免了对边数据排序的巨大开销。GridGraph[36]提出一种二维图划分的方式，并采用双重滑动窗口的方式对边进行流处理。FlashGraph[37]是一个半外核的图系统，它将顶点数据存储在内存中，将边数据存储在用户空间的flash文件系统中，以提高小型I/Os的性能。ODS[38]提出使用动态分区来调整图数据的布局。CLIP[39]采用了复用已加载子图的思想，充分利用了每一个I/O。Graphene[40]通过采用I/O中心计算模型和基于位图的异步IO技术优化了I/O管理。GraFBoost [41]和V-Part [42]利用高性能的新兴设备进行存储或计算来进一步提升基于磁盘的单机图处理系统的性能。\n\n上述所有图系统都采用基于迭代的I/O模型，迭代地加载磁盘上的所有图数据分区，在每轮迭代中，顺序地加载所有需要的分区一次。但是，由于随机游走步骤中随机邻居的选择加剧了对图数据的随机访问，且造成各个子图分区之间的访问非常不均衡，均匀的加载每个子图并不是一个合适的方式；另外许多在线图数据查询算法也是基于随机游走实现的，此时随机游走只需要访问整个图数据的一部分，迭代的加载所有图数据更造成大量的无效I/O。所以，这种基于迭代的I/O模型不能有效地支持基于随机游走的图算法。\n\n#### 并发图分析优化\n\n为了多任务并发的图处理场景下，各个并发图分析任务之间竞争CPU、I/O及内存等资源导致的相互干扰的问题，目前也有几个研究工作专门针对多任务并发的图处理场景的优化。Seraph[44]通过数据解耦的方式，允许多个并发图分析任务共享内存中的图数据，通过减少内存需求提高并发图分析任务的吞吐率。CGraph[10]进一步挖掘各个并发图计算任务之间的关联性，并采用一种以数据为中心的LTP（load-trigger-pushing）模型来进行图数据的调度和各个图分析任务的并发计算。图7展示了CGraph的以数据为中心的LTP计算模型，包含加载（Load）图分块、触发（Trigger）各图处理任务的并发执行和数据推送（Pushing）实现master和mirror的状态同步三个阶段。\n\n1. **加载图分块**，CGraph首先实现图结构数据和图处理任务状态数据的分离。图结构数据为所有并发图计算任务的共享数据，各图处理任务分别有一个状态数据。图结构数据被划分为多个块存储，CGraph采用切割节点的方式，所有的边被均匀划分到不同的分块，跨越不同分块的节点建立master和mirror。CGraph每次加载一个块的共享图数据进入内存进行计算。\n\n2. **触发各图处理任务的并发执行**，CGraph加载一个子图分区进入到内存以后，在该图分区上有计算任务的图处理任务进行并发计算。当要并发处理的任务数量大于CPU的核数时，这些并发图处理任务被分配为不同的批处理。\n\n3. **数据推送实现master和mirror的状态同步**，CGraph在计算处理一个图分块时，是没有cache miss的，因为不同的图分块的节点之间是没有通信的。但是在不同图分块上，具有副本的顶点需要同步它们的状态。mirror节点需要推送（push）它的新状态到它的master节点，master节点获取到来自所有mirror节点的状态更新之后计算出当前轮最终的状态值，并推送到各个mirror节点。在这样的节点状态同步的过程中，私有状态表的许多图分区经常被加载到缓存中，导致较高的cache miss率。为了解决上述问题，CGraph将每个mirror节点的更新状态保存到一个缓冲区中。在数据同步阶段再隐式发送到master节点以进行批量顶点状态同步。\n\n为了提高每个加载的图分块的利用率，CGraph还提出一种基于核心子图的调度算法：首先筛选出所有的核心节点（度数大于某阈值的节点）以及他们之间的连接边，构成一个核心子图；然后将这个子图的边放到几个大小相同的图分块中，其余的边被划分到其他大小相同的图分块中。这样，对核心节点的频繁加载和处理，带来的对相同分区中早期收敛顶点的加载开销更小。然后，CGraph给每个图分块一个优先级，优先调度优先级更高的图分块进入内存进行处理。（1）当大多数任务需要对一个块进行处理时，给它更高的优先级；（2）当一个块有更高的平均度或者更多的节点状态更新时，给它更高的优先级。具体的优先级的值设置为。通过这种方法，加载到缓存中的图分块可以服务尽可能多的图处理任务，而其他图分块在一段时间间隔后有更多的机会被更多的任务需要，通过降低平均数据访问成本进一步提高了吞吐量。\n另外，最近也有一些工作专门被提出用于支持对图数据的并发查询。例如，TAO[45]提供了一个简单的数据模型来存储和查询图形数据。Wukong[46]使用一种基于RDMA的方法，提供大规模RDF图数据集上的低延迟并发查询。\n上述几个针对并发图处理场景的工作虽然能很好地降低平均数据访问成本，提升总的并发图执行运行性能。但是依然存在一定的局限性，比如Seraph和CGraph更适用于需要迭代地处理整个图数据很多轮的重负载的图计算任务，轻负载的图查询任务由于只访问一小部分图数据而将长时间处于等待状态，响应时间将大大增加。而TAO和Wukong等图查询引擎又不适用于重负载的图计算任务。所以对于计算与查询混合的应用场景，上述系统不能实现很好的支持。\n\n#### 动态图存储优化\n\n近年来最常用的一种存储图数据的方式为压缩稀疏行，即CSR（Compressed Sparse Row）。CSR使用两个序列来存储图数据，CSR序列用来顺序存储每个节点的出边邻居的ID，beg_pos序列用来存储每个节点在CSR序列中开始位置。图8直观地展示了CSR存储格式的数据表示以及数据查询方式。其中图8（a）为样例图；图8（b）为它的边列表表示；图8（c）为它的CSR表示，CSR序列中顺序写入各节点的出边邻居，分别为1和2、有3、0和3、1和2，beg_pos序列中顺序写入各节点在CSR序列中的开始位置分别为0、2、3、5，最后再加上一个总边数7。通过这种方式，CSR存储格式将一个图数据的存储开销减少到，相比之下邻接矩阵的存储开销高达。同时，CSR存储格式的查询开销也很低，比如查询节点2的邻居节点，只需要首先访问beg_pos序列中第二个值和第三个值，分别为3和5，我们就可以得知CSR序列中区间存储的是节点2的邻居，读取得知为节点0和节点3。由于其很低的存储开销和查询访问开销，CSR存储格式被广泛地应用于各个图分析系统中。\n\n但是，CSR存储格式只适用于静态图的存储。在动态图场景下，当有新的节点或边数据插入时，想要融入增量图数据，CSR需要重构CSR序列和beg_pos序列的存储内容。而当不断有增量数据插入时，重构的开销就非常大，在真实的场景中往往难以实现。\n\n现在的图处理系统中往往采用一种快照的方式，将静态图数据与动态插入的增量图数据分开存储。这种方式虽然能很快的插入图数据的更新信息，但是在进行图分析计算时，需要分别访问静态图数据以及动态增量图数据，造成额外的查询开销，影响分析计算的性能。而且随着增量图数据的不断增加，也越来越难以维护，存储和计算开销都将变得越来越困难。\n\n#### 基于随机游走的系统优化\n\nWalk信息的管理成本也限制了图系统在运行随机游走时的效率。由于每个顶点上的行走数是动态的，不可预测的，所以在当前的图数据系统中，walk数量通常是用大量的动态数组来存储的，例如，GraphChi[24]以边为单位管理walk数据，也就是说，每个边关联一个动态数组，存储当前通过它的walk。这种设计会产生很大的内存开销，例如，要在YahooWeb数据集（14亿个顶点，66亿个边）上运行一些随机游走，仅仅存储该图上walk的动态数组的索引信息就至少需要26.4 GB。其他一些图系统可能使用以顶点为单位来管理walk信息，但它仍然会带来较高的内存成本，例如，也需要5.6 GB的内存来存储YahooWeb[47]这样的中等规模的图上的walk的动态数组的索引信息。在加上walk本身的数据信息，将大大占用内存开销，限制了这些图处理系统能够支持的图数据的规模以及上面能支持的随机游走的规模。\n\nDrunkardMob[13]将每个walk编码为32位或64位数组，并将相邻128个顶点的walk放入相同的walk缓冲区中，以减少walk索引的总大小，如图9所示。它有效地将walk索引的大小减少到以节点为单位的管理方式的1/128，例如，YahooWeb只有44.8 MB。然而，DrunkardMob中的每个行走缓冲区还是由一个动态数组管理的，这仍然对计算造成了限制。首先，对于大规模图图数据，DrunkardMob需要创建了太多的动态数组，例如，为YahooWeb创建了1120万个动态数组，这会导致频繁地重新分配内存，不仅引入了内存片段，而且带来了额外的时间成本，限制了可分析的图数据的规模。其次，DrunkardMob将所有的walk保存在内存中，由于与walk索引相关的文件太多，将它们刷新到磁盘的成本非常高。因此，DrunkardMob能够分析的walk的规模也是有限的。\n\n最近于2019年SOSP上提出的KnightKing[23]，是一个专门的随机游走图系统。KnightKing主要针对复杂的动态随机游走（即随机游走的每一步的邻居选择的概率是根据walk状态变化的）提出一种拒绝采样的策略。拒绝采样开始用于通用的任意概率的采样，将一个一维的采样过程转换成一个二维的采样过程。具体对应到随机游走的边采样过程为：随机地产生一个位置，其中是从当前节点的出边中均匀随机选取的一条边e，，其中是当前节点的出边的动态转移概率的最大值。当，则e被接收，当前walk通过e跳转。否则，e被拒绝，需要重新采样并重复上面过程，直至walker成功跳转。通过拒绝采样的方式，消除了对当前节点所有出边的访问去获取他们的转移概率。一般只需要几次尝试就可以成功采样一条边（复杂度为）。大大减少了对高度节点的采样开销。图10展示了KnightKing中的拒绝采样，其中图10（a）展示了一个样例图以及当前walk在节点v对各个边的动态转移概率，图10（b）展示了当前walk在节点v的拒绝采样过程。\n\nKnightKing主要是针对复杂随机游走中随机邻居选择的优化，没有考虑太多系统层面的存储管理、I/O调度以及计算框架等方面的优化。存储管理方面，KnightKing也没有专门针对walk数据管理的优化，walk数据的索引开销依旧很大；I/O调度方面，KnightKing底层还是沿用现有系统中的基于迭代的计算模型，导致支持随机游走的应用时I/O的效率还是不高。\n\n## 研究内容和研究方法\n\n### 主要研究内容\n\n考虑到随机游走的广泛应用场景，本报告拟研究基于随机游走的大规模图分析系统。具体地，针对基于磁盘的单机图处理场景，向下支持大规模的图数据，向上支持基于随机游走的图算法及应用。如图11所示，研究内容分三个层次来实现，分别存储管理与计算框架、并发图处理优化和动态图处理优化。其中存储管理与计算框架针对静态图下单任务的场景，实现对大规模图数据下的随机游走的系统支持，并发图处理优化和动态图处理优化分别针对多任务并发图处理场景和动态增量图处理场景进行进一步的优化支持。\n\n#### 存储管理与计算模型\n\n本报告首先考虑一种相对简单的静态图下单任务的随机游走图分析场景，拟设计对随机游走的存储管理与计算模型的支持。如图12所示，本报告拟开展下面三个方面的研究，图数据与walk数据的分离存储管理、walk状态感知的按需调度策略和以walk为中心的计算框架。\n\n1. 考虑随机游走中walk数据分布的动态性和不均衡性，以节点或边为单位的walk数据管理会带来巨大的动态数组索引开销。因此本报告拟设计图数据与walk数据的分离存储管理，以最小化图数据和walk数据的存储和 管理开销。\n\n2. 考虑基于迭代的I/O模型在支持随机游走时会带来严重的I/O不高效的问题，本报告拟根据图中各个随机游走的状态，设计walk状态感知的按需调度策略，每次从磁盘调度最需要的图数据块进入内存，以保证最优的I/O效率。\n\n3. 为了最大化每次I/O的利用率，本报告拟设计一种I/O效率最大化的计算框架，使得能够充分利用每次I/O加载的子图数据，尽可能多地进行walk的转发，直至所有walk都跳出该子图为止。这样可以进一步提升每次I/O的效率，减少总的I/O次数，提升基于随机游走的图分析性能。\n\n#### 并发图处理优化\n\n基于上面针对随机游走的存储管理和计算框架的优化，本报告进一步考虑多个基于随机游走的应用并发处理的场景，优化多任务并发图处理的性能。如图13所示，本报告拟开展以下研究。\n\n1. 考虑多个并发的随机游走图分析任务中可能存在重复的随机游走任务，本报告拟设计一种walk共享的机制，考虑不同的算法可能会产生一些不同类型的随机游走，设计随机游走的分类共享，即同一类型的随机游走之间实现复用，以减少随机游走的存储和计算开销。\n\n2. 对于同一类型的随机游走任务，检测它们之间随机游走的重复部分，设计walk任务的去重派发方案，实现多并发图处理任务之间的walk共享，并在计算完成之后分别反馈相应的计算结果。通过这样walk共享的实现，提升总体图分发任务的运行性能。\n\n3. 考虑基于随机游走的图分析任务之中同时包含需要全局计算的图计算任务和只针对局部图数据的查询任务，为了实现对这两类应用的混合支持和及时响应，拟设计一种查询计算混合应用的均衡调度策略，在提高整体运行性能的情况下，提高单个图分析任务的运行性能。\n\n#### 动态图优化\n\n本报告进一步考虑大规模动态变化的图数据场景，优化动态图上的图处理的性能。如图14所示，本报告拟开展以下研究。\n\n1. 考虑键值（KV，key-value）存储系统可以支持数据的快速插入和查询，本报告拟设计基于KV的图存储结构，以实现对大规模动态图数据中节点和边数据的存储管理。\n\n2. 基于KV的图存储结构，拟设计对动态增量图数据的插入合并方案，实现对图中节点和边数据的快速插入或删除。\n\n3. 基于KV的图存储结构，拟设计对图数据的快速查询访问机制，以支持上层图分析任务的快速执行。\n\n### 研究目标\n\n本项目拟研究基于随机游走的大规模图分析系统，拟达到以下研究目标：\n\n1. 设计图数据和walk数据分离存储管理策略，减少walk数据的存储开销到原来的20%，使得留出更多的内存空间，可以用来存放更多的图数据和walk数据，使得系统能够支持数十亿节点、数千亿边的大规模的图数据，以及能够支持数百亿条、长达数万步的并发执行的大规模随机游走；\n2. 设计walk感知的按需调度策略以及I/O效率最大化的计算框架，提高每次I/O的利用率至少到原来的2倍，使得一次I/O能进行更多的walk转发，加速随机游走的进程，提高算法的执行效率；\n3. 设计基于walk共享的随机游走并发图处理机制，减少walk数据的总量到原来的80%，从而减少整体存储和计算的开销，提升基于随机游走的并发图处理的性能。\n4. 设计基于key-value的动态图存储管理策略，减少动态增量图数据的合并时间到原来的50%，同时实现高效的数据查询访问，以支持动态图场景下的快速图分析处理。\n\n###  研究方法与技术路线\n\n#### 存储管理与计算框架\n\n面对基于磁盘的大规模图数据，首先需要设计图数据的划分方式和存储格式，使得每次加载的一个子图数据能够放入内存，以支持后续的计算；其次，针对随机游走产生的walk数据，需要设计轻量级的walk存储格式和索引查询；然后，需要根据当前图中walk的状态，设计walk感知的按需调度策略，加载一个最合适的子图数据块进入内存；最后，为了尽可能地提高每次I/O的利用率，需要设计I/O效率最大化的计算框架来利用加载子图数据进行walk的转发计算。按照上述技术路线，本报告拟按以下方法开展研究：\n\n1. **设计图数据的存储格式和划分方式**：为了最小化图数据的存储开销，拟采用压缩行矩阵（CSR）的存储格式来存储图数据，即所有节点的出边邻居顺序存放到一个CSR文件中，并再使用一个index文件来存储每个节点在CSR文件中的开始位置。以此为基础，本报告拟设计一个轻量级的图划分方式，根据顶点ID将图划分为很多图数据块。具体地，按照顶点ID的升序顺序，将该节点及其出边邻居添加到当前图数据块中，直到块中的数据量超过预定义的块大小，然后创建一个新块。图15展示了图3（a）中的样例图在该方案下的数据布局。这种图划分方案只需要一次性的遍历读取index文件即可完成，并且只需要记录每个图数据块的开始节点ID。所以图划分的计算和存储开销都非常低，是一种非常轻量级的图划分方式。\n\n2. **设计walk数据的存储结构和索引管理**：为了最小化每个walk的存储开销，拟采用一种压缩的64位long类型的数据结构来存储一条walk，记录关于这个walk的始发节点（source）、当前节点（current），步长（step）这三个变量的信息，具体位分配如图7中所示。然后，为了减少walk数据的索引开销，拟设计一种以块为中心的walk管理机制，对于每个图数据块，在内存中采用一个定长的walk buffer来存储当前落在该图数据块的所有walk，当该图数据块的walk数量超过buffer的长度时，再将该walk buffer的所有walk都追加写到磁盘上与其对用的walk pool中。图16展示了walk数据的存储结构和索引管理策略。这种方式下，存储walk内存开销只有定长的walk buffer，可以通过控制buffer长度来严格控制。\n\n3. **设计walk感知的按需调度策略**：为了提高I/O效率，拟设计一种按需加载策略来管理图数据块的I/O调度，具体的，首先记录每个图数据块中的walk数，并将其称为walk需求，每次加载需求最大的那个图数据块进入内存。这种随需应变的图加载策略使得通过一次I/O，能够让最多的walk向前移动最少一步，因此可以提高I/O的利用率。图17展示了图数据的按需加载策略。\n\n4. **设计I/O效率最大化的计算框架**：为了使每次加载的图数据能够被充分利用，拟设计一种以walk为中心的计算框架。对于每个walk，允许它尽可能向前转发，直到到达当前图数据块边界为止。完成一个walk后，选择另一个walk来处理，直到所有的walk都被处理完成，然后根据前面描述的按需调度的方式加载另一个图数据块进行处理。为了加速计算，拟采用多线程在walk之间并行计算。图18展示了以walk为中心的计算框架。\n\n#### 并发图处理优化\n\n面向多任务并发的随机游走图处理场景，考虑多个并发的随机游走任务之间可能存在大量重复的walk任务，图19展示了四个典型的随机游走算法的walk计算任务，它们之间有很多重叠部分，这部分的walk数据实际上可以实现共享复用，以大大减少各个基于随机游走的图分析任务的计算开销。本报告拟按以下技术路线开展研究：\n\n1. **设计随机游走的分类共享策略**：首先我们需要分析哪些图分析任务的随机游走之间可以实现共享复用，以此为基础对随机游走任务进行分类，本报告拟采用一种按照随机游走的随机邻居的选择时的不同选择概率进行分类的策略，拥有相同的随机邻居选择策略的随机游走任务之间实现walk的共享复用。\n\n2. **设计walk任务的去重派发机制**：基于随机游走的分类共享策略，本报告拟设计一种基于共享的walk去重派发机制，避免共享walk的重复计算，并在计算完成之后分别反馈相应的计算结果。图20展示了四个典型的随机游走算法在去重后派发到随机游走引擎的共享walk任务。\n\n3. **设计查询计算混合应用的均衡调度策略**：针对查询和计算混合的应用场景，本报告拟设计一种轻量级查询任务友好型的均衡的共享图数据的调度策略，减轻轻量级查询任务的饥饿等待的问题，以实现各单个任务的及时响应策略。\n\n#### 动态图处理优化\n\n面向动态变化的大规模图处理场景，为了同时实现动态增量数据的快速插入合并以及图分析任务对图数据的快速访问，本报告拟按以下技术路线开展研究：\n\n1. **设计基于KV的图存储结构**：为了能支持大规模动态图数据的快速插入和查询，本报告拟设计一种key-value的图存储结构，如图21所示，其中key是节点的ID，进行节点的唯一标识；value包含该节点的总邻居数以及各个邻居节点的ID。\n\n2. **设计动态增量数据的插入合并**：基于设计的key-value的图存储结构，本报告拟设计动态增量数据的插入合并，具体地，添加或删除一个节点只需要删除一个KV对，添加或删除一条边只需要修改相应KV对的值。\n\n3. **设计图数据的访问查询机制**：基于设计的key-value的图存储结构，本报告拟设计对图数据的快速访问查询机制，例如快速查询一个节点的邻居信息，以支持上层图处理任务对图数据的快速分析，得到计算结果。\n\n### 可行性分析\n\n1. **在存储管理与计算框架方面**：拟设计如图22所示的基于随机游走的图分析系统。为实现内存容量受限的情况下的大规模图数据处理，设计基于CSR的压缩图存储格式并将图数据划分成多个数据块存在磁盘，每次加载一个块进入内存进行处理；为了减少动态不均衡的walk数据的索引开销，设计以图数据块为单位的walk管理策略，存放当前落在该子图数据块的所有walk信息，并在内存中使用一个定长的walk buffer来存储，将超出buffer长度的walk信息信息也保存在磁盘上，以控制walk数据的内存开销；为了最大化I/O效率，设计按需调度图数据块的策略，根据当前图中walk的分布状态，加载需求最大的图数据块进入内存，以保证最多的walk能进行至少一步的转发；为了最大化每一次I/O的利用率，设计以walk为中心的计算框架，以walk为单位进行转发更新每一条walk，持续向前移动walk直至到达当前子图的边界。系统架构的设计从存储管理到I/O调度再到计算框架，自下向上提供支持，使得整个系统架构的设计是合理的，且在技术实现上也是可行的。\n\n2. **在并发图处理优化方面**：通过分析多种典型的基于随机游走的图算法可知，不同分析任务之间存在大量的walk冗余，所以设计基于walk共享的随机游走并发图处理策略是合理的，且预期能带来一定的性能提升；按照随机游走的随机邻居的选择时的不同选择概率对不同随机游走处理任务进行分类，同一类的随机游走在理论上是可以被共享复用的。\n\n3. **在动态图处理优化方面**：基于key-value的存储系统由于能实现对数据的快速插入和查询访问而被应用于现实的很多场景中。通过将动态变化的图数据存储为基于KV的存储结构，能够实现对增量图数据的快速插入合并，同时支持上次图分析任务对图数据的快速查询访问。同时，本人所在的课题组有一个小组专门做key-value的存储系统的性能优化，所以结合组里的现有研究工作，能更快的设计针对动态图场景下的KV优化策略。\n\n## 创新点\n\n本报告的特色之处在于着手于图分析上一类重要的应用场景——基于随机游走的图分析场景，并从系统设计的角度出发， 研究大规模图数据上随机游走的性能优化。下面分别从研究内容、拟采用的研究方法和技术路线这三个方面来介绍本报告的创新之处。\n\n1. **研究内容的创新**：不同于以往的通用图分析处理系统的设计优化，本报告着手于随机游走这一类算法的系统设计优化，通过研究图数据和walk数据的存储管理、I/O调度以及计算模型等方面优化大规模图数据上的基于随机游走的图分析的性能。 \n\n2. **技术路线的创新**：考虑现实世界中图分析应用中存在数据规模大、多任务并发图处理、图数据不断动态变化等复杂的应用场景，本报告采用循序渐进的研究技术路线，首先考虑静态图下单任务的随机游走图处理场景，进行存储管理和计算框架的优化；然后考虑考虑现实应用中的多任务并发的图处理场景，本报告进一步研究并发随机游走图处理的优化；最后考虑实应用中的动态变化的大规模图处理场景，本报告进一步研究动态图处理的优化。\n\n3. **研究方法的创新**：考虑现有图处理系统中的基于迭代的I/O模型对随机游走的支持呈现I/O效率差的问题，本报告拟采用按需I/O调度的方法，并结合存储管理和计算框架的优化，提升随机游走在图处理系统中的I/O效率，从而提升计算性能；考虑基于随机游走的并发图处理的多任务之间存在很多的walk重叠，本报告拟采用walk共享的方法实现walk复用从而提升计算性能；考虑动态变化的大规模图数据场景下，增量数据维护困难的问题，拟采用基于KV的动态图数据的存储管理，实现对增量图数据的快速插入合并，且支持上层应用对更新后的图数据的快速查询访问。","tags":["random walks","graph processing system","my work"]},{"title":"NBRW(SIGMETRICS 2012) 不回溯的无偏图采样","url":"/2019/12/15/NBRW-SIGMETRICS-2012-不回溯的无偏图采样/","content":"\n[Lee, Chul-Ho, Xin Xu, and Do Young Eun. \"Beyond random walk and metropolis-hastings samplers: why you should not backtrack for unbiased graph sampling.\" ACM SIGMETRICS Performance evaluation review. Vol. 40. No. 1. ACM, 2012.](http://delivery.acm.org/10.1145/2260000/2254795/p319-lee.pdf?ip=222.195.68.252&id=2254795&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EA4F9C023AC60E700%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1576408507_9dea440cf445046ba6683f1b18b61c97)\n\n### 无偏图采样\n\n#### 无偏图采样技术\n通过爬行的无偏图采样技术，是指通过一个或多个在图上爬行的随机游走，进行的均匀节点采样，最终分析估计目标图的节点或者拓扑特性。具体来说，无偏均匀图采样即对于任意给定的一个满足均匀分布的期望函数$f$，即$E_u(f) \\stackrel{\\Delta}{=} \\sum_{i\\in N}{f(i)/n}$，开发一个基于随机游走的无偏估计器。（一个图上的随机游走，若其状态转移矩阵P满足不可约的特性，则该随机游走所表示的马尔可夫链存在唯一的一个稳态分布$\\pi$。）\n\n#### 基于随机游走的无偏图采样\n\n对任意一个函数$f$，可以定义一个基于随机游走的估计器：$\\hat{\\mu}_t(f) \\stackrel{\\Delta}{=} \\frac{1}{t} \\sum_{s=1}^t{f(X_s)}$,\n\n函数$f$关于$\\pi$的期望为$E_{\\pi}(f) \\stackrel{\\Delta}{=} \\sum_{i\\in N}{f(i)\\pi(i)}, E_{\\pi}(|f|)< \\infty$。\n\n**强大数定理（SLLN, Strong Law of Large Numbers）**保证了，当$t \\rightarrow \\infty$，$\\hat{\\mu}_t(f) \\rightarrow E_{\\pi}(f) a.s.$。\n\n#### 不同随机游走采样的评判指标\n\n一个图上的很多种随机游走可能都能达到同一个稳态分布$\\pi$，可以用来进行相同的无偏估计，如何去评判哪一种基于随机游走的采样算法更好呢？\n\n**混合时间（mixing time）**是刻画图上随机游走收敛速度的一个重要指标，适合用来比较不同的随机游走。\n\n但是混合时间（mixing time）却不适合用来比较不同的随机游走采样，因为基于随机游走的采样虽然通常是需要经历一个时期进行收敛（burn-in period），以消除初始节点的影响，但是在随机游走收敛之后，仍然需要获取很多样本从而进行无偏估计。所以，对于基于随机游走的无偏图采样来说，估计器的效率，即在保证一定精度的情况下，所需要的最少的**样本的数目**才是最重要的评判指标。\n\n#### 渐进方差\n\n定义上述基于随机游走的无偏估计器的渐进方差\n\n$$\\sigma^2(f) \\stackrel{\\Delta}{=} lim_{t \\rightarrow \\infty} t \\cdot Var(\\hat{\\mu}_t(f))$$\n\n**极限中心定理（CLT, Central Limit Theorem）**表明$\\sigma^2(f)$是$\\hat{\\mu}_t(f)$的方差，可以根据$\\sigma^2(f)$来决定，在保证一定精确度的情况下所需要的采样样本的数目。$\\sigma^2(f)$值越小，则对应的基于随机游走的无偏估计器的效率就越高，即在保证相同精确度的情况下所需要的样本数目越少。\n\n**该篇论文的目标：通过减小$\\sigma^2(f)$的值来减少基于随机游走的无偏估计器所需要的样本数目。**\n\n### 基于随机游走的采样算法\n\n#### SRW-rw\n\n在图上进行简单的随机游走（SRW, Simple Random Walk），其访问的节点序列组成一个马尔可夫链${X_t}$，其对应的状态转移矩阵为$P={P(i,j)=\\frac{1}{d_i}}$，稳态分布为$\\pi={\\pi(i)=\\frac{d_i}{2m}}$。\n\n根据随机游走获取的样本进行无偏估计，可以设置无偏估计的权重$w(i)=\\frac{u(i)}{\\pi(i)}=\\frac{2m}{nd_i}$，则无偏估计器为\n\n$$\\hat{\\mu}_t(wf) \\stackrel{\\Delta}{=} \\frac{1}{t} \\sum_{s=1}^t{w(X_s)f(X_s)}$$\n\n当$t \\rightarrow \\infty$，$\\hat{\\mu}_t(wf) \\rightarrow E_{\\pi}(wf) = E_{u}(f) a.s.$。\n\n但是，由于$n$和$m$在很多场景下是未知的，所以$w(i)=\\frac{2m}{nd_i}$无法计算，所以可以使用另一种替代的无偏估计的方法：\n\n$$\\frac{\\hat{\\mu}_t(wf)}{\\hat{\\mu}_t(w)} \\stackrel{\\Delta}{=} \\frac{\\sum_{s=1}^t{w(X_s)f(X_s)}}{\\sum_{s=1}^t{w(X_s)}}$$\n\n此时，可以设置$w(i)=\\frac{1}{d_i}$，计算结果相同。\n\n#### MHRW\n\n主要思想：调整随机游走的状态转移概率，使得其马尔可夫链对于的稳态分布$\\pi=u$。\n\n**（1）MH（Metropolis-Hastings）算法**\n\nMH算法首先设置一个**建议概率（proposal probability）$Q(i,j)$**（$Q(i,j)>0$当且仅当$Q(j,i)>0$，即只给与互为邻居的节点之间正的转移概率），然后建议状态过渡到$X_{t+1} =j$后以一定的**接受概率（acceptance probability）$A(i,j)$**接收该次转移，$A(i,j)= min(1,\\frac{\\pi(j)Q(j,i)}{\\pi(i)Q(i,j)})$。最终，MH算法真实是状态转移概率为：\n\n$$P(i,j)=min(Q(i,j),Q(j,i)\\frac{\\pi(j)}{\\pi(i)}$$\n\n**（2）MHRW采样**\n\n设置建议概率$Q(i,j)=\\frac{1}{d_i}$，则状态转移概率为$P(i,j)=min(\\frac{1}{d_i},\\frac{1}{d_j}), if (i,j) \\in E$。\n\n上述状态转移矩阵所对应的是一个时间可逆的马尔可夫链，所以$\\pi_iP_{ij}=\\pi_jP{ji}$，又因为$P_{ij}=P{ji}$，\n\n$\\Rightarrow \\pi_i=\\pi_j, if (i,j) \\in E$，\n\n$\\Rightarrow \\pi_i=\\frac{1}{n}$，\n\n$\\Rightarrow \\pi=u$。\n\n#### 存在问题 & Idea\n\n存在问题：SRW和MHRW都容易回到之前一步访问过的节点，导致短时间内产生重复样本，带来较大的渐进方差。\n\nIdea：修改随机游走的状态转移概率，避免回到前一步访问过的节点。\n\n待解决的的挑战：1）如何保证不改变原本的稳态分布；2）如何实现最小的额外开销；3）证明能减小采样算法的渐进方差。\n\n### 避免回溯的随机游走图采样\n\n#### 从可逆到不可逆\n\n若要实现不回溯的随机游走，随机游走的下一跳选择不仅取决于当前节点，还取决于上一步的节点，所以在状态空间$N$上的不回溯的随机游走，不再是一般意义上的马尔可夫链了。\n\n构建新的状态空间$\\Omega \\stackrel{\\Delta}{=} ( (i,j), i,j\\in N, s.t. P(i,j)>0 )$， 其中一个状态表示为$e_{ij}$。在状态空间$\\Omega$上构建新的马尔可夫链，对于的状态转移概率和稳态分布分别表示为$P'(e_{ij},e_{jk})$和$\\pi'(e_{ij}$。\n\n如果新的马尔可夫链满足：$\\pi'(e_{ij}=\\pi(i)P(i,j)$，且原来的马尔可夫链是时间可逆的，则$\\pi'(e_{ij})=\\pi'(e_{ji})$。\n\n且新的马尔可夫链在达到稳态分布时，停留在节点$j$的概率就等于原马尔可夫链的概率$\\pi(j)$，即：\n\n$$\\sum_{e_{ij}\\in \\Omega}{\\pi'(e_{ij})} = \\sum_{i \\in N}{\\pi(i)P(i,j)}=\\pi(j)$$\n\n我们可以利用新的马尔可夫链进行无偏采样：令$g(e_{ij})=f(j)$，则$E_{\\pi'}(g)=\\sum_{e_{ij} \\in \\Omega}{g(e_{ij})\\pi'(e_{ij})}=E_{\\pi}(f)$。\n\n**定理3（由一个可逆的马尔可夫链构建其相应的不可逆的马尔可夫链）：**\n\n*假定$X_t$是状态空间 $N$上的一个不可约且可逆的马尔可夫链，其状态转移概率和稳态分布分别为$P={P(i,j)}$和$\\pi$。构建状态空间 $\\Omega$上的一个新的马尔可夫链$Z_t$，使得其转移概率$P'={P'(e_{ij},e_{lk})}$满足下面两个条件：*\n\n$$P(j,i)P'(e_{ij},e_{jk})=P(j,k)P'(e_{kj},e_{ji})$$\n\n$$P'(e_{ij},e_{jk}) \\geq P(j,k)$$\n\n*那么$Z_t$是一个不可约且不可逆的马尔可夫链，其存在唯一的一个稳态分布$\\pi'$，且满足$\\pi'(e_{ij})=\\pi(i)P(i,j)$，并且对任意一个函数$f$，满足$\\sigma'^2(f) \\leq \\sigma^2(f)$。*\n\n#### NBRW-rw\n\n#### MHDA\n\n### 模拟实验","tags":["random walks","theoretical analysis","graph sampling","paper reading"]},{"title":"Random Walks on Graphs -- A Survey","url":"/2019/12/11/Random-Walks-on-Graphs-A-Survey/","content":"\n[Lovász L. Random walks on graphs: A survey[J]. Combinatorics, Paul erdos is eighty, 1993, 2(1): 1-46.](http://www.cs.yale.edu/publications/techreports/tr1029.pdf)\n\n这是一个关于**随机游走**的综述性的调研报告，包含与随机游走相关的很多问题，涵盖了*基础的随机游走模型*，*访问时间*，*覆盖时间*，*收敛速度*，*特征值分析*，*电气网络*以及*应用算法*等等。\n\n### 随机游走简介\n\n给定一个图和一个起始节点，随机选择当前节点的一个邻居节点并跳转，持续上述过程，产生一串随机的节点的过程称为**图上的随机游走**。\n\n图上的随机游走的过程可以看成是一个有限的马尔可夫链，无向图上的随机游走可以看成是时间可逆的马尔可夫链。\n\n实际上，现实生活中很多场景都可以看成是随机游走，比如*洗一副扑克牌*的过程，所有纸牌的排列置换可以构成一个图的节点，若通过一次洗牌可以实现两个状态的转换，则将相应的两节点相连，则持续洗牌的过程即可看成是一个图上随机游走的过程。\n\n最早的随机游走通常简单、无限的图上的随机游走来定性的分析某些特征，比如随机游走是否能回到初始节点？；之后，随机游走开始更多的面向通用的、有限的图的场景，并且更多的进行定量的分析研究，比如随机游走需要多少步能够回到起始节点？随机游走多快能到达极限分布？\n\n研究发现，随机游走与很多图理论相关，比如图的**谱理论**，**电气网络**中的电阻等等。本篇调研报告将关注**特征值**和**电气网络**。最后，本文调研了一些相关的应用场景。\n\n### 基础知识\n\n随机游走 -- 马尔可夫链 -- 状态转移矩阵\n\n当随机游走进入一个状态的分布后，状态的分布不再改变，则称其为**稳态分布**，对每个连通图，都有唯一的稳态分布：$\\pi(v)=\\frac{d(v)}{2m}$。\n\n当图为正则图（各定点度数均相同），则称该图上的随机游走对应的马尔可夫链是**对称的**。当图不是正则图，该性质由**时间可逆性**代替。对于时间可逆的马尔可夫链的任意一对节点$i,j$，都有$\\pi_i P_{ij}=\\pi_j P_{ji}$。\n\n### 主要参数\n\n#### 主要参数的定义\n\n**（1）访问时间（access time / hitting time）**，$H(i,j)$，表示从节点$i$出发访问到节点$j$的期望步数。\n\n**（2）通讯时间（commute time）**，$\\kappa(i,j)=H(i,j)+H(j,i)$，表示从节点$i$出发访问到节点$j$，之后又回到节点$i$的期望步数。\n\n**（3）覆盖时间（cover time）**，表示从一个初始节点出发，访问到图中每个节点的期望步数。若未指定初始节点，则是指最差情况下的期望步数。\n\n**（4）混合速率（mixing rate）**，表示随机游走收敛到其极限分布的速率，定义为：$\\mu=lim_{t\\to \\infty} \\sup max_{i,j}|p_{ij}^{(t)}-\\frac{d_j}{2m}|^{1/t}$\n\n#### 相关性质\n\n* 主要参数的界\n\n* 对称性和访问时间\n\n* 访问时间和覆盖时间\n\n* 单调性\n\n* 覆盖时间和通讯时间的界的应用场景\n\n### 特征值连接\n\n谱（spectral）理论\n\n* 谱和访问时间\n\n* 谱和生成函数\n\n### 电气连接 \n\n### 混合速率\n\n* 混合速率和耦合\n\n* 混合速率和特征值间隔（eigenvalue gap）\n\n* 特征值间隔和导通性\n\n* 导通性和多商品流\n\n### 随机游走采样","tags":["random walks","theoretical analysis"]},{"title":"GraphX(OSDI 2014) 分布式数据流框架上的图处理","url":"/2019/11/24/GraphX-OSDI-2014-分布式数据流框架上的图处理/","content":"\n### 图处理场景\n\n#### 分布式流处理框架\n\n通用分布式数据流框架，比如MapReduce和Spark，能支持丰富的数据流操作，但是却更适用于分析处理非结构化或表格类的数据，在处理迭代的图算法时多个阶段的复杂连接，而且没有利用到迭代图算法中的常见模式和结构，因此利用他们进行迭代图算法分析往往性能很差。\n\n#### 专用图处理系统\n\n专用的图处理系统能很好的表达迭代图算法，进行图处理时通常比通用的分布式数据流框架能好几个数量级。\n\n图系统中一般将图结构数据表示为一个属性图，每个节点和边有其相应的属性，其中属性包括元数据（例如用户配置文件和时间戳）和程序状态（例如PageRank值）。\n\n专用图系统的不足：\n* （1）现实应用中，图分析任务往往伴随着其他类型数据的分析处理，比如非结构化的数据或表格数据。此时就需要组合多种系统进行管道处理流程，此过程中不免提升了计算的复杂度，带来了不必要的数据迁移和移动。\n* （2）现在图处理系统一般为了性能优化而放弃了考虑容错。\n所以专用的图处理系统通常没有被分布式数据流框架的广泛支持。\n\n#### 局限性与希冀\n\n过去，图处理系统和分布式数据流框架是分开发展的，主要原因有：\n* （1）早期的分布式数据流框架（比如MapReduce）强调单阶段计算和在磁盘上处理，而迭代图算法需要重复且随机地访问图的子集，所以很难应用于这些计算框架。\n* （2）早期的分布式数据流框架没有公开对数据分区的细粒度控制，从而阻碍了图数据分区技术的应用。\n\n但是，新提出的内存分布式数据流框架（比如Spark和Naiad）公开了对数据的划分和数据的内存表示，已经解决了一部分上述的局限性。\n\n考虑*分布式流处理框架*相对*专用图处理系统*的优点：\n* 数据流系统中操作往往可以跨越多个集合，但图系统中操作只定义在单个的属性图上。\n\n**希冀**：结合图处理系统和分布式流数据框架的优点，使得一个系统能处理整个分析管道。\n\n#### 目标与实现\n\n所以本文的想法是开发一个**通用的分布式数据流框架之上的图处理系统**，需求：\n* （1）识别图计算的基本数据流模式；\n* （2）将图处理系统中的优化转换为数据流优化。\n\n本文在Spark的基础上构建了GraphX库，GraphX提供了图API,并在上层实现了Pregel抽象以及一些图操作。GraphX将图计算嵌入到分布式流处理框架中，将图计算的过程提取成一个特定的“join–map–group-by”的数据流模式。不同于现有的图处理系统，GraphX的API支持图数据和非结构化、表格数据的组合。并且允许将同一个物理数据同时视为图数据和集合数据，避免数据移动和复制。\n\n但是，直接将图编码为集合，然后直接使用通用的数据流操作执行迭代图计算非常低效。为了能实现与专有图系统相当的性能，GraphX进行了如下方面的优化：\n* （1）如何将图编码为集合；\n* （2）如何执行通用的数据流操作。\n\n具体的，将专用图处理系统中的有几个优化点重现应用到spark数据流操作中：\n* （1）切割点划分 -- 水平划分的集合\n* （2）活跃节点记录 -- 增量视图\n* （3）节点镜像 -- 基于路由表的多播连接\n\n真实数据集上的实验表明，GraphX能实现和专用图系统相当的性能，同时保留通用数据流框架的优点。\n\n### GraphX的编程抽象\n\n#### 集合表示属性图\n\nGraphX中使用一对*节点集*和*边集*来表示一个*属性图*。**节点集**包含节点属性，由*节点ID*唯一标志，。**边集**包含边属性，由*源节点和目的节点ID*唯一标志。\n\n通过将一个属性图表示成一对节点集和边集的形式，使得GraphX能轻易将分布式数据流框架中的其他集合与图组合。比如增加一个节点属性只需要与相应的节点属性集合连接。分析图计算的结果以及比较不同图的属性也只需要进行连接相应的结果集合（这在专用的图计算系统中不能支持）。\n\n图上不同的算法拥有各自的*节点集*，但可以共享同一个*边集*。可以实现数据的复用。此外，特定于图的索引数据结构可以在具有公共顶点和边集的图之间共享，从而减少存储开销并提高性能。\n\n#### 数据流操作实现图计算\n\nGraphX将分布式数据流框架中的图并行计算表示为一个由*连接（join）*阶段和*分组（group-by）*阶段组成的序列，这些阶段由*map（映射）*操作间隔。\n\n* 在**连接（join）**阶段， 节点和边连接形成一个*三元组视图（triplets view）*，包含边以及其源节点和目的节点的属性。\n\n* 在**分组（group-by）**阶段，三元组根据源顶点或目的顶点来构造每个节点的邻居节点，并进行聚合计算。\n\n*分组（group-by）*阶段*收集（gather）*发送到同一节点的消息，然后*映射（map）*操作*应用（apply）*聚合的消息来更新节点的属性，最后*连接（join）*阶段将新的节点属性*分散（scatters）*到所有相邻的节点。上面的过程构成了专用图计算系统的GAS模型。\n\n**迭代**的组合*连接（join）*和组（group-by）阶段以及数据并行映射（map）阶段，可以实现**Pregel抽象**。\n\n#### GraphX操作\n\n### GraphX的系统实现\n\n#### 分布式图表示\n\n#### 实现三元组视图\n\n#### 优化mrTriplets\n\n#### 其他优化\n\n* （1）基于内存的Shuffle；\n\n* （2）块状和柱状结构；\n\n* （3）可变的整数编码（一个字节中只使用7位来记录数据，最高的第8位用来记录是否需要另一个字节来记录该数字）。\n\n### 实验对比\n\n**（1）实验设置**\n\n* 实验环境：Amazon EC2，**16**个m2.4xlarge工作结点;每个结点有6个虚拟核，**64GB**内存。\n\n* 数据集：Twitter-2010，uk-2007-05。\n\n* 运行算法：PageRank，connected components。\n\n* 对比系统：Apache Spark 0.9.1，Apache Giraph 1.1，GraphLab 2.2 (PowerGraph)。\n\n**（2）对比其他系统**\n\n* 对比baseline的分布式数据流框架，性能高出最多一个数量级。\n\n* 与专门的图处理系统性能相当。\n\n**（3）GraphX性能**\n\n* 扩展性\n\n* 容错\n\n","tags":["graph processing system","paper reading","distribute dataflow framework"]},{"title":"Managing Large Dynamic Graphs Efficiently(SIGMOD 2012)","url":"/2019/11/20/Managing-Large-Dynamic-Graphs-Efficiently-SIGMOD-2012/","content":"\nMondal, Jayanta, and Amol Deshpande. \"Managing large dynamic graphs efficiently.\"2012 ACM SIGMOD. | [paper](https://dl.acm.org/citation.cfm?id=2213854) |\n\n### 网络图研究现状\n\n#### 网络图场景\n\n如今网络图越来越无处不在，如社交网络、通讯网络、金融交易网络、引文网络、基因调控网络、疾病传播网络、生态食品网络、传感器网络等等。网络数据甚至出现在普通的应用程序中，如电话呼叫数据、IP流量数据或包裹装运数据等。\n\n这些网络数据通常表示成一个*图（graph）*，然而目前缺乏一个良好的针对这种图结构的数据的数据管理系统，用以支持图上的查询与分析。\n\n并且，随着图规模的不断增长，这就需要使用并行和分布式的解决方案。然而，图操作不容易并行化，即使是对分布式图的简单查询也可能导致大量的网络遍历。\n\nMapReduce框架已经成为并行处理许多大型分析任务的框架。然而，MapReduce框架的目标是批量处理大量静态数据，既不支持实时数据摄取，也不支持实时查询。\n\n目前为止，有很多工作研究*单站点的图数据库系统*，他们通过对底层图的策略遍历，可以有效的执行特定类型的查询，比如*可达性（reachability）*，*关键字查询（keyword search queries）*，*子图模型匹配（subgraph pattern matching）*等。\n\n然而，*动态图数据的分布式管理*还没有得到很好的研究。在执行特定类型的查询或执行特定类型的分析方面也有一些工作，例如子图模式匹配、数据挖掘等，但这些工作要么关注点有限，要么就像Pegasus一样，是为了进行批处理。\n\n**本文的目标：：构建一个能够支持大规模动态变化的网络图的分布式图数据管理系统。**\n\n#### 图划分\n\n分布式图管理系统中一个关键的挑战是*图划分*，但是由于图结构的复杂连接，想要实现有效的图划分及其困难，尤其是在动态图的场景下。\n\n标准的**基于哈希的图划分方案**虽然能实现分布式集群的结点之间良好的负载均衡，但是通常会带来太多的*切割边（edge cut）*，因为大多数图查询或分析任务都需要遍历边来获取邻居信息。这不仅增加了查询延迟，还增加了整个网络通信，从而限制了系统的可扩展性。\n\n有很多工作研究更**复杂的图划分策略**。将一个图划分为大小相等的分区，同时最小化边切割是一个NP难的问题，目前也有一些实际的技术方案能够实现较好的图划分结果。但是，这些技术不能处理高度动态的图，因为节点访问模式和图结构本身可能会很快发生变化。\n\n更重要的是，在大多数实际应用中，图数据高度互联的特性意味着，通常不存在将边切割最小化的干净的不相交分区。特别是社交网络，由于社区结构重叠，存在高度连接的稠密分部，因此很难分割。\n\n#### 图复制\n\n一种替代的方案是**基于节点复制的方法**，其主要思想是复制图中的一些节点，以最小化分布式遍历的数量。\n\n**本地语义**，Pujol等人提出一种该方法的极端版本，即充分地复制图，以便对图中的每个节点，它的所有邻居都在本地出现(称为本地语义)。他们还使用主动复制策略（*push-on-change model*），即所有复制的数据都要即时保持最新。然而，这种方法需要非常高的、不必要的通信来保持副本的更新，Facebook使用一种替代的*pull-on-demand model*来减少更新的开销。\n\n为了能保证*本地语义*，其复制开销（即图中每个节点的平均副本数）通常特别大。对于一个Facebook数据集，只划分成8个分区，平均每个节点就需要大约2个副本。\n\n本文提出一种**混合自适应的复制策略**，减少复制开销，同时支持大规模图数据上的高效查询。\n\n### 本文系统设计\n\n#### 数据模型与查询模式\n\n#### 路由与存储\n\n本文在一个开源的KV存储系统Apache CouchDB的基础上实现了分布式图数据管理系统。\n\n#### 复制管理器\n\n本文使用一种新奇的**公平需求**的策略来指导复制的策略，公平需求策略可以使用一个阈值$\\tau \\leq 1$来刻画,可以简单表述为:**对于图上的每个节点，要求其所有邻居节点中不少于$\\tau$的部分存于本地**。当$\\tau = 1$时，就相当于*本地语义*。\n\n#### 复制决策\n\n根据*公平需求策略*的指导，需要对节点进行细粒度的选择性复制，并决定何时进行push或pull来更新副本信息，维护这些决策的开销通常也非常大。\n\n本文设计了一种**基于cluster的方案**，将具有相似访问模式的节点分组在一起，在不影响质量的情况下减少开销。该方案分析了决定复制什么，以及选择何时push或pull的问题，并提供了理论分析和有效的实用算法。该算法能够在每个节点上进行局部决策，能够在低负载期间更改决策，并/或错开决策的时间以避免性能的显著下降。\n\n### 实验对比\n\n**（1）实验设置**\n\n实验环境：Amazon EC2 infrastructure using 7 EC2 instances; 1 instance 1 core, and 1.7G of memory。\n（1个实例用于向系统发送更新和查询，其余6个用于存放图数据）\n\n数据集：使用*偏好连接模型*来构建图数据（已经被证明能够很好地模拟社交网络）。具体的生成过程为：每次添加一个节点，新增的节点*优先连接*到具有更高度（degree）的现有节点，即连接到现有节点的概率取决于该节点的度数。本文中大多数实验使用的图规模为**1.8M**个节点，**18M**条边。另外，本文选择了100个tweet数量足够的Twitter用户，并下载了他们的tweet以获得他们的访问跟踪，用于模拟用户的活动模式。\n\n运行算法：图查询。\n\n对比三种方法：((1) all-pull, where we do not do any replication, (2) all-push, where the nodes are replicated sufficient to guarantee no pulls would be needed (i.e., local semantics), and (3) hybrid, our hybrid approach.\n\n对比指标：所有服务器上交换消息计算的网络通信量，可以表示为推送和接收的消息的总量。\n\n**（2）直方图粒度的影响**\n\n**（3）带宽消耗和网络负载**\n\n**（4）改变Clusters的数量**\n\n**（5）改变Write-Read比率**\n\n**（6）改变公平阈值**\n\n**（7）改变图密度**\n\n**（8）Pull超时的影响**","tags":["graph processing system","paper reading","graph partition","graph vertices replication","dynamic graphs"]},{"title":"CGraph(ATC 2018) 并发图处理系统","url":"/2019/11/12/CGraph-ATC-2018-并发图处理系统/","content":"\nCGraph: A Correlations-aware Approach for Efficient Concurrent Iterative Graph Processing. Yu Zhang, Xiaofei Liao, Hai Jin, Liu Gu, Haikun Liu, Bingsheng He, Ligang He. ATC 2018 [presentation](https://https://www.usenix.org/conference/atc18/presentation/zhang-yu) | [paper](https://www.usenix.org/system/files/conference/atc18/atc18-zhang-yu.pdf) |\n\n### 并发图处理场景\n\n并发图处理（CGP）是指，大量的图算法并发的运行在同一平台上对底层同一个图数据进行处理，以对该图数据进行多方位的分析处理，获得各种目的性的分析结果。通过追踪一个大型社交网络上的信息发现，对同一个图数据在峰值的时候有超过20个计算任务在并发执行。\n\n这些任务之间独立运行，相互之间造成缓存干扰和内存墙的问题，限制了这些并发图计算任务的运行性能。实验发现，随着并发图处理任务的数量的增加，每个任务的平均执行时间明显增加，而增加的时间开销主要来源于更高的数据访问开销。因为并发图处理任务之间会竞争数据访问通道、内存和缓存。\n\n这些并发图处理任务对图数据的访问也存在关联性，包含空间关联性和时间关联性。\n\n（1）空间关联性：多个并发图分析任务需要访问和处理的图数据存在大量的交集。数据显示，平均每一轮并发图处理任务之间对图数据的访问的交集高达70%。\n\n（2）时间关联性：多个并发图分析任务可能在很短的时间内需要同时访问同一个图划分块。\n\n所以本文旨在考虑通过充分利用这些并发图处理任务对图数据的访问的空间/时间相关性，开发高效使用缓存/内存和数据访问通道的解决方案，以实现更高的吞吐量。\n\n### 相关工作\n\n现有的单机图处理系统，包括GraphChi，X-Stream，GridGraph，NXgraph和CLIP等，通常旨在优化使得有更高的顺序内存带宽，更好的数据局部性，减少冗余数据访问，更少的内存消耗等。他们主要针对单个图处理任务的场景能实现很好的性能，但对并发图处理场景运行效率并不高。\n\n### 以数据为中心的LTP模型\n\n以数据为中心的LTP包含三个阶段：Load-Trigger-Pushing。\n\n#### 加载图分块（Load）\n\n**数据分离**，一个图处理任务的数据通常包含四个部分，$D_J=(V_J,S_J,E_J,W_J)$，分别表示节点集，节点状态集，边集和边权重集。LTP模型中首先实现图结构数据和图处理任务状态数据的分离。即$D=(V,E,W)$为所有并发图计算任务的共享数据，被划分为多个块存储，$G=\\cup_iG^i$。各图处理任务分别有一个状态数据$S_J$。共享的图数据和各计算任务的状态数据通过多张KV表来存储。\n\n**图划分**，CGraph采用切割节点的方式，所有的边被均匀划分到不同的分块，跨越不同分块的节点建立master和mirror。这样能很好的达到各个图数据分块间的负载均衡，且避免各个图数据分块之间的通信，只有master和mirror之间需要通信。每个图分块的大小取决于CPU的核数N以及缓存容量的大小C，具体的值取满足下列公式的最大值，$P_g + \\frac{P_g}{s_g} \\times s_p \\times N + b \\leq C$。\n\n**动态图支持**，在动态图场景下，图数据结构会随着时间更新，比如增加或删除一些节点和边。这些更新只对在他们之后提交的图并发任务有效，CGraph通过一些快照（snapshots）来保存这些更新的增量信息，这样不同的并发图处理任务可以分别处理不同的快照信息。\n\n**图分块加载**，在每一轮计算中，各个并发图处理任务共享同一个图分块数据。所以每一轮，CGraph顺序加载有需求的图分区进入内存，这样在该图分区上有计算任务的图处理任务进行并发计算。\n\n但这种加载图分块的调度方式往往会造成加载的图数据未能被充分使用，原因有：\n\n1）有些度比较大的节点可能会比其他节点收敛更慢，而后面的几轮计算也需要加载进来那些已经收敛了的图数据；\n\n2）不同图分块的使用频率也是倾斜的并且会随时间变化；\n\n3）被加载的图分块可能只被很少（甚至一个）的计算任务需要，利用率很低。\n\n**基于核心子图的调度算法**，为了提高每个加载的图分块的利用率，CGraph提出一种基于核心子图的调度算法，其主要思想是：首先筛选出所有的核心节点（度数大于某阈值的节点）以及他们之间的连接边，构成一个核心子图；然后将这个子图的边放到几个大小相同的图分块中，其余的边被划分到其他大小相同的图分块中。这样，对核心节点的频繁加载和处理，带来的对相同分区中早期收敛顶点的加载开销更小。\n\n然后，CGraph给每个图分块一个优先级，优先调度优先级更高的图分块进入内存进行处理。\n\n1）当大多数任务需要对一个块进行处理时，给它更高的优先级；\n\n2）当一个块有更高的平均度或者更多的节点状态更新时，给它更高的优先级。\n\n具体的优先级的值计算如下：$Pri(P)=N(P) + \\theta \\cdot D(P) \\cdot C(P)$\n。其中，$\\theta$是一个使得第二部分小于1的数。\n\n通过这种方法，加载到缓存中的图分块可以服务尽可能多的图处理任务，而其他图分块在一段时间间隔后有更多的机会被更多的任务需要，通过降低平均数据访问成本进一步提高了吞吐量。\n\n实验表明，采用基于核心子图的调度算法最高能将执行时间减少到原来的60%。\n\n#### 触发（Trigger）各图处理任务的并发执行\n\n加载一个子图分区进入到内存以后，在该图分区上有计算任务的图处理任务进行并发计算。注意，任何新提交的作业只需要注明它在第一次迭代时要处理的分区，然后等待被触发来处理它们。当要并发处理的任务数量大于CPU的核数时，这些CGP作业被分配为不同的批处理。\n\n对于每个图分块的处理，不同CGP任务的计算负载往往是倾斜的，导致硬件的利用率较低。我们将当前图分块的私有表中未处理顶点数量最多的任务称为straggler。然后在逻辑上将straggler的未处理的顶点划分成多个片，并将他们分配到空闲的CPU核中。\n\n#### 数据推送（Pushing）实现master和mirror的状态同步\n\nCGraph在计算处理一个图分块时，是没有cache miss的，因为不同的图分块的节点之间是没有通信的。但是在不同图分块上，具有副本的顶点需要同步它们的状态。mirror节点需要推送（push）它的新状态到它的master节点，master节点获取到来自所有mirror节点的状态更新之后计算出当前轮最终的状态值，并推送到各个mirror节点。在这样的节点状态同步的过程中，私有状态表的许多图分区经常被加载到缓存中，导致较高的cache miss率。\n\n为了解决上述问题，CGraph将每个mirror节点的更新状态保存到一个缓冲区$S_j^{new}$中。在数据同步阶段再隐式发送到master节点以进行批量顶点状态同步。\n\n当有多个CGP作业要同步顶点状态时，对这些作业逐一进行，以减少资源争用，因为作业之间的状态数据没有数据共享。每个作业的各个节点的状态同步分批完成，首先将缓冲区$S_j^{new}$中的*状态更新项*按照其master节点所在的图分块的ID进行排序，这样很多状态更新变成了对同一分区的连续访问，我们只需要加载很少的的私有表分区。当一个master节点的连续更新完成时，就会得到当前迭代中这个顶点的最终状态。然后，这样的新值也可以直接批处理同步到他们对应的mirror节点。\n\n### 实验对比\n\n**（1）实验设置**\n\n实验环境：4-way 8-core Intel Xeon CPU E5-2670; each CPU has 20 MB LLC，64GB DRAM。\n\n数据集：Friendster，Twitter，uk2007，UK-Union，hyperlink14。\n\n运行算法：PageRank，SSSP，SCC，BFS。\n\n对比系统：CLIP，Nxgraph，Seraph。\n\n**（2）整体性能**\n\n**（3）可扩展性**\n\n**（4）动态图上的性能**","tags":["graph processing system","paper reading","concurrent graph processing"]},{"title":"KnightKing(SOSP 2019) 分布式随机游走系统","url":"/2019/11/04/KnightKing-SOSP-2019-分布式随机游走系统/","content":"\nKnightKing: A Fast Distributed Graph Random Walk Engine. Ke Yang, MingXing Zhang, Kang Chen, Xiaosong Ma, Yang Bai, Yong Jiang, SOSP 2019. | [Presentation](https://sosp19.rcs.uwaterloo.ca/videos/D3-S2-P2.mp4) | [Paper](http://delivery.acm.org/10.1145/3360000/3359634/p524-yang.pdf?ip=222.195.68.252&id=3359634&acc=OPENTOC&key=BF85BBA5741FDC6E%2EA4F9C023AC60E700%2E4D4702B0C3E38B35%2EC42B82B87617960C&__acm__=1572836886_72f8bbbe82d7289fac30d1fcc02962f6) |\n\n### 随机游走\n\n#### 应用场景\n\n随机游走是图数据分析和机器学习中一个重要的分析工具，可以利用图中节点之间的集成路径提取信息，经常被应用于一些重要的图分析、排序和嵌入式算法中，比如*PPR（personalized PageRank）*，*SimRank*，*DeepWalk*，*node2vec*等。\n\n这些算法既可以独立运行，也可以作为机器学习任务的预处理步骤。他们服务于各种应用场景，比如*点|边分类*，*社区检测*，*链接预测*，*图像处理*，*语言建模*，*知识发现*，*相似性测量*和*推荐系统*等。\n\n#### 执行过程\n\n图上的随机游走的执行过程为：\n\n1. 从图上出发$w$条walker，每条walker从一个特定的节点出发，walker之间独立的游走。\n\n2. 每一步，每条walker选取其所停留的当前节点的出边中随机采样选择一条出边，并沿着该出边跳转到下一跳。\n\n3. 每条walker在达到预设的终止条件时终止行走，一般为达到预设的长度或者预设的终止概率。\n\n一般来说，基于随机游走的算法的**输入**为一个图$G$。**输出**为随机游走过程中嵌入的计算结果，或者随机游走的路径信息。\n\n#### 关键步骤\n\n随机游走过程中的主要计算开销在于**边采样过程**，这也是不同的随机游走算法的不同之处，每个不同的随机游走算法定义其特有的**边转移概率**。随着随机游走的普及，边采样的逻辑也变得越来越复杂，近期的算法中更是提出了**动态采样**，即随机游走在每个节点处的采样概率不仅跟该节点的邻居信息有关，还与随机游走的状态有关。\n\n#### 复杂的随机游走\n\n复杂的随机游走算法能实现更高的灵活性，带来更好的性能，但随之带来的也有更大的采样的复杂度和计算开销。例如，一个很受欢迎的网络特征学习技术**node2vec**，包含*动态随机游走*和*跳跃语言模型构建*两个部分，而其在Spark上的实现据说98.8%的时间开销花在第一部分。而本文作者的实验表明，即使在Gemini的实现版本中，node2vec的执行会停滞在**边采样**的步骤，导致其在Twitter数据集中*每秒访问的节点个数*比BFS要低1434倍。\n\n#### 计算开销来源\n\n边采样过程中的巨大计算开销来源于它的*动态*特性，即在每一步进行随机边选择时，需要重新计算当前节点的所有出边的转移概率，这个计算开销随着当前节点度的增长而增长。而真实时间的图的度分布一般呈现幂律分布，所以造成各个节点的计算开销非常不均衡。而随机游走一般趋向于走到度数高的节点，这进一步加剧了采样开销。\n\n本文的作者对比考虑了两个真实时间的图Friendster和Twitter，他们有相似的平均度，分别为51和70，但是Twitter的度分布更加倾斜。在这两个图上执行node2vec，采用“Full-scan”的边采样方式，Twitter上的平均采样开销是Friendster的255倍，Twitter上进行一步walker转发平均需要将近访问$10^6$条边。\n\n#### 发展需求\n\n其他的随机游走也有如上所述的挑战，然而目前没有一个统一的随机游走计算框架，所有这些算法都需要用户自己在通用的图计算框架上实现，不仅工作量大而且性能也难以优化。\n\n这些随机游走算法都是以walk为中心的算法，但目前的图计算系统中大多采用以点或边为中心的计算模型，更关注于更新点和边的状态信息，随机游走中的“walker”通常作为消息信息被传递，此时walk信息很难记录，而那些依赖于walk状态来进行边采样的算法也很难实现。\n\n另外，现有的通用图计算系统中采用的有一些优化方案，对随机游走算法来说并不适用甚至反而降低随机游走算法的性能，比如*2-D图划分*和*GAS计算模型*。\n\n#### KnightKing概述\n\nKnightKing是一个*分布式随机游走计算引擎*，可以开成是传统分布式图计算引擎的随机游走副本。KnightKing采用以walk为中心的视角，用户自定义walk的边转移概率。与通用的图计算引擎类似，KnightKing隐藏了图划分，节点分配，通信和负载均衡等系统层面实现细节，只是给用户提供了一个“think-like-a-walker”的视角，用户可以灵活的添加可选的优化。\n\nKnightKing带来性能提升的核心在于**快速地选择下一跳**。\n\n（1）KnightKing首先引入了一个统一的**转移概率的定义**，引入*静态概率*和*动态概率*，有效的刻画各类随机游走算法。\n\n（2）然后采用**拒绝采样**的方式，避免了在进行边采样时遍历walker所在的当前节点的所有出边，大大减少了边采样的开销。对于相同的node2vec，换成KnightKing中的拒绝采样，采样一条边进行一步walk转发平均只需要0.79条边。另外，不同于现有的一些近似优化算法，KnightKing采用精确采样，提高性能的同时并没有损失准确度。\n\n（3）KnightKing也做了一些系统方面的优化工作，来支持以walk为中心的编程模型，并进一步提升随机游走的性能。\n\n### 统一的随机游走算法定义\n\n#### 随机游走分类\n\n一般随机游走的过程为：在给定图上出发一定数量的随机游走，每个出发于一个特定的节点，每条walker重复在当前节点的邻居节点中随机选择一个节点，并转发到该节点。不同的随机游走算法的不同就在于**邻居节点的选择**。\n\n根据当前节点的邻居节点们被选择的机会是不是相同的，可以分为**无偏**随机游走，即当前节点的各个邻居节点被选择的概率是相等的，和**有偏**随机游走，即当前节点的各个邻居节点被选择的概率取决于其权重或其他特征，各不相同。\n\n根据各个walker转发过程中在一条边上的转移概率是不是恒定的，又可以分为**静态**随机游走，即walker在一条边上的转移概率只与图结构有关，在walker的转发过程中保持恒定，和**动态**随机游走，即walker在一条边上的转移概率不仅与图结构有关，还与walker当前的状态有关，会随着walker的转发不断变化。所以对于动态随机游走来说，我们不再能够预计算出每条边的转移概率，而在每一步walker转发时都需要重新计算转移概率。\n\n我们可以进一步根据随机游走算法的转移概率考虑当walker最近路径的步长数来定义随机游走算法的**阶数**，**一阶随机游走**算法中，walker只知道当前节点，不知道之前访问的节点信息。**一阶随机游走**算法中，walker在选择下一跳的时候考虑上一步所在的节点。高于二阶（包含二阶）的*高阶随机游走为**动态**随机游走*。\n\n除了转移概率的不同，不同的随机游走算法也有不同的**终止策略**，常见的终止策略有（1）在walker走到一定步长后终止，（2）每个walker在每一步有一定的概率终止。\n\n#### 转移概率统一定义\n\n本文给出各类随机游走算法一个统一的非标准化（未归一）的转移概率的定义：\n\n*对于一个walker $w$，当前停留在节点$v$，该walker通过$v$的一条出边$e$转发到下一跳的概率为*\n\n$$P(e)=P_s(e) \\cdot P_d(e,v,w) \\cdot P_e(v,w).$$\n\n*其中，$P_s(e)$为静态分量，$P_d(e,v,w)$为动态分量，$P_e(v,w)$为扩展分量。*\n\n在这个统一定义的框架下，简单的随机游走算法就是有偏高阶算法的一个特例。比如简单的无偏静态算法，$P_s(e)=P_d(e,v,w)=1$。$P_e(v,w)$的设置独立于$P_s(e)$和$P_d(e,v,w)$，当一个walker满足终止条件时，设置$P_e(v,w)=0$。\n\n#### 典型随机游走算法\n\n下面介绍四个有代表性的随机游走算法，并给出他们在上述的统一的转移概率的定义下，各个分量的值。\n\n**（1）PPR**\n\nPPR，即个性化的PageRank（personalized PageRank），是经典的PageRank算法的一个更复杂的扩展版本。通用的PageRank算法通常是使用*幂法迭代计算*，但是PPR，尤其是*fully PPR*(为所有节点计算PPR)用幂法迭代计算需要非常高的时间和空间开销，对非常大的图来说通常难以承受。\n\n一个通常的做法是用基于随机游走的方案来计算得到近似值，考虑一个节点$v$的PPR可以从$v$出发进行一条很长的RWR，统计各个节点的访问概率，当walk的长度足够长，这里的访问概率就趋近于PPR值。这里我们考虑基于随机游走的fully PPR。\n\n考虑一个有向加权图，当前节点的一条出边被采样的概率正比于它的权重，即$P_s(e)=f(v,x)$，其中e是一条从$v$到$x$的边，$P_d(e,v,w)=1$。为了提升性能，我们通常将一条长walk拆成很多条短walk并行处理，每个短walk以一定的概率$P_t$终止，即在$P_t$的概率下，$P_e(v,w)=0$。（本文设置$P_t=0.0125 or 0.149$）\n\n这里，PPR是一个有偏静态随机游走算法。\n\n**（2）DeepWalk**\n\nDeepWalk是一个广泛应用于机器学习的一个图嵌入技术，利用语言建模技术来进行图分析。DeepWalk使用随机游走来产生很多的walk序列，每个节点作为一个节点，每个walk序列就构成一个句子，然后利用SkipGram语言模型来学习这些节点的潜在表征，这有很多应用场景，比如*多标签分类*，*链接预测*和*异常检测*。\n\n原始的DeepWalk是无偏的随机游走，这里我们扩展成加权图下有偏的随机游走，转移概率的设置与PPR相同，walk终止条件为走一定的walk长度。\n\n**（3）Meta-path**\n\nMeta-path用于捕捉节点和边之间的异构性背后蕴含的语义。Meta-path中，每条walker关联着一个**meta-path模式**，指定一个walker路径中边类型的模式。比如在一个论文发表网络图中，为了探索论文之间的引用关系，我们可以设置walker的初始节点为一个*作者*，设置meta-path模式为“isAuther -> citeBy -> autheredBy”。\n\n对于关联着meta-path模式$S$的一个walker，其在第$k$步的动态转移概率为$P_d(e,v,w)=1$, if $type(e)=S_{k mod |S|}$, otherwise $P_d(e,v,w)=0$。\n\n这里，Meta-path是一个动态的一阶随机游走算法。\n\n**（4）node2vec**\n\nnode2vec是一个高阶的随机游走算法，walker根据最近访问的历史信息来选择下一跳。node2vec与DeepWalk有相似的应用场景，但更加灵活。\n\n在一个无向图中，一个walker $w$，刚刚从节点$t$跳转到节点$v$，$x$是v的邻居节点，则node2vec中转移概率的动态分量可以表达为：\n\n$$P_d(e,v,w)=\\frac{1}{p}, if d_{tx}=0$$\n$$P_d(e,v,w)=1, if d_{tx}=1$$\n$$P_d(e,v,w)=\\frac{1}{q}, if d_{tx}=2$$\n\n这里，$p$和$q$是用户配置的参数，分别称为*回归参数*和*出入参数*，$d_{tx}$表示节点$t$到节点$x$的距离。考虑加权图的场景，$P_s(e)=f(v,x)$。\n\n这里，node2vec是一个有偏的动态二阶随机游走算法。\n\n### 发展现状\n\n目前已有一些研究工作用于加速边采样的过程，提升随机游走的性能，可以分为针对静态随机游走的优化和针对动态随机游走的优化。\n\n#### 静态随机游走\n\n**（1）逆转变换采样（ITS, Inverse Transform Sampling）**\n\n在已知所有边的采样概率的情况下，增加一个预处理过程，为每个节点构建一个数组$C$，用于存放其所有出边的转移概率的CFD（Cumulative Distribution Function），i.e.，$C[i]=\\sum_{j=0}^{i-1}{P_s(e_j)}$。设一个节点的出边数为$n$，则在随机游走进行边采样的时候，首先生成一个随机数$r \\in [0,C[n-1])$，并通过二分查找寻找最大的$i$使得$C[i]>r$，然后就选取$e_i$作为随机游走在该步采样的边。\n\nITS方法在预处理时需要$O(n)$的时间和空间用于构建CDF数据，在随机游走的每一步需要$O(log_2 n)$去采样一条边。\n\n**（2）别名法（alias method）**\n\n别名法也是在预处理阶段将每条边根据其转移概率拆分成一个或多个*片段（piece）*，每个图产生的总片段数不超过2n。然后将这些片段放入不同的*桶（bucket）*，使得每个桶的概率和是相等的。这些桶和他们的内容构成了一张*别名表（alias table）*。在随机游走进行边采样的时候，首先随机选择一个桶，然后在桶中根据每个片段的权重随机选择一个片段，将该片段所属的边作为随机游走在该步采样的边。\n\n别名法在预处理时需要$O(n)$的时间和空间用于构建别名表，在随机游走的每一步只需要$O(1)$去采样一条边。\n\n#### 动态随机游走\n\n上述两个方法针对静态随机游走时能提升较高的性能，但在动态随机游走的场景下，构建CDF数据或别名表都需要巨大的开销，比如针对Twitter数据集（11G）上的node2vec算法，就分别需要970TB或1.89PB的内存开销。所以动态随机游走不能用上述预处理的方法来加速边采样过程。目前也有一些加速动态随机游走算法的优化工作。\n\n**（1）针对专门算法的优化**\n有一些专门针对某一个特定算法的优化工作，比如针对meta-path算法，在预处理时，对每一种边的类型构建ITS数组或别名表。这样所有的边根据类型被划分成多个不相交集合，没有增加预处理额外的时间和空间开销。但这种方法并不能扩展到通用的动态随机游走算法。Fast-Node2Vec是针对node2vec的一个优化工作，通过缓存受欢迎节点的边列表来减少数据传输。这种方法牺牲了walker间的并发处理性能来节省内存开销。\n\n**（2）近似采样方法**\n\n也有一些近似采样算法来提升高阶动态随机游走的类型，比如node2vec-on-spark通过修剪掉高度节点，预处理时针对高度节点只选取其中的30条边。但即使牺牲了一定的准确度，这种方法依旧需要存储高达900|V|的转移概率。Fast-Node2Vec则是针对高度节点忽略去动态概率分布，只考虑其静态概率部分，以此来减少存储和采样开销。\n\n#### 系统优化工作\n\n目前针对随机游走算法的系统方面的工作只有DrunkardMob，但是它只考虑静态随机游走算法而且是设计在单机外核场景下，可扩展性受限。而其他通用的图计算系统是针对一些传统的图算法进行优化，并没有解决随机游走算法的问题。\n\n### KningKing的采样策略\n\nKningKing关键的创新点在于其边采样机制：动态概率分部采用拒绝采样，静态概率分部采用别名法。\n\n#### 拒绝采样\n\n**（1）无偏拒绝采样**\n*拒绝采样*开始用于通用的任意概率的采样，将一个一维的采样过程转换成一个二维的采样过程。具体对应到随机游走的边采样过程为：随机地产生一个位置$(x,y)$，其中$x$是从当前节点的出边中均匀随机选取的一条边e，$y \\in [0,Q(v)]$，其中$Q(v)$是当前节点的出边的动态转移概率的最大值。当$y \\leq P_d(e)$，则e被接收，当前walker通过e跳转。否则，e被拒绝，需要重新采样$(x,y)$并重复上面过程，直至walker成功跳转。\n\n通过拒绝采样的方式，消除了对当前节点所有出边的访问去获取他们的转移概率。一般只需要几次尝试就可以成功采样一条边（复杂度为$O(1)$）。大大减少了对高度节点的采样开销。\n\n**（2）有偏拒绝采样**\n\n有偏拒绝采样是指每条边的静态采样分部$P_s$是有偏的。一般是在加权图场景下采样概率正比于该条边的权重。无偏拒绝采样扩展到有偏拒绝采样，即在随机生成$(x,y)$时，通过$x$来进行边e的选取是有偏的。这里KnightKing使用ITS或别名法。\n\n**（3）采样复杂度**\n\n静态分部：预处理开销$O(n)$，计算开销$O(1)$（别名法）或$O(n)$（ITS）。\n动态分部：一次尝试开销$O(1)$。具体的开销取决于平均尝试的次数$E$，一般可以计算如下。\n\n$$E=\\frac{Q(v) \\cdot \\sum_{e \\in E_v}{P_s(e)}} {\\sum_{e \\in E_v}{P_s(e) \\cdot P_d(e)}}$$\n\n$E$并不直接关联节点的度，而是取决于$Q(v)$，所以我们可以通过减小$Q(v)$的值进一步优化拒绝采样的平均尝试次数，进而提升效率。\n\n#### 优化技术\n\n**（1）解决$P_d$中的异常值（outliers）**\n\n$P_d$中可能会存在几个异常大的值，从而增大了$Q(v)$的值（该节点所有出边的最大值），而大部分概率值都比较低。此时可以通过阶段异常值，拆成多个小的概率值的方式添加到所有出边的后面。这样减小$Q(v)$的值，而不改变每条边被采样到的概率（可以参考论文中的Figure 3）。\n\n**（2）预接收**\n\n可能该节点所有出边的概率值存在一个最小值$L(v)$，则当随机生成的$y \\leq L(v)$，我们直接接收当前节点，而不用去访问当前边获取它的$P_d$。\n\n### 计算流程和编程模型\n\n#### 随机游走的生命周期\n\nKnightKing是一个分布式随机游走系统，同时并发的处理很多条walker。walker根据其当前所在的节点被划分到不同的机器上，并行计算。为了同步协调很多节点上更新任务，KnightKing采用**基于迭代的计算模型**。不同于传统图计算系统上运行的确定性算法，KnightKing每一步的概率选择导致其每一轮计算流程与传统的图计算系统都有细微的差别。\n\n在处理高阶的随机游走时，每一轮迭代计算需要包含两轮消息传递：1）发送查询概率请求；2）收集查询结果。\n\n#### KnightKing API\n\n* 指定转移概率\n\n* 初始化和终止条件\n\n* walker状态\n\n### 系统优化\n\nKnightKing是一个分布式图计算系统，本文实现于2500行的C++源码，使用OpenMPI进行结点间通信。它的底层与分布式图引擎有很多共同之处，所以直接使用成熟的系统（Pregel和Gemini）中的基础设施和技术。\n\n#### 图的存储与划分\n\n存储：CSR格式。\n\n划分：KnightKing采样节点划分策略，每个节点连同它的出边被划分到集群中的一个机器结点（无向图中每条边存两次）。划分时使得每个机器上的节点数和边数的和尽量均匀。\n\n#### walker的执行与协调\n\n**（1）计算模型**\n\nwalker之间独立执行，会导致严重的不同步，而且带来巨大的网络通信开销。KnightKing采用BSP模型，协调同步各个walker的执行。\n\nwalker开始之前需要先进行一些初始化，包括*构建静态概率的别名表*，*设置动态概率的上下界*，*实例化walker*。\n\n每一轮采样**以walker为中心的计算模型**，包括*per-walker的消息生成*，*目标结点查找*，*消息批处理*，*all-to-all的消息传递*。还有一些额外的优化技术包括*缓冲池管理*和*流水线*，以使计算与通信重叠，实现更高的并行度。\n\n**（2）任务调度**\n\n每个结点上有两个线程专门用于消息传递，剩余线程用于walker转发。计算与消息传递并发执行，消息（walkers）被存放于一个共享队列供所有线程抓取，队列的长度一般设置为128。\n\n**（3）walker同步**\n\n即使采样BSP计算模型，大多数walker之间能够同步执行过程，但是仍然会存在一部分stragglers，拖慢整体的运行时间。stragglers的来源有以下两个部分：\n\n1）有些应用中，walker的执行长度本就各不相同，比如PPR，每条walker以一定的概率终止，不同walker终止在不同的步长。\n\n2）在基于动态转移概率的随机游走算法中，采用拒绝采样策略，被拒绝的walker只能待在原节点等到下一轮再尝试转发。\n\n本文统计了在LiveJournal上运行node2vec算法（每条walker运行80步后终止），发现有少部分stragglers落后很多，最慢的walker需要200多轮迭代计算才能完成计算，可以称之为“长尾”。\n\nKnightKing不能减少这些stragglers的迭代次数。但是长尾期间，总walker数量很少时（少于4000），可以通过降低的并发度（总共只使用3个线程，1个用于计算，2个用于通信）的方式来加速stragglers在每一轮的计算。实验表明该优化可以减少总运行时间的57.5%。\n\n### 实验\n\n**（1）实验设置**\n\n实验环境：8个结点的集群，每个结点装备Ubuntu 14.04系统，有2个8核处理器，20MB的L3级缓存，94GB的DRAM。\n\n数据集：LiveJournal，Friendster，Twitter，UK-Union。处理成无向加权图（每条边随机给定权重$[1,5)$）。\n\nRW应用：DeepWalk，PPR，Meta-path，node2vec。\n\n对比系统：Gemini。\n\n评估方法：执行时间。在非常慢的场景下，使用线性回归来推断运行时间。\n\n**（2）整体性能**\n\n**（3）图拓扑的敏感性**\n\n**（4）概率分布的敏感性**\n\n**（5）系统优化**\n","tags":["random walks","graph processing system","paper reading"]},{"title":"谷歌上网助手Ghelper","url":"/2019/10/30/谷歌上网助手Ghelper/","content":"\nGhelper是Chrome浏览器的一个插件，中文名为“谷歌上网助手”，可以让我们在无需翻墙的情况下，方便稳定的使用Google、Google学术等网站。\n\n### 下载插件\n\n（1）在[Chrome插件网](http://chromecj.com/)搜索“ghelper”，下载.crx文件。[推荐地址](http://chromecj.com/downloadstart.html#1501)\n\n（2）将扩展名改成.zip，然后解压到某本地目录下（我放在D:\\Google下），得到一个目录文件（不能删除）。\n\n### 安装插件\n\n（1）打开你的Chrome浏览器的 更多工具 --> 扩展程序页面。或者直接在网址输入: chrome://extensions/。\n\n（2）打开开发者模式。\n\n（3）点击 \"加载已解压的扩展程序\"，选择上一步解压得到的目录文件后确认添加。\n\n### 注册登录\n\n（1）安装完成后，在Chrome浏览器地址栏右侧可以看到Ghelper插件图标，点击出现登录页面。\n\n（2）新用户可以注册并通过邮箱激活，登录后即可访问Google。\n\n（3）新用户初次使用会有三天的VIP权限，三天后只可以使用免费权限，但免费权限就可以一直访问Google和Google学术等网站了。"},{"title":"可逆的马尔可夫链","url":"/2019/10/29/可逆的马尔可夫链/","content":"\n参考：\n\n[stochastic-I-Time-Reversibility](http://www.columbia.edu/~ks20/stochastic-I/stochastic-I-Time-Reversibility.pdf)\n\n[马尔可夫链](https://blog.csdn.net/u011898542/article/details/88018164)\n\n## 马尔可夫链\n\n### 定义\n\n（1） **马尔可夫链（Markov chain）**\n\n马尔可夫链是一组具有马尔可夫性质的离散随机变量的集合，可以表示为$X=\\{X_n:n>0\\}$，其中一维指数集为可数集，随机变量的取值都在可数集$S$内，即$X=s_i,s_i \\in S$，且下一步的随机变量$X_{t+1}$在给定其当前步随机变量$X_t$后与其余的随机变量条件独立，即随机变量的条件概率满足\n\n$$P(X_{t+1}|X_t, \\dots, X_1)=P(X_{t+1}|X_t)$$\n\n该性质即为**马尔可夫性质**，也称为“无记忆性”。\n\n可数集$S \\in Z$称为*状态空间（state space）*，马尔可夫链在状态空间内的取值称为*状态（state）*，马尔可夫链的指数集被称为*步（step）*。\n\n（2） **k-阶马尔可夫链（n-order Markov chain）**\n\nk-阶马尔可夫链拥有k阶的记忆性，可视为马尔可夫链的推广。类比马尔可夫链的定义，k-阶马尔可夫链满足如下条件\n\n$$P(X_{t+1}|X_t, \\dots, X_1)=P(X_{t+1}|X_t, \\dots, X_{t-k+1})$$\n\n（3） **马尔可夫过程（Markov process）**\n\n马尔可夫过程也被称为连续时间马尔可夫链，是马尔可夫链的推广，其状态空间是可数集，但一维指数集不再有可数集的限制，可以表示连续时间，其马尔可夫性质可表示为\n\n$$P(X(t+u)=s_j | X(t)=s_i) = P(X(u)| =s_j | X(0)=s_i))$$\n\n### 转移理论\n\n马尔可夫链中随机变量的状态随*步*的变化被称为演变（evolution）或转移（transition）。\n\n（1） **转移概率（transition probability**\n\n马尔可夫链中的状态间的单步转移概率可定义为随机变量间的条件概率$P_{ij}=P(X_{n+1}=s_j | X_n=s_i)$。\n\n（2） **转移矩阵（transition matrix）**\n\n若一个马尔可夫链的状态空间是有限的，则将所有状态间的的单步转移概率按矩阵排列，得到转移矩阵\n\n$$P=\n    \\begin{matrix}\n    P_{00} & P_{01} & \\dots & P_{0n} \\\\\n    P_{10} & P_{11} & \\dots & P_{1n} \\\\\n    \\dots & \\dots & \\dots & \\dots \\\\\n    P_{n0} & P_{n1} & \\dots & P_{nn} \\\\\n    \\end{matrix}\n$$\n\n马尔可夫链的转移矩阵是右随机矩阵（right stochastic matrix），每行元素之和等于1。在给定初始状态概率和状态转移矩阵，我们即可以确定该马尔可夫链的有限维分布（finite-dimensional distribution）。\n\n（3）**转移图（transition graph）**\n\n我们也可以通过转移图来刻画一个马尔可夫链的转移过程，一个状态表示为 一个节点，两个状态间的转移概率表示为一条加权边。\n\n对马尔可夫链中的两个状态$s_i$和$s_j$，若在转移图中存在一条路径$ik_0k_1\\dots j$，有$P_{i}P_{k_0}P_{k_1}\\dots P_{j}>0$，则称$s_i$到$s_j$**可达**，若$s_i$和$s_j$互相可达，则称$s_i$和$s_j$之间**连通**。连通是一组等价关系，因此多个相互连通的状态可以构建一个等价类，包含尽可能多状态的等价类称为**连通类**。\n\n给定状态空间的一个子集，若马尔可夫链进入该子集后无法离开，则称该子集为**闭合集**。若一个闭合集中只有一个状态，则该状态是**吸收态**。若一个马尔可夫链从任意状态出发最终都会进入吸收态，则称该马尔可夫链为**吸收马尔可夫链（absorbing Markov chain）**。\n\n\n### 性质\n\n不同的马尔可夫链可能会具备不同的性质。\n\n（1）**不可约性（irreducibility）**\n\n如果一个马尔可夫链的状态空间仅有一个连通类，即状态空间的全体成员，则该马尔可夫链具有不可约性。马尔可夫链的不可约性意味着在其演变过程中，随机变量可以在任意状态间转移。\n\n（2）**重现性（recurrence）**\n\n若马尔可夫链在到达一个状态后，在演变中能反复回到该状态，则该状态具有**重现性**，否则该状态具有**瞬变性（transience）**。若状态$s_i$具有重现性，则可计算其平均重现时间（mean recurrence time）$E(T_i)$，若$E(T_i)<\\infty$，则该状态是**正重现的（positive recurrent）**，若$E(T_i)=\\infty$，则该状态是**零重现的（null recurrent）**，意味着马尔可夫链两次访问该状态的时间间隔的期望是正无穷。\n\n推论：若有限个状态的马尔可夫链是不可约的，则其所有状态是正重现的。\n\n（3）**周期性（periodicity）**\n\n一个正重现的马尔可夫链可能具有周期性，即在其演变中，马尔可夫链能够按大于1的周期重现其状态。\n\n推论：若不可约的马尔可夫链有周期性状态A，则该马尔可夫链的所有状态为周期性状态。\n\n推论：若状态A与状态B连通，则A与B周期相同。\n\n（4）**遍历性（ergodicity）**\n\n若马尔可夫链的一个状态是正重现的和非周期的，则该状态具有遍历性。若一个马尔可夫链是不可约的，且有某个状态是遍历的，则该马尔可夫链的所有状态都是遍历的，被称为遍历链。\n\n推论：若多个状态的马尔可夫链包含吸收态，则该马尔可夫链不是遍历链。\n\n### 稳态分析\n\n（1）**平稳分布（stationary distribution）**\n\n若一个马尔可夫链的状态空间存在概率分布\n\n$$\\pi=\\pi P$$\n\n则称$\\pi$是该马尔可夫链的平稳分布。\n\n对于一个不可约的马尔可夫链，当且仅当其存在唯一平稳分布，该马尔可夫链是正重现的，且平稳分布有如下表示\n\n$$\\pi(s_i)= \\frac{1}{E(T_i)}$$\n\n$E(T_i)$是状态$s_i$的平均重现时间。\n\n马尔可夫链存在平稳分布的充要条件是其存在正重现状态。若一个马尔可夫链包含多个由正重现状态组成的连通类，则每个连通类都拥有一个平稳分布，且演变得到的稳态取决于初始分布。\n\n（2）**极限分布（limiting distribution）**\n\n若一个马尔可夫链的状态空间存在概率分布\n\n$$\\lim_{n \\to \\infty}{p(X_n=s_i)}=\\pi(s_i)$$\n\n则称$\\pi$是该马尔可夫链的极限分布,极限分布与初始分布无关。\n\n*极限分布一定是平稳分布，但反之不成立，例如周期性的马尔可夫链可能具有平稳分布，但周期性马尔可夫链不收敛于任何分布，其平稳分布不是极限分布。*\n\n（3）**极限定理（limiting theorem）**\n\n两个独立的遍历链各自给定任意初始分布，如果他们有相同的转移矩阵，那么当时间步趋于无穷时，两者极限分布间的差异趋于0。该定理表明若马尔可夫链是遍历的，则其极限分布是平稳分布。\n\n（4）**遍历定理（ergodic theorem）**\n\n若一个马尔可夫链为遍历链，其对某一状态的访问次数与时间步的比值，在时间步趋于无穷时趋近于平均重现时间的倒数，即该状态的极限平稳分布。\n\n遍历定理的证明依赖于强大数定律（Strong Law of Large Numbers, SLLN），表明遍历链无论初始分布如何，在经过足够长的演变后，对其中一个随机变量进行多次观测和对多个随机变量进行一次观测都可以得到极限分布的近似。由于遍历链满足极限定理和遍历定理，因此MCMC通过构建遍历链以确保其在迭代中收敛于平稳分布。\n\n（5）**平稳马尔可夫链（stationary Markov chain）**\n\n若一个马尔可夫链拥有唯一的平稳分布且极限分布收敛于平稳分布，则该马尔可夫链是**平稳马尔可夫链**，也被称为**齐次马尔可夫链（time-homogeneous Markov chain）**。\n\n（6）**可逆马尔可夫链（reversible Markov chain）**\n\n一个平稳马尔可夫链也是可逆马尔可夫链，其平稳分布对任意两个状态满足\n\n$$\\pi(s_i) P(X_{n+1}=s_j|X_n=s_i) = \\pi(s_j) P(X_{n+1}=s_i|X_n=s_j)$$\n\n或者简单写成 $\\pi_i P_{ij}=\\pi_j P_{ji}$。\n\n*平稳马尔可夫链与可逆马尔可夫链互为充要条件。？？？*\n\n### 求解稳态分布\n\n（1）**通过马尔可夫链的可逆性求解其平稳分布**\n\n可逆的马尔可夫链一定存在平稳状态，且可以通过其可逆性，求解其平稳分布。\n\n**例（无向加权连通图上的随机游走）**考虑一个n个节点的无向连通图，任意两个节点$i$和$j$之间若存在一条边，其权重$w_{ij}=w_{ji}>0$，否则$w_{ij}=w_{ji}=0$。在该图上进行随机游走，节点$i$到$j$的状态转移概率为\n\n$$P_{ij}=\\frac{w_{ij}}{\\sum_{k}{w_{ik}}}$$\n\n该随机游走所刻画的马尔可夫链为可逆的马尔可夫链。所以任意两个节点$i$和$j$有\n\n$$\\pi_i P_{ij}=\\pi_j P_{ji} \\to \\frac{\\pi_i}{\\sum_{k}{w_{ik}}} = \\frac{\\pi_j}{\\sum_{k}{w_{jk}}}$$\n\n所以，对所有的节点$i$有\n\n$$\\frac{\\pi_i}{\\sum_{k}{w_{ik}}} = C \\to \\pi_i=C\\sum_k{w_{ik}}$$\n\n因为$\\pi$是一个在所以状态上的概率分布，有$\\sum_i{\\pi_i}=1$，所以\n\n$$\\sum_i{(C\\sum_k{w_{ik}})}=1 \\to C=\\frac{1}{\\sum_i{\\sum_k{w_{ik}}}}$$\n\n最终求得该马尔可夫链的平稳分布为\n\n$$\\pi_i=\\frac{\\sum_k{w_{ik}}}{\\sum_i{\\sum_k{w_{ik}}}}$$\n\n若是考虑无权图是场景，即任意两个节点$i$和$j$之间若存在一条边，其权重$w_{ij}=w_{ji}=1$，记$d_i$为节点$i$的度，则其平稳分布为\n\n$$\\pi_i=\\frac{\\sum_k{w_{ik}}}{\\sum_i{\\sum_k{w_{ik}}}} = \\frac{d_i}{\\sum_i{d_i}} = \\frac{d_i}{2|E|}$$","tags":["theoretical analysis","random walk"]},{"title":"知识图谱和图数据库","url":"/2019/10/23/知识图谱和图数据库/","content":"\n参考博客：\n\n[知新温故，从知识图谱到图数据库](https://blog.csdn.net/wireless_com/article/details/86486289)\n\n[知识图谱-浅谈RDF、OWL、SPARQL](https://www.jianshu.com/p/9e2bfa9a5a06)\n\n### 知识图谱\n\n#### 需求与定义\n深度学习、机器学习等人工智能技术，要在行业中得到应用，首先要对行业已有的知识有足够的认知。知识图谱可以用来描述真实世界中存在的各种实体和概念，以及他们之间的强关系。构建和完善知识图谱是事物分析学习的基础。\n\n知识图谱可以理解成是由很多知识点和它们之间的关系连接构成的语义网络。也可以简单的将一个知识图谱理解成一个*多关系图*，即图中包含多种类型的节点和多种类型的边。在知识图谱里，通常用*实体*来表达图里的节点，即现实世界中的事物，用*关系*来表达图里的边，即不同事物之间的某种联系，实体和关系也通常拥有各自的属性。\n\n#### 设计与构建\n设计某行业的知识图谱需要对业务本身有足够的理解，从业务逻辑出发，并考虑业务未来可能的变化。要把知识图谱设计成轻量级的存储载体，决定哪些数据需要放在知识图谱中。\n\n构建知识图谱，首先要进行*数据抽取*，即把数据从不同的数据源中提取出来，进行统一的管理，这其中需要用到自然语言处理（Natural Language Processing，NLP）中的一些技术，包括实体命名识别、关系抽取、实体统一、指代消解等。\n\n#### 存储方式\n知识图谱主要有两种存储方式：RDF和图数据库。\n\n##### RDF\n\nRDF，即资源描述框架（Resource Description Framework），是W3C提倡的一个数据模型，用来描述万维网上的资源及其相互间的关系。RDF数据模型的核心包括资源（resource）、属性（property）、RDF陈述（RDF statement）。\n\n*资源*，表示一个具体的事物或抽象的概念。每个资源拥有一个统一资源标识符（URI）来标识。\n\n*属性*，表示资源之间的联系，每个属性也使用唯一的URI来标识。\n\n*RDF陈述*，描述某个资源特定属性及其属性值，表示为（主语——谓语——宾语）的三元组结构。\n\n*RDF图*，由很多RDF三元组组成的一个集合可以构成一个RDF图。RDF图也可以看成是节点和边均带有标签的有向图结构。\n\n##### 图数据库\n\n图数据库是非关系型数据库（Not Only Structured Query Language, NoSQL）的一种，重点描述数据之间关系的数据库。\n\nRDF与图数据库的区别在于，RDF一个重要的设计原则是数据的易发布以及共享，图数据库则把重点放在了高效的图查询和搜索上。其次，RDF以三元组的方式来存储数据而且不包含属性信息，但图数据库一般以属性图为基本的表示形式，所以实体和关系可以包含属性，这就意味着更容易表达现实的业务场景。RDF常应用于学术场景，而图数据库常用于工业场景。\n\n### 图数据库\n\n#### 关系型数据库\n传统的关系型数据库更注重刻画实体内部的属性，实体与实体之间的关系通常都是利用外键来实现，将所有的数据用竖立的堆栈表示，并且保持它们直接的关系，在求解关系的时候通常需要join操作，而join操作通常又是耗时的。常常被优化用于聚合数据，而非高度关联的数据。对于高度关联的数据存储与分析就需要求助于NoSQL了。\n\n#### 非关系型数据库\n非关系型数据库（Not Only Structured Query Language, NoSQL）可以分为4类：key-value，文档型，列存储和图数据库。\n\nKey-Value模型适合用于简单的数据或者列表。当数据之间不断交互关联时，实际上更需要一张图。\n\n文档型NoSQL用来管理文档。在传统的数据库中，信息被分割成离散的数据段，而在文档数据库中，文档是处理信息的基本单位。文档可以很长，可以很复杂，可以是无结构的，与字处理文档类似。一个文档相当于关系数据库中的一条记录。文档型NoSQL用文档进行层次划分，而自由的数据规划也很容易被表示成一颗树。成长为一张图的话，文档之间的关联需要更有代表性的数据结构来存储。\n\n列存储。\n\n从应用开发的角度看，这些NoSQL数据库不处理关系，没有数据结构建模或存储数据关系，没有查询结构支持些数据关系。而且，在应用中连接数据同样需要JOIN，操作 对事务没有 ACID 的支持。因此，这三种 NoSQL 数据库也不适用于有实时价值的数据关系。\n\n#### 图数据库\n图数据库是基于数学里图论的思想和算法而实现的高效处理复杂关系网络的数据库。图形数据库善于高效处理大量的、复杂的、互连的、多变的数据，计算效率远远高于传统的关系型数据库。\n\n图中每个节点代表一个对象，节点之间的连线代表对象之间的关系。节点可带标签，节点和关系都可以带若干属性。关系可以将节点组织成任意的结构，允许一张图被组织成一个列表，一棵树，一张地图，或者一个复杂的实体。这个实体本身也是由复杂的，关系高度关联的结构组成。\n\n#### 现有的图数据库\n\nNeo4j\n\ntitan\n\narangoDB\n\nOrientDB\n\nGUN","tags":["graph database"]},{"title":"CNARW 基于公共邻居感知的快速随机游走","url":"/2019/10/18/CNARW-基于公共邻居感知的快速随机游走/","content":"\n[Yongkun Li, Zhiyong Wu, Shuai Lin, Hong Xie, Min Lv, Yinlong Xu, John C.S. Lui. \"Walking with Perception: Efficient Random Walk Sampling via Common Neighbor Awareness\". 35th IEEE International Conference on Data Engineering (ICDE), Macau, SAR, China, April 2019.](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8731555)\n\n### 图中心性分析\n\n#### 应用场景\n\n近年来，对社交网络分析能更准确的进行一些商业活动，比如病毒式营销和产品推荐等。通过分析图上的各种图中心性可以获取社交网络中用户的属性，进而用来促进商品营销。可以通过下面具体的两个例子来直观的说明。\n\n（1）**网络平台投资**，根据病毒式营销中的“口碑效应（word-of-mouth）”，一个用户购买商品时可能会受到其朋友的影响而去买同一件商品。所以利用在线社交网络（OSN）可以很好的进行商品营销。不同的OSN会呈现不同的潜力，比如不同的OSN中用户的活跃性和影响力会有所不同。所以一个商家来说，**选择哪个网络平台进行投资能吸引到最多的用户购买商品？**这个问题可以通过*估算OSN中所有*用户对*之间的平均相似性*来衡量。\n\n（2）**病毒式营销中的捆绑策略**，将多个商品在一起打折捆绑销售也是一种常见的营销策略。但是**具体选择哪些商品放在一起捆绑销售能带来最大的销售额**。这个问题可以通过*估算每个商品在用户之间的兴趣分布，捆绑有相似分布的商品*来解决。\n\n#### 计算挑战\n\n想要准确的计算图上的这些中心性不是件简单的事情，主要有如下挑战。\n\n（1）OSN的图规模通常很大，例如Facebook的用户数已经超过20亿。\n\n（2）为了保护用户的隐私，很多OSN只允许第三方代理通过固定的速度受限的API接口访问网络数据。\n\n为了分析这些大规模图数据，**图采样**是个常用的技术，通过分析采样的一些有代表性的样本，而避免遍历整个网络数据，这样大大减少了对网络的访问开销。\n\n### 随机游走采样\n\n随机游走采样是这类应用场景的一个主流采样算法，因为它扩展性强且实施简单。\n\n#### 简单随机游走\n\n考虑一个无向连通图$G(V,E)$，$N(v)$表示图中节点v的邻居集合，$deg(v)=|N(v)|$表示节点v的度。\n\n图上简单随机游走过程是：首先从图中随机选取一个节点，然后重复从当前节点中随机挑选一个它的邻居节点进行跳转。\n\n这个过程可以看成是一个有限的马尔科夫链，每一步访问的节点id就马尔科夫链的状态。每一步的状态转移概率可以表示成一个$|V|\\times |V|$的概率转移矩阵$P$，$P_{uv}$为从节点u通过一步random walk走到节点v的概率。简单随机游走（Simple Random Walk, SRW）的状态转移矩阵可以表示为$P_{uv}=1/deg(u), \\quad if \\quad v \\in N(u)$，否则$P_{uv}=0$。\n<!-- $P_{uv}= \\begin{cases} 1/deg(u) & \\text{if v \\in N(u)}\\\\0 & \\text{otherwise} \\end{cases}$ -->\n\n很多步以后达到收敛状态，即随机游走访问图中每个节点的概率呈现稳态分布。SRW收敛后的稳态分布可以表示成：$\\pi (u)=deg(u)/(2|E|)$。\n\n#### 随机游走采样\n\n随机游走的采样是在随机游走收敛以后开始采样收集样本。根据收集到的样本和收敛后的稳态分布，我们就可以对感兴趣的一些图测量指标进行无偏估计。\n\n##### 收集样本\n\n收集样本节点时，一般有两种方法：（1）*连续采样*，在图中只开启一条random walk，收敛以后持续采集样本直到收集到足够的样本节点。（2）*独立采样*，在图中同时开启多条random walk，每条walk收敛以后只采集一个样本节点。这两种方法都需要在random walk收敛以后才能开始收集样本，然后根据稳态分布进行无偏估计。\n\n##### 无偏估计\n\n假定图上的一个测量指标可以表示成一个函数$f:V \\to R$，在一个达到稳态分布$\\pi$的随机游走上收集到的足够的样本上应用函数$f$，即可得到一个估计值$E_\\pi[f] \\stackrel{\\mathrm{\\Delta}}{=} \\sum_{u \\in V}{f(u)\\pi(u)}$。该估计值的准确性可由**强大数定律（the Strong Law of Large Numbers, SLLN）**保证。\n\n#### 加速随机游走收敛\n\n从开始到达稳态分布的持续时间称为“the burn-in period”，在真实的OSN中，这个阶段通常需要一个很大的计算开销，因为通常需要很多步以后才能达到收敛。在给定一个采样预算（总共访问的节点数）的情况下，除去收敛开销，我们只能采样少量的有代表性的样本，因此分析的准确性就会收到影响。所以随机游走采样一个重要的问题就是：**如何加速随机游走在大规模图上的收敛？**\n\n现在有两类加速随机游走收敛的方法：\n\n（1）增加图的导通性（conductance），这类方法通常需要全局的图信息，所以在现实场景中通常不可行。\n\n（2）修改每一步walk的转移概率，这类方法通常是利用walk的历史信息，并且只需要访问少量的局部图信息。\n\n### CNARW\n\n这篇论文跟随第二类加速随机游走收敛的方法，提出公共邻居感知的随机游走（Common Neighbor Aware Random Walk）CNARW，通过利用walk前一步访问过的节点信息来优化下一步跳转的邻居选择。具体的，CNARW考虑当前节点和下一跳候选节点的公共邻居数量来进行下一跳的邻居选择。\n\n#### 主旨思想\n\n考虑简单随机游走收敛慢的主要原因：一般的社交网络都有很高的*聚类*特性，即图中形成很多的社区结构，社区内部的节点连接紧密，社区之间连接稀疏。所以简单随机游走的过程中，walker均匀随机地选取当前节点的一个邻居跳转，大概率会选到社区内部的节点，而且很容易陷入当前子图，只在社区内部反复游走在已经访问过的节点，只有很小的概率能走出当前的子图，从而探索到全局的图信息。这大大减慢了简单随机游走的收敛速度。\n\n所以为了加速随机游走的收敛，我们需要尽量减少对已经访问过的节点的频繁的再次访问。该论文提出，在每一步随机游走选择的时候，不同于简单随机游走的均匀随机选择，我们给访问过的节点小一点的访问概率，而给有更大机会能探索更多未访问的节点的那些节点大一点的访问概率。该论文根据下一跳候选节点的信息以及一些历史访问信息，重新设置每一步随机游走的转移概率，具体考虑如下两个方面。\n\n（1）若一个候选节点的*度*，即邻居节点数，越大，则它可能访问到更多未访问的节点的概率也就越大。\n\n（2）若一个候选节点与当前节点的公共邻居数越少，则随机游走通过该候选节点再次回到当前节点的概率也就越小。\n\n所以，在各个候选节点中，我们应该给度数高且与当前节点公共邻居数少的节点更大的转移概率。通过这种加权游走的策略，CNARW可以更快的收敛。\n\n\n#### 算法设计\n\n下面介绍通过一些公式化的表示和理论支持而形成的CNARW的具体算法设计。\n\n**（1）首先引入集合导通性（set conductance）**\n\n**定义：集合导通性（set conductance）**，用$G=(V,E)$表示一个无向图，$C \\in V$是图中的一个节点集，集合$C$的导通性$\\phi (C)$定义为\n$$\\phi (C)=\\phi (C,V-C)=|E_{C,V-C}| / Vol(C),$$\n其中$E_{C,V-C}={(u,v) | u \\in C, v \\in V-C}$，$Vol(C)=\\sum_{u \\in C}{deg(u)} $。\n\n集合导通性可以看成是节点集合$C$和它的差集之间的边数除以$C$内部的边数。一个节点集与图中其他节点的连接数越多，节点集内部的连接数越少，则该节点集的导通性越大，随机游走被困在该节点集中可能性也就越小。\n\n**（2）接下来公式化下一跳的节点选择**\n\n假设随机游走当前停留在节点$u$，定义$S={u} \\cup N(u)$为包含当前节点和它的邻居节点的*边界节点集（frontier nodes）*。则我们可以用$\\phi(S)$来表示随机游走可能被困在$S$的概率程度。而其中一个候选节点$v$对$\\phi(S)$的贡献度可以表示为$\\Delta \\phi_v = \\phi(S)-\\phi(S_{-v})$，其中$\\phi(S_{-v})=S \\setminus {v}$。\n\n$$\\Delta \\phi_v = \\frac{ (1-\\phi(S))-2(C_{uv}+1)/deg(v) }{ (\\sum_{i \\in S}{deg(i)})/deg(v)-1 },$$\n\n其中$deg(v)$表示节点$v$的度，$C_{uv}$表示节点$u$和节点$v$的公共邻居数。在$deg(v)$不变的情况下，$C_{uv}$越大，则$\\Delta \\phi_v$越小。而在固定$C_{uv}$不变的情况下，$deg(v)$越大，则$\\Delta \\phi_v$也越大。\n\n对于每个候选节点$v \\in N(u)$，$\\Delta \\phi_v$可以作为下一跳节点选择合适程度的测量指标。$\\Delta \\phi_v$越大，即度数高且与当前节点公共邻居数少的节点，CNARW给与节点$v$在下一跳邻居选择中更高的权重。\n\n**（3）转移矩阵的设计**\n\n直觉来说，可以将节点$u$到节点$v$的转移概率$P_{uv}$设置为一个正比于$\\Delta \\phi_v$的值，比如为了避免$\\Delta \\phi_v$的复杂计算，我们可以简单的设置为$P_{uv}=1-\\frac{C_{uv}}{deg(v)}$。\n\n但是为了保证随机游走的*可逆性（reversible）*，从而能够简单地获得它的稳态分布。因此，我们设计转移概率时需要保证*对称性（symmetric）*，即$P_{uv}=P_{vu}$，具体CNARW设置为\n\n$$P_{uv} \\varpropto 1-\\frac{C_{uv}}{min(deg(u),deg(v))}.$$\n\n我们也可以考虑其他的形式，比如上式中的分母也可以替换成$deg(u)+deg(v)$或者$max(deg(u),deg(v))$，也能保证对称性。但是使用$min(deg(u),deg(v))$可以避免当$deg(u)$很大时，$P_{uv}$之间差别很小的情况。\n\n**（4）随机游走过程**\n\n为了实现满足上述转移概率的随机游走，且减少计算开销，CNARW采用了一种*带拒绝的随机游走策略*。具体的，在每一步随机游走时：\n\n1）我们首先从当前节点$u$的邻居节点$N(u)$中随机均匀的选取一个候选节点$v$；\n\n2）然后计算节点$v$的接收概率，表示为$q_{uv}=1-\\frac{C_{uv}}{min(deg(u),deg(v))}$；\n\n3）我们以$q_{uv}$的概率接收然后将随机游走跳转到节点$v$，以$1-q_{uv}$拒绝，并重新回到1）选取一个候选节点；\n\n4）重复上述过程直至随机游走成功转发；\n\n这种*带拒绝的随机游走策略*的好处是我们只需要访问被接收的节点$v$及其之前访问过的节点信息，而不需要访问节点$u$的所有邻居，从而减少了查询开销。\n\n**（5）转移概率归一化**\n\n上述的随机游走过程中，会有一定的概率$P_{uu}= 1 - \\frac{1}{deg(u)}\\sum_{v \\in N(u)}{(1-\\frac{C_{uv}}{min(deg(u),deg(v))})}$跳回到当前节点。为了避免这种情况，我们对转移概率进行归一化矫正，$P_{uv}={p'_{uv}/(1-p'_{uv})}$。\n\n#### 稳态分布\n\n**定理（唯一存在性）**：给定无向连通图G(V,E)，在G上运行CNARW存在唯一的一个稳态分布。（不可约）\n\n**定理（节点的稳态分布）**：CNARW的稳态分布$\\pi$满足：$\\frac{\\pi(u)}{\\pi(v)}=\\frac{deg(u)(1-p'_{uu})}{deg(v)(1-p'_{vv})}$，所以我们可以得出$\\pi(u)=Z \\times deg(u) \\times (1-p'_{uu})$，其中Z是一个归一化的常数。\n\n**定理（边的稳态分布）**：CNARW收敛后，$\\pi(e_{uv})=\\pi(u) \\times P_{uv}$。\n\n#### 扩展利用更多历史节点信息\n\n上述介绍的CNARW算法是只利用了当前节点（一步历史）的信息，直观来看，考虑更多的历史信息可以进一步加速随机游走的收敛。所以该论文中也考虑了扩展到考虑多个历史访问节点的的信息，来设计随机游走的转移概率。\n\n我们用H来表示考虑的之前访问的节点个数，$H=0$和$H=1$分别对应SRW和CNARW的场景。$H \\geq 2$时，重新定义*边界节点集（frontier set）*$S = N(x_H) \\cup N(x_{H-1}) \\cup \\dots \\cup N(x_2) \\cup N(u)$。此时，候选节点$v$的对$\\phi(S)$的贡献度$\\Delta \\phi_v^H$为：\n\n$$\\Delta \\phi_v^H = \\frac{((1-\\phi(S))-2(C_{Sv}+1)/deg(v) )}{(\\sum_{i \\in S}{deg(i)})/deg(v)-1}.$$\n\n该论文在实验中测试了H对收敛速度的影响，结果表明$H=1$时的性能提升就已经足够和有力。更大的H带来的进一步的性能提升并不显著。\n\n### 基于CNARW的无偏采样\n\n基于CNARW，这篇论文提出了一种采样算法，并且提供了高效的无偏估计方法并且提供理论证明来保证无偏估计的准确度。\n\n#### 无偏点采样\n\n#### 无偏边采样\n\n\n### 实验 \n\n（1）实验环境和数据集。\n\n服务器：2 Intel Xeon E5-2650 2.60GHz CPUs & 64GB RAM。\n\n数据集：（a）4个大规模数据集：Google Plus, Flickr, DBLP and LiveJournal；（b）3个小规模数据集： Facebook, CaGaQc, and Phy1（用于计算第二大特征值）。\n\n对比算法：SRW, NBRW, CNRW。\n\n（2）性能指标定义。\n\n（3）收敛速度，包括实验统计的收敛需要的步数以及理论计算的第二大特征值。\n\n（4）估算误差和查询开销。\n\n（5）H的影响。\n\n（6）转移矩阵的设计。\n\n（7）具体应用场景。\n\n* 网络平台投资\n\n* 病毒式营销中的捆绑策略\n\n实验结果表明，（1）CNARW最多能将当前的随机游走算法SRW，NBRW，CNRW的收敛所需的步数减少71.9%。（2）在实现相同的准确度的情况下，CNARW最多能减少35.7%的查询开销。\n\n\n\n","tags":["random walks","theoretical analysis","graph sampling"]},{"title":"Deeper Inside PageRank","url":"/2019/10/17/Deeper-Inside-PageRank/","content":"\n[Deeper Inside PageRank, Langville A;Meyer C, Internet Mathematics 2004](https://www.internetmathematicsjournal.com/article/1388)\n\n这是一个关于PageRank的综述性的调研报告，包含与PageRank相关所有问题，涵盖了*基础的PageRank模型*，*计算方法*，*稳态分布的存在性和唯一性分析*，*收敛速度*，*存储问题*，*基础模型上的改动*，*传统计算方法的改进*等等。\n\n### PageRank的由来\n\n当前的搜索引擎一般通过一个两步的过程来检索与用户查询相关的页面，1）信息检索（Information Retrieval），检索找出所有相关的页面（通常能找出几千个相关的页面 ）；2）**页面排序**（Page Rank），对检索出的页面按照某种准则进行排序，按照顺序展示给用户。PageRank是一个大家熟知的页面排序算法，它基于网页之间的超链接结构，计算出一个页面的重要程度，用于Google搜索引擎。（实际上在Google会综合考虑IR（Information Retrieval） score和PR（PageRank） score决定最终的网页排序，这里我们只关注于PageRank。）\n\nPage, Lawrence和Brin, Sergey于1998年发表了论文，[Page, Lawrence & Brin, Sergey & Motwani, Rajeev & Winograd, Terry. (WWW1998). The PageRank Citation Ranking: Bringing Order to the Web.](http://web.mit.edu/6.033/2004/wwwdocs/papers/page98pagerank.pdf)，第一次提出PageRank算法，并基于此创办了Google公司。\n\n### 基础的PageRank模型\n\n#### 基本概念\n**马尔可夫链（Markov chain）**，考虑状态空间中，从一个状态到另一个状态的转换的随机过程。某一时刻状态转移的概率只依赖于它的前一个状态。这种特定类型的“无记忆性”称作*马尔可夫性质*。满足*马尔可夫性质*的随机过程称为[*马尔可夫链*](https://blog.csdn.net/bitcarmanlee/article/details/82819860)。\n\n**随机性（stochastic）**，矩阵的随机性表示矩阵中的所有元素都是非负的，且每一行的元素和为1。\n\n**不可约性（irreducible）**，不可约的数学定义是“如果从C 中任一状态出发经有限步转移到另一状态的概率都大于0，则称C为不可约闭集”，即任意一种状态都可能转化到任意另外一种状态，即不存在多余的状态（可减少的状态）。\n\n**素矩阵（primitive matrix）**，素矩阵是指自身的某个次幂为正矩阵的矩阵。设$$A$$为一个$$n \\times n$$的方阵，如果存在正整数k使得矩阵$$A^k>0$$那么，称矩阵A为素矩阵。\n\n#### 状态转移矩阵\n\n考虑网页之间的链接关系，可以看成一个有向图，图中节点表示页面，边代表页面之间的超链接关系。一个用户随机浏览网页的过程可以看做是一个在图上节点之间跳转的*随机游走*过程，也是一个马尔可夫链。\n\n考虑各节点之间的转移概率，可以表示成一个矩阵$$P$$，其中$$P_{ij}$$表示通过一步从页面$$i$$跳转到页面$$j$$的概率。例如，假设从一个页面有相等的概率跳转到它所链接的任意页面，则$$P_{ik}=1/d_i, \\forall k \\in N(i)$$（其中$$d_i$$为节点i的出度，$$N(i)$$为节点i的出边邻居集）。也根据自定义的加权方式设置概率分布$$v^T$$，公式表示为$$P'=P+av^T$$，其中$$a$$为一个构造的向量，其中如果i为悬挂节点，则$$a_i=1$$，否则$$a_i=0$$。\n\n由于图中存在*悬挂节点（dangling node）*，即该节点没有出边邻居，此时$$P_i=0^T$$，使得该转移矩阵不满足*随机性*，当随机游走跳转到悬挂节点时，就会停止。为了修正这种情况，我们修改$$P'_i=1/ne^T$$（其中n为图中的总节点数），或者一个自定义的个性化的的随机向量$$P'_i=v^T$$（personalized vector）。\n\n为了保证该马尔可夫链能够收敛得到一个概率分布的稳态向量（stationary vector），也就是最终算得的PageRank值，该马尔可夫链需要满足*不可约性*。所以需要对该状态转移矩阵做进一步的修改，$$P''= \\alpha P'+(1-\\alpha)ev^T/n, 0 \\leq \\alpha \\leq 1$$。\n\n这样通过修正的状态转移矩阵有:\n\n$P''= \\alpha P'+(1-\\alpha)ev^T/n$，\n\n$ \\quad = \\alpha (P+av^T)+(1-\\alpha)ev^T/n$，\n\n$ \\quad = \\alpha P+(\\alpha a+(1-\\alpha)e)v^T$, 其中$0 \\leq \\alpha \\leq 1$，\n\n图中的每个节点都可以通过一步直接到达另一个节点，使得该马尔可夫链满足不可约的性质。该矩阵是一个素矩阵，即通过幂法(power method)迭代计算可以得到一个收敛的稳态向量$$\\pi^T$$。\n\n### 计算PageRank\n\n上述状态转移矩阵代表的马尔可夫链，最终能达到一个稳定状态，即存在一个稳态分布$$\\pi^T$$，使得$$\\pi^TP''=\\pi^T$$，其中$$\\pi^T$$是一个概率向量，$$\\pi^Te=1$$。通过计算该稳态向量$$\\pi^T$$，即得到各个页面的PageRank值，其中$$\\pi^T_i$$即为页面i的PageRank值。\n\n#### 幂法迭代计算\n\n幂法迭代计算是一个传统的计算特征向量问题的方法。\n\n* 设置一个任意的初始向量$$x^{(0)T}$$，通常$$x^{(0)T}=e^T/n$$。\n* 迭代计算：$$x^{(k)T}=x^{(k-1)T}P''$$，即$x^{(k)T}=\\alpha x^{(k-1)T}P+(\\alpha x^{(k-1)T}a+(1-\\alpha))v^T$。\n\n这样，通过一轮又一轮的*向量矩阵相乘*，迭代计算直至达到终止条件，则可计算出稳态向量$$\\pi^T$$。每一轮计算中，需要的$nnz(P)$次浮点运算，$nnz(P)$为P中非零元素的个数。一般P为一个稀疏矩阵，P中每一行的非零元素的个数即为图中每个节点的度数，一般平均为3-10，所以$\\omicron(nnz(P)) \\approx \\omicron(n)$。Brin和Page在论文中指出，一般幂法迭代运算很快就可以达到收敛，通常只需要50-100次迭代运算。\n\n#### 收敛性\n状态转移矩阵$$P''$$的不可约性（irrducibility）保证了该马尔可夫链的唯一一个稳态分布向量的存在性。\n\n而$$P''$$的素性（primitivity）保证了通过幂法迭代计算能够收敛，算出该稳态分布向量。\n\n#### 收敛速度\n\n[矩阵的谱用于分解一个矩阵](https://blog.csdn.net/qq997843911/article/details/88189426)，对于上述的稳态分布$$\\pi^TP''=\\pi^T$$，$$\\pi^T$$就是$$P''$$的一个特征向量，对应的特征值就是1。对$$P''$$所有的特征向量$$v_i^T$$，有$$v_i^TP''=v_i^T c_i$$，其中$$c_i$$为对应的特征值，对$$v_i^T$$的每一轮更新，所有节点的值变为原来的$$c_i$$倍，当$$0 < c_i < 1$$，所有节点值呈指数衰减，直至趋近于0。\n\n我们可以用谱的方法，将上述马尔可夫链的任意初始状态$$x^{(0)T}$$分解成\n\n$x^{(0)T}=v_1^T+c_2 v_2^T+c_3 v_3^T+\\cdots$\n\n对于状态转移矩阵$$P''$$，其最大特征值为1，对应于特征向量$$v_1^T$$，即稳态向量$$\\pi^T$$。其他特征向量$$v_2^T, v_3^T, \\cdots$$对应于特征值$1>c_2>c_3>\\cdots >-1$。则经过t步迭代计算，到达状态$$x^{(t)T}$$\n\n$x^{(t)T}=v_1^T+c_2^t v_2^T+c_3^t v_3^T+\\cdots$\n\n其中$$v_i^T$$部分的分量保持不变，即为我们所求的稳态向量，其他分量随着t增长而指数衰减，最后整个状态$$x^{(t)T}$$收敛趋近于平衡状态。而这个过程的**收敛速度（rate of convergence）**取决于上述非平衡分量中衰减得最慢的那一个，即**第二大特征值$$c_2$$**。$$c_2$$的大小越接近1，收敛越慢，越接近于0，收敛越快。\n\n而$P''$的第二大特征值取决于$\\alpha$。$\\alpha$设置的越小，收敛速度越快，但是网页之间的链接结构对最终计算结果的贡献程度也越小。考虑权衡，Google创始人Brin和Page使用$\\alpha=0.85$。\n\n#### 收敛判断\n\n幂法迭代计算直至满足一个终止条件，一个传统的终止条件是：当k轮计算后的**残差（residual）**$$x^{(k)T}P''-x^{(k)T}=x^{(k+1)T}-x^{(k)T}$$，小于一个预先定义的**容忍度（tolerance ）**$\\tau$时，迭代终止。此时，可以大致估算收敛所需要迭代计算的轮数为$\\frac{log_{10}\\tau}{log_{10}\\alpha}$。当$\\tau=10^{-6}, \\alpha=0.85$时，大致需要 $\\frac{-6}{log_{10}0.85} \\approx 85$ 次迭代计算。上面说到Brin和Page指出，通常只需要50-100次迭代运算，是指$\\tau$取值为$10^{-3}$ 到 $10^{-6}$。\n\n在实际应用中，我们通常只需要计算出页面之间的正确顺序，并不需要知道他们具体的PageRank值。所以我们只需要通过幂法迭代到PageRank向量的排序收敛就可停止。某篇论文在实验展示，在某些数据集上只需10次迭代就能产生良好的近似排序。\n\n#### 加速幂法计算\n\n（1）减少每一轮的计算时间\n\n* 自适应的PageRank，考虑到图中某些节点收敛快，而有些节点收敛慢。所以我们关注于迭代向量中元素，当某些节点已经收敛后，我们就锁定这些节点，不再对他们进行更新计算。\n\n* 图中存在大量悬挂节点，可以划分悬挂节点和非悬挂节点。因为所有悬挂节点对应的行的转移概率是一样的，可以通过一种汇集的聚合方法高效的处理。\n\n（2）减少迭代的次数\n\n* 扩展的Aitken外推法；\n\n* BlockRank；\n\n* 取消对幂法的限制，高斯-赛德尔法，雅可比法。","tags":["random walks","theoretical analysis"]},{"title":"并发图分析系统","url":"/2019/10/16/并发图分析系统/","content":"\n并发图分析任务：大量的图算法并发的运行在同一平台上对底层同一个图数据进行处理，以对该图数据进行多方位的分析处理，获得各种目的性的分析结果。\n\n### 研究工作\n\n[Yu Zhang's Research](https://www.researchgate.net/scientific-contributions/57497079_Yu_Zhang)\n\n#### CGraph\n基于关联性感知的并发图处理\n\n1. [CGraph: A Correlations-aware Approach for Efficient Concurrent Iterative Graph Processing(ATC'18)](https://www.usenix.org/conference/atc18/presentation/zhang-yu)\n2. [CGraph: A Distributed Storage and Processing System for Concurrent Iterative Graph Analysis Jobs(TOS'19)](https://dl.acm.org/citation.cfm?doid=3326597.3319406)\n\n并发图分析任务之间存在关联性。\n\n（1）空间关联性：多个并发图分析任务需要访问和处理的图数据存在大量的交集。\n\n（2）时间关联性：多个并发图分析任务可能需要同时访问同一个图划分块。\n\n但在此前的图处理系统中进行并发图分析任务时，各个任务对共享图数据的访问相互独立，互不感知。使得各个并发的图分析任务在计算时遇到内存墙（内存性能严重限制CPU）和缓存相互干扰的问题。\n\n这篇工作通过感知各个并发图分析任务之间的关联性，使得各个并发图分析任务之间能有效的共享数据和数据访问。\n\n#### DiGraph\n基于关联依赖的单任务图处理\n\n* [DiGraph: An Efficient Path-based Iterative Directed Graph Processing System on Multiple GPUs(ASPLOS'19)](https://dl.acm.org/citation.cfm?doid=3297858.3304029)\n\n* [Efficient Disk-Based Directed Graph Processing: A Strongly Connected Component Approach(TPDS 2018)](https://ieeexplore.ieee.org/document/8118091)\n\n同一个图分析任务的子任务（处理各图划分块的任务）之间也存在依赖关联性。\n\n核心图顶点状态收敛所需要的更新次数决定了整个图收敛所需迭代次数。\n\n这篇工作在单个图分析任务场景下，通过感知图中顶点之间的依赖关联性特征进行图划分，使得各个图划分块之前的依赖关联性尽量符合全序关系，尝试使得未收敛的图划分块对已经收敛的图划分块影响最小化。另外通过加速核心顶点之间的状态传递，进一步加速全局的收敛速度。\n\n#### FBSGraph\n基于路径的异步图处理\n\n* [FBSGraph: Accelerating Asynchronous Graph Processing via Forward and Backward Sweeping(TKDE'18)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8170287)","tags":["graph processing system","paper reading","concurrent graph processing"]},{"title":"ASAP(OSDI 2018) 分布式图模式挖掘系统","url":"/2019/10/15/ASAP(OSDI-2018)-分布式图模式挖掘系统/","content":"\nASAP: Fast, Approximate Graph Pattern Mining at Scale. Anand Padmanabha Iyer, Zaoxing, Xin Jin, Shivaram Venkataraman, Vladimir Braverman and Ion Stoica, OSDI 2018. [presentation](https://www.usenix.org/conference/osdi18/presentation/iyer) | [paper](https://www.cs.jhu.edu/~xinjin/files/OSDI18_ASAP.pdf)\n<!-- [PPT](https://www.usenix.org/sites/default/files/conference/protected-files/osdi18_slides_iyer.pdf) -->\n\n## 图模式挖掘研究现状\n\n### 图处理算法：\n现有图处理算法可大致分为两类：\n（1）*图分析算法*，e.g. PageRank，社区检测，标签传播。\n（2）*图模式挖掘算法*，e.g. 图形计数（motif counting），频繁子图挖掘（frequent sub-graph mining, FSM），团挖掘（clique mining）。图模式挖掘算法常应用于社交网络中的图元（graphlet）相似性检测，信用卡诈骗侦测等。\n\n现有的图处理系统大多针对图分析算法优化计算，这些系统框架在计算*图分析算法*时，速度很快，并且可以扩展到处理非常大的图数据（e.g. GraM [59] can run one iteration of page rank on a trillionedge graph in 140 seconds in a cluster.）。但是这些系统在计算*图模式挖掘算法*时却很慢，在一个中等大小的图上挖掘简单的模式都需要几个小时。\n\n### 现有图模式挖掘算法\n\n#### 精确计算\n模式挖掘算法中最常用的方法是，从最简单的图模式开始，迭代遍历图中所有可能的*嵌入组合（embeddings）*，检查所有候选的*组合嵌入*，依次修剪掉不能形成最终图模式的*组合嵌入*。\n这个*图模式挖掘算法*的复杂度很大，而且产生的*中间候选集*的大小随着图的规模呈指数增长（1M个节点的图可能就会包含$$10^{17}$$个三角形）。即使在分布式计算中，也需要很大开销来执行**join**来创建和管理这些*中间候选集*。[Arabesque(SOSP 2015)](http://delivery.acm.org/10.1145/2820000/2815410/p425-teixeira.pdf?ip=222.195.68.252&id=2815410&acc=OPENTOC&key=BF85BBA5741FDC6E%2EA4F9C023AC60E700%2E4D4702B0C3E38B35%2E9F04A3A78F7D3B8D&__acm__=1571129497_d7c2b24f90623254ad2b1c0e79d31eb2)针对这个问题，优化了分布式场景下这些*中间候选集*的存储。但是即使经过这些优化，Arabesque依然没有能力处理大规模的图，因为需要*具体化候选集*和*不断在机器间交互候选集数据*。Arabesque在一个由20个256GB内存的机器组成的分布式集群中，统计一个1B个节点的图中的*3节点图模式*，依然需要10个小时。\n\n#### 采样近似计算\n在很多模式挖掘应用中，经常并不需要精确的答案。比如FSM通常只需要输出频繁访问子图出现次数的顺序，图形计数（motif counting）也只需要输出一个指定图形出现的次数。在这些场景下，给出一个近似的答案就已足够。\n\n大数据分析场景下的近似分析已经引起一些关注，这些近似系统的基本思想是：在一小部分抽象的样本数据上执行精确的算法，并根据统计特性进行误差分析。这些系统的一个基础假设是：可以算法的准确性可以由样本的大小决定，并且计算的误差可以推导。\n\n但是，这种假设应用到*图模式挖掘算法*时并不成立。作者通过实验发现，通过减少样本的大小，计算误差和运行效率之间并没有明显的关系，而且即使样本数量设置很大，依然会有很大的计算误差，例如50%的边抽样就会带来大概80%计算误差（详细参见paper中的Figure 1）。\n\n#### 邻居采样\n\n现有的图计算理论中，已经有一些针对特定图模式的近似技术。比如要统计图中三角形的个数，可以从图中随机抽样三条边，看这三条边是否能构成一个三角形，是的话估计值就是$$m^3$$，其中m是图的总边数，否则估计值就是0，通过大量抽样就可以计算平均估计值。这种采样计数理论上确实能达到无偏估计，但是由于m在实际中是很大的，所以随机抽样三条边能构成三角形的概率很小，所以这种采样技术计算的方差非常大，想要达到比较高的近似计算的准确度，需要非常多的抽样估计，从而带来很大的计算和内存开销。\n\n[邻居采样（Neighborhood sampling, VLDB 2013）](http://www.doc88.com/p-3734516936384.html)是最近提出的一种针对*三角形计数（triangle counting）*的近似计算方案。它的基本思想是（边数据以流的形式输入）：\n\n（1）首先从全图随机采样一条边$$l_0$$，采样概率是$$Pr(l_0)=1/m$$；\n\n（2）均匀的从$$l_0$$的邻居边中采样第二条边$$l_1$$，边数据流中，$$l_1$$在$$l_0$$的后面，采样概率是$$Pr(l_1|l_0)=1/c$$，c为边数据流中出现在$$l_0$$后面的$$l_0$$的边邻居数；\n\n（3）在边数据流的$$l_1$$的后面所有边中，找到一条能与$$l_0$$和$$l_1$$构成一个三角形的边$$l_2$$，如果能找到，则这个三角形被采样到的概率是$$Pr(l_0 \\cap l_1 \\cap l_2)=1/mc$$。\n\n上述过程称为一次采样尝试，如果成功采样到一个三角形，则设这次采样计算的图中三角形的个数的估计值为$$e_i=mc$$，否则为0。多次采样，计算平均值（paper中的Figure 2展示了一个五节点完全图的例子）。\n\n#### 依然存在的挑战\n\n1.邻居采样算法只针对一种特定的图模式（三角形），需要扩展到通用的邻居采样方法，使之也能采样其他模式。\n\n2.邻居采样算法是假定图存放在单机的基础上，想要进行大规模的图模式挖掘，需要扩展到分布式图处理。\n\n3.邻居采样算法没有考虑到*属性图*，而现实生活的图模式挖掘通常是针对*属性图*，即节点和边都有类型和属性，因为通常需要*谓词匹配*。\n\n4.需要允许终端用户进行*准确性*和*延迟*之间的权衡。\n\n\n## ASAP中的近似模式挖掘\n\nASAP(A Swift Approximate Pattern-miner)是一个快速、可扩展的分布式近似图模式挖掘系统（paper中的Figure 3展示了ASAP的系统架构）。\n\n### 扩展到通用模式\nASAP推广邻居采样算法到通用的图模式，由两个阶段组成：\n\n（1）采样阶段，在有序的边流中依次采样几条边，分别统计采样概率。\n\n（2）闭合阶段，等待剩下的一条或多条边来构成一个完整的图模式，如果能成功构成，则计算采样到完整图模型的概率，进而计算估计值，否则估计值为0.\n\n对于大于三节点的图模式，有多种采样构成完整图模式的方式，采样概率取决于开发者选择的采样阶段形成的初始模式（paper中的Figure 4展示了采样4-cliques的两种方式）。\n\n#### 通用模式分析\n设$$p*$$为一个$$k$$-节点的图模式，$$p*$$的抽样概率取决于$$k$$和用邻居采样技术采样图模式的不同方式。\n\n* 当$$k=2$$, $$Pr(p=p*,k=2)=1/m$$。\n\n* 当$$k=3$$, $$Pr(p=p*,k=3)=1/m \\cdot c_1$$。\n\n* 当$$k=4$$, $$Pr(p=p*,k=4)=1/m^2$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=4)=1/m \\cdot c_1 \\cdot c_2$$(type 2)。\n\n* 当$$k=5$$, $$Pr(p=p*,k=5)=1/m^2 \\cdot c_1$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m^2 \\cdot c_2$$(type 2)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m \\cdot c_1 \\cdot c_2 \\cdot c_3$$(type 3)\n\n#### 编程接口\n\n* SampleVertex\n\n* SampleEdge\n\n* ConditionalSampleVertex\n\n* ConditionalSampleEdge(subgraph)\n\n* ConditionalClose(subgraph, subgraph)\n\n### 应用到分布式场景\n\nASAP通过2步，将上述图模式挖掘过程扩展到分布式场景：\n\n（1）**并行化采样过程**，由于采样过程中的边数据流没有排序的要求，所以ASAP随机均匀划分节点，使得各个机器上的节点数和边数都尽量均匀。计算时，在多个机器上执行估算任务的多个副本，然后聚合计算结果。\n\n（2）**结合各个机器上的输出结果，修正误差**，由于在分布式集群上计算时，机器之间的边没有办法采样到，所以会导致计算误差。ASAP通过分析误差损失，加权求和纠正误差：$$c=f(w)\\sum^{w-1}_{i=0}{c_i}$$，其中$$w$$为机器个数，$$f(w)$$为纠正权重。以*三角形计数*为例，在全图采样到的所有三角形的三个节点都在同一个机器上的概率是$$1/w^2$$，所以统计三角形个数时，$$f(w)=w^2$$。类似的，统计4-clique时，$$f(w)=w^3$$。\n\n### 属性图中的模式挖掘\n\n#### Predicate Matching\n\n现实生活的图模式挖掘通常是针对*属性图*，因为需要匹配的模式满足一些*谓词*。例如，一个*谓词查询*任务可能会要求统计图中的4-clique，其中clique中每个节点都属于某种特定的类型。ASAP支持两种谓词类型：\n\n（1）**all** ，匹配的模式中*每个*节点和边都满足某个属性。\n（2）**atleast-one**，匹配的模式中*至少有一个*节点和边都满足某个属性。\n\n#### Motif mining\n另一种查询模式是，查找某个特定节点数量的所有模式，称为* motif queries*。\n\n* 3-motif query有2种模式，链式和三角形。\n\n* 4-motif query有6种模式。\n\n其中，有几个模式会有相同的*基础构建块（underlying building block）*。针对这种情况，ASAP节省采样阶段*基础构建块*的构建。\n\n#### 精炼准确度\n有些对图数据的探索性分析场景，需要迭代地完善查询任务。针对这种场景，ASAP保留上一轮的抽样估计结果，在新一轮只需要补充差额。\n\n### 误差延迟配置\n\nASAP提供了两种用户接口，允许用户在准确性和误差之间做权衡，进行误差延迟配置（Error-Latency Profile, ELP）。\n\n* Building Estimator vs. Time Profile。用户指定一个时间预算$$T$$，ASAP返回一个时间$$T$$以内能计算出的最准确的答案，给出误差率保证$$\\epsilon$$和可配置的自信等级（默认95%）。\n\n* Building Estimator vs. Error Profile。用户指定一个误差预算$$\\epsilon$$，ASAP计算出能在最短时间内达到误差范围的答案。\n\n* ASAP也可以实现在动态图场景下快速重建ELP。\n\n\n## 实验\n\n### 实验设置\n\n#### 实现\nASAP部署在Apache Spark上，使用了GraphX中图数据流操作的实现（只使用了简单的map和reduce操作）。ASAP可以实现于任何数据流引擎。\n\n#### 数据集和对比系统\n\n* 数据集：共使用了7个数据集，最大的为UK（106M个节点，3.7B个边）。\n\n* 实验环境：16个Amazon EC2 r4.2xlarge的集群，每个机器有8个虚拟cpu和61GB内存。尽管图能放下一个机器的内存，但是产生的中间状态大大增大了计算的复杂度。\n\n* 使用的模式和指标：3-motifs（2种模式），4-motifs（6种模式），4-cliques。\n\n* 对比系统：Arabesque。\n\n### 对比实验\n\n（1）Overall Performance\n\n* Comparison with Arabesque.\n\n* Scalability on Larger Graphs.\n\n（2）Advanced Pattern Mining\n\n* Motif mining.\n\n* Predicate Matching. \n\n（3）Effectiveness of ELP Techniques\n\n* Time Profile. \n\n* Error Profile. \n\n* Error rate Confidence. \n\n* ELP Building Time. \n\n（4）Scaling ASAP on a Cluster\n\n（5）More Complex Patterns\n\n## 相关工作\n图处理系统\n\n图挖掘系统\n\n近似分析系统\n\n近似图算法\n\n<!-- ## 思考\n思考：分布式图处理系统对网络方面有什么需求?\n\n* 缓存，现有的分布式图计算系统大多数采用*迭代式的计算模型*，一轮计算结束后，机器之间交互信息，然后进行下一轮计算。这一轮传输的信息中可能与上一轮中传输的数据有重合，所以可以考虑缓存？ -->","tags":["graph processing system","graph pattern mining","paper reading"]},{"title":"IMM(SAN)工作扩展","url":"/2019/10/11/IMM-SAN-工作扩展/","content":"\n### Journal扩展点\n\n1.**从无权图扩展到加权图，** (1)加权图的应用场景，（2）在加权图上的RW需求，（3）加权图上进行一步RW转发的执行过程，（4）时间复杂度分析，（5）利用二分查找优化加权图上的RW过程以及优化后的时间复杂度。实验章节添加从无权图生成加权图的过程。\n\n2.**增加LT模型下的影响力传播,** 6.4 添加对LT模型的介绍以及在LT模型下的实验。\n\n3.**增加一组多种用户和活动类型的实验,**（1）一种用户一种活动，（2）两种用户一种活动，（3）一种用户两种活动。6.4 添加上述三种场景下的实验结果。\n\n4.**增加了三个真实世界的数据集：** Epinion, Slashdot, Youtube。","tags":["random walks","theoretical analysis","my work"]},{"title":"IMM(SAN) 引入社会活动的影响力最大化问题","url":"/2019/10/10/IMM(SAN)-引入社会活动的影响力最大化问题/","content":"\n[Pengpeng Zhao, Yongkun Li*, Hong Xie, Zhiyong Wu, Yinlong Xu, John C. S. Lui. \"Measuring and Maximizing Influence via Random Walk in Social Activity Networks.\"The 22nd International Conference on Database Systems for Advanced Applications (DASFAA 2017), Suzhou, China, March 2017.](https://link.springer.com/content/pdf/10.1007%2F978-3-319-55699-4_20.pdf).\n\n<!-- ## IMM(SAN) Journal扩展 -- TKDE -->\n\n### 论文大纲\n\n1.**用户活动网络图（SAN），**考虑在线社交网络图（OSN）中用户社交活动的影响，比如对同一个产品的点赞、评论等，基于此提出用户活动网络图（SAN），并提出一种“超图”的概念来表示SAN， 其中一条t型的“超边”连接多个用户，代表这几个用户都参与某种t型活动，比如都对某产品点赞或评高分。\n\n2.**基于RW的影响力中心性，**考虑SAN场景下的影响力最大化问题（IMP(SAN)），采用基于Random Walk的方式来近似估算SAN中大小为k的种子节点集S的影响力，定义为影响力中心性（influence centrality），估算在超图中从每个节点出发进行大量random walks，其中能到达种子节点集S的击中概率（decayed hitting probability）。\n\n3.**贪心算法计算IMP(SAN)，**为计算SAN中的影响力最大化问题（IMP(SAN)），本文采用Monte Carlo框架来估算SAN中的影响力中心性，并提出一种贪心的迭代算法，每一轮选出一个能够带来最大影响力增量的节点，加入到种子节点集S中，具体实现：每一轮，计算每个节点u能够带来的影响力增量，在超图中每个节点出发进行R条L步的random walks，计算这些walks能够访问到$$S\\cup{u}$$的hitting probability。时间复杂度为$$\\omicron(kn^2RL)$$。\n\n4.**算法优化1——并行计算，**每一轮，计算图中每个节点的影响力增量都需要从全图每个节点出发R条L步的random walks，其实这些walk可以共用，即一次性从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，这样可以将时间复杂度优化到$$\\omicron(knRL)$$。\n\n5.**算法优化2——walk复用，**每一轮都需要从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，其实第一轮轮的walk信息可以一直被复用到下一轮中，这样可以将时间复杂度优化到$$\\omicron(nRL)$$，这其中会带来walk更新的问题，详细参加paper 5.2。\n\n6.**实验对比，**本文在三个真实世界的数据集上对比了加入用户活动后带来的在独立级联模型（independent cascade model，IC）的影响力传播模型下影响力的增长，以及对比最新的OSN上的影响力最大化问题的最新算法IMM在不同用户活动权重和不同种子节点集大小的配置下效率的改进和能带来的影响力传播。\n\n\n\n","tags":["random walks","theoretical analysis"]},{"title":"Hexo的配置和使用","url":"/2019/10/10/Hexo的配置和使用/","content":"\n博客搭建，GitHub Page和Hexo的使用\n\nhttps://www.cnblogs.com/ryanleee/p/8274314.html\n\nHexo 和 Markdown 的基本使用规则\n\nhttps://www.jianshu.com/p/56d99a3049a5\n\n在HEXO主题中添加数学公式支持\n\nhttps://www.cnblogs.com/zhyantao/p/10424874.html\n\nMarkDown公式查阅\n\nhttps://blog.csdn.net/EchoWenyu/article/details/95046618\n\nGitment：使用 GitHub Issues 搭建评论系统\n\nhttps://imsun.net/posts/gitment-introduction/\n\n解决gitment无法登录的问题\n\nhttps://cloud.tencent.com/developer/news/316368","tags":["hexo"]},{"title":"Hexo部署错误","url":"/2019/10/09/Hexo部署错误/","content":"\n## Hexo部署错误\n\n生成和本地测试都能通过\n\n``` bash\n$ hexo g\n$ hexo s\n```\n\n但是部署时出错\n\n``` bash\n$ hexo d\n```\n\n错误提示如下：\n\n>...\n>\n>Connection reset by 13.250.177.223 port 22\n>\n>fatal: Could not read from remote repository. &emsp;\n>\n>Please make sure you have the correct access rights and the repository exists.\n>\n>FATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\n>\n>Error: Spawn failed\n>\n>...\n\n搜索相关信息发现应该是GitHub中SSH没有连接上，测试ssh连接GitHub\n\n``` bash\n$ ssh -T git@github.com\n```\n\n连接不成功：\n\n>Connection reset by 13.229.188.59 port 22\n\n## 尝试过的方法\n\n*新建SSH KEY*\n\n*设置防火墙*\n\n都还是不行。\n\n## 最终解决方案\n\n**校园网网络通端口号切换到1号口**","tags":["hexo","github","ssh"]},{"title":"Hello World","url":"/2019/10/09/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"},{"title":"远程桌面连接","url":"/2019/09/09/远程桌面连接/","content":"\n目标：在本地电脑A通过远程桌面连接控制远程电脑B。\n\n（1）[开启远程电脑B的远程连接](https://jingyan.baidu.com/article/6f2f55a171c4fdb5b93e6c38.html)，这个经验里的第四步的添加用户可不加。\n\n（2）查看远程电脑B的内部IP地址：打开远程电脑B的windows cmd，**ipconfig**命令查看自己的ip地址，一般是192.168.x.x。\n\n（3）在远程电脑B设置外部端口：打开路由器admin，在里面找“虚拟服务器”或者“端口转发”，添加映射关系，内部端口3389，外部端口设置自己喜欢的，内部ip地址就是第二步查出来的。\n\n（4）查看远程电脑B的外部IP地址：打开网络通，找到找到WAN网ip地址，就是主页上显示的那个，一般是222或104等开头。\n\n（5）[在远程电脑B设置静态IP](https://jingyan.baidu.com/article/7f766dafeabc204101e1d0b8.html)，是指第二步查看到的IP，否则下次重启有可能IP地址就变了。\n\n（6）在本地电脑A进行远程连接：打开远程桌面连接，输入**WAN IP:外部端口**，然后输入用户名密码即可登录。\n"},{"title":"Youth","url":"/2019/08/04/Youth/","content":"\n*源于百词斩的一篇阅读分享*\n\nYouth is not a time of life; it is a state of mind;\n\nit is not a matter of rosy cheeks, red lips, and supple knees;\n\nit is a matter of the will, a quality of the imagination, a vigor of the emotions; \n\nit is the freshness of the deep springs of life. \n\nYouth mean a temperamental predominace of courage over timidiity, of the appetite for adventure over the love of ease.\n\nThis often exsits in a man of sixty more than a boy of twenty.\n\nNobody grows old merely by a number of years, \n\nWe grow old by deserting our ideas.\n\nYears may wrinkle the skin, but to give up the enthusiasm wrinkles the soul.\n\nWorry, fear, self-distrust bows the heart and turns the spirit back to dust.\n\nWhether sixty or sixteen, there is in every human being's heart the lure of wonders, the unfailing child-lke appetite of what's next, and the joy of game of living.\n\nIn the center of your heart and my heart, there is a wrieless station;\n\nso long as it receieves the messages of beauty, hope, courage and power from man and from the Infinite, so long as you are young,\n\nWhen the aerials are down, and your spirit is covered with snows of cynicism and ice of pessimism, then you've grown old, even at twenty. but as long as your aerials are up, to catch the waves of optimism, there is hope you may die young at eighty."},{"title":"matlab程序脱离matlab环境运行","url":"/2019/07/01/matlab程序脱离matlab环境运行/","content":"\n我的需求来源于：\n\n* 想用Graph500的图生成器，生成两个大规模的图数据集。在官方github源码中发现了.m文件，测试发现可在matlab中运行生成图数据集。\n\n* 但是，由于我的PC内存容量有限（8GB），最多生成（28，1）的生成图（4GB），即节点数为2^28，边数比节点数为1的子图。\n\n* 我的需求是分别生成一个（30，32）-- 128GB 和（31，128）-- 1TB的生成图，至少需要能够生成（31，1）的子图，然后拼起来，即32GB，内存需求最少为64GB。\n\n* 所以，可以将kronecker_generator.m转成exe可执行文件直接放到64GB服务器上去执行，免去在服务器上装matlab。\n\n\n### 在有matlab的电脑生成.exe可执行文件\n\n1. 生成kronecker_generator.exe文件\n``` bash\nmcc -m kronecker_generator.m\n```\n\n2. 测试：打开cmd命令行，进入kronecker_generator.exe所在目录，运行\n``` bash\nkronecker_generator.exe\n```\n\n3. 带参数运行\n（1）首先在kronecker_generator.exe中添加代码\n\n***\n    function ij = kronecker_generator (SCALE, edgefactor)\n    if (ischar(SCALE))\n        SCALE = str2num(SCALE);\n    end\n    if (ischar(edgefactor))\n        edgefactor = str2num(edgefactor);\n    end\n***\n（2）cmd中测试运行\n``` bash\nkronecker_generator.exe 10 16\n```\n\n### 在另一台电脑上运行\n\n传输可执行文件到目标电脑后执行\n``` bash\nscp -P 5922 kronecker_generator.exe wang@210.45.114.192:/home/wang/code/\nkronecker_generator.exe 10 16\n```\n\n此方法只能用于另一个Windows系统下脱离MATLAB环境运行，Linux中不能直接运行.exe。\n\n要考虑在Linux环境下脱离MATLAB环境运行，需要尝试其他方法，比如将m文件转化为c/c++语言文件，但是还没尝试过。\n\n### 参考\n[matlab程序脱离matlab环境运行-mcc、mbuild和mex命令详解](http://blog.sciencenet.cn/blog-419879-508169.html)","tags":["matlab"]},{"title":"DrunkardMob的编译运行","url":"/2019/06/19/DrunkardMob的编译运行/","content":"\nDrunkardMob部署于Java版本的GraphChi，因为对Java的使用不是很熟练，简单的Java版本的GraphChi的编译和运行折腾了一个多周。这里记录一下编译运行的过程以及其他遇到的问题\n\n#### 安装jdk和mvn\n\n其实简单的apt-get install就可以了\n``` bash\nsudo apt-get install openjdk-8-jdk\nsudo apt-get install maven\n```\n\n所谓后来编译出现的各种问题，就是这里没有装好，我一开始是按照网上一些配置Java运行环境的博客做的，然后配置JAVA_HOME之类的，编译就报各种错，尝试安装了各种版本，还是会有各种奇特的错误。其实这里通过apt-get安装默认是可以不用配置JAVA_HOME环境的。\n\n\n我是先安装的mvn，会自动安装一个jdk，用 java -version看也确实是安装了Java8，但是并没有安装javac，所以编译的时候会找不到编译的包。所以还是需要另外去安装一个jdk。\n\n#### scala版本冲突问题\n\n“class ... is broken”\n\n这里其实是因为作者的pom.xml文件中指定的Scala版本是2.9.0-1， 而实际编译运行需要的Scala的版本是2.11.2.\n\n所以解决办法是：将相应依赖项中scala-lang的版本号改为 2.11.2\n\n***\n    <dependency>\n        <groupId>org.scala-lang</groupId>\n        <artifactId>scala-library</artifactId>\n        <version>2.11.2</version>\n    </dependency>\n***\n\n我上周在这个问题的时候走了很多弯路，看到网上有博客说这个报错是因为需要安装比较老的jdk版本，所以也尝试安装了jdk7和jdk6，mvn的版本也按照作者给的版本重新安装了，总之瞎折腾了很久。\n\n#### 运行找不到类\n\n这个实际上是个很坑的问题，因为后来版本有改进，应该将命令中graphchi-java-0.2-jar-with-dependencies换成graphchi-java-0.2.2-jar-with-dependencies\n\n到这里，不出意外的话，程序应该是可以正常编译，运行起来了，因为最后在403的ccc服务器上，到这里就运行成功了\n\n#### common-math版本冲突\npom.xml中关于common-math有重复定义，可以注释掉其中一个。\n\n#### jdk版本配置\n\n作者用的是jdk1.6，我这边安装的jdk1.8，这里pom.xml文件中maven-compiler-plugin下的configuration中的*source* 和 *target* 应该改为1.8.\n\n\n#### TEST时找不到surefire\n\n解决办法是追加plugin（version要根据报错信息调整，这里应该是2.12.4）\n***\n    <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-surefire-plugin</artifactId>\n        <version>2.12.4</version>\n        <configuration>\n            <useSystemClassLoader>false</useSystemClassLoader>\n        </configuration>\n    </plugin>\n***\n\n#### 在线依赖项\n\n之后遇到的问题是发现修改后的源码，编译后无效，即不能运行编译后的结果。\n又是折腾了两天，发现是因为添加了在线依赖项的原因。。。\n\n即作者的说明文档中，说是要加入的依赖项：\n***\n    For maven, include the following in <dependencies>:\n    <dependency>\n        <groupId>org.graphchi</groupId>\n        <artifactId>graphchi-java_2.11</artifactId>\n        <version>0.2.2</version>\n    </dependency>\n***\n其实是编译好的graphchi-java的库包，被放在的maven的仓库中，添加依赖项就会直接引用在线的库包，从而覆盖了本地的编译的结果。删除掉这项依赖项，可以正常修改然后编译运行了。\n\n#### 版本冲突\n系统不知道什么时候升级了openjdk，导致与pom.xml中声明的版本冲突！\n查看版本：\n``` bash\njava -version\nmvn -version\n```\n\n解决，卸载重装：\n``` bash\nsudo apt-get autoremove openjdk*  //autoremove会卸载所有相关依赖项，慎重使用！！！！\nsudo apt-get autoremove java*\nsudo apt-get install openjdk-8-jdk\n```\n","tags":["Java"]},{"title":"Wukong 基于RDMA的快速并发RDF查询","url":"/2019/02/25/Wukong-基于RDMA的快速并发RDF查询/","content":"\n[Wukong:Fast and Concurrent RDF Queries with RDMA-based Distributed Graph Exploration, JIAXIN SHI, YOUYANG YAO, RONG CHEN, HAIBO CHEN, OSDI16](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/shi)\n\n[可参考博客](https://blog.csdn.net/qq_21125183/article/details/80670024)\n\n### 背景介绍\n\n#### 在线图查询\nOnline graph query plays a vital role for searching, mining and reasoning linked data.\n\n#### RDF and SPARQL\nRDF :  Resource Description Framework 资源描述框架。用于表示网络上链接的数据，例如知识图谱。\n\nRDF is a graph composed by a set of ⟨Subject, Predicate, Object⟩ triples 由<主谓宾>三元组组成的图。\n\nSPARQL ： 针对RDF的标准查询语言。\n\n### 现有查询方法\n\n1、关系型数据库管理（RDBMS）\n\n三元组存储和三元组联接，联接三张表，查询得出结果。\n\n缺点 ：分布式联接开销大 & 会产生大量的中间结果。\n\n2、图处理系统\n\n图存储和图检索，将RDF数据存储为一个图的形式，一步步检索出满足条件的节点关系，最后联接所有查询结果，得出最终结果。\n\n缺点 ：最后联接部分开销非常大 & 查询节点关系需同步执行，比较慢。\n\n## 基于图的RDF数据模型\n\n1. Graph model and indexes\n\n新增协助索引节点（index vertices）：predicate index & type index\n\n原来的节点（normal vertices）：subjects& objects\n\nindex vertices与normal vertices一起参与划分子图和存储\n\n2. Differentiated Graph Partitioning\n受 PowerLyra[ EuroSys15] 启发\n\n1）高度节点 ： 拆分成多个节点，分别存放于不同机器；\n\n2）低度节点 ： 分部存储到不同机器\n\nwukong：\n\n1）index vertices : 拆分；\n\n2）normal vertices ： 分布；\n\n3）在RDF场景下，高度节点的不均匀，并不会很大的影响负载均衡。\n\n3. RDMA-friendly Predicate-based KV store\n\nkey :  \"vid, p/tid, d\"\n\nvalue : the list of neighboring vertex IDs or predicate/type IDs\n\n减少大量计算和网络开销\n\n## wukong查询过程\n\n1. Basic Query Processing\n\n2. Full-history Pruning\n\n3. Migrating Execution or Data\n\n4. Concurrent Query Processing\n","tags":["graph processing system","RDF query","KV graph storage"]}]