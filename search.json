[{"title":"ASAP(OSDI 2018) 分布式图模式挖掘系统","url":"/2019/10/15/ASAP(OSDI-2018)-分布式图模式挖掘系统/","content":"\nASAP: Fast, Approximate Graph Pattern Mining at Scale. Anand Padmanabha Iyer, Zaoxing, Xin Jin, Shivaram Venkataraman, Vladimir Braverman and Ion Stoica, OSDI 2018. [presentation](https://www.usenix.org/conference/osdi18/presentation/iyer) [paper](https://www.cs.jhu.edu/~xinjin/files/OSDI18_ASAP.pdf)\n<!-- [PPT](https://www.usenix.org/sites/default/files/conference/protected-files/osdi18_slides_iyer.pdf) -->\n\n## 图模式挖掘研究现状\n\n### 图处理算法：\n现有图处理算法可大致分为两类：\n（1）*图分析算法*，e.g. PageRank，社区检测，标签传播。\n（2）*图模式挖掘算法*，e.g. 图形计数（motif counting），频繁子图挖掘（frequent sub-graph mining, FSM），团挖掘（clique mining）。图模式挖掘算法常应用于社交网络中的图元（graphlet）相似性检测，信用卡诈骗侦测等。\n\n现有的图处理系统大多针对图分析算法优化计算，这些系统框架在计算*图分析算法*时，速度很快，并且可以扩展到处理非常大的图数据（e.g. GraM [59] can run one iteration of page rank on a trillionedge graph in 140 seconds in a cluster.）。但是这些系统在计算*图模式挖掘算法*时却很慢，在一个中等大小的图上挖掘简单的模式都需要几个小时。\n\n### 现有图模式挖掘算法\n\n#### 精确计算\n模式挖掘算法中最常用的方法是，从最简单的图模式开始，迭代遍历图中所有可能的*嵌入组合（embeddings）*，检查所有候选的*组合嵌入*，依次修剪掉不能形成最终图模式的*组合嵌入*。\n这个*图模式挖掘算法*的复杂度很大，而且产生的*中间候选集*的大小随着图的规模呈指数增长（1M个节点的图可能就会包含$$10^{17}$$个三角形）。即使在分布式计算中，也需要很大开销来执行**join**来创建和管理这些*中间候选集*。[Arabesque(SOSP 2015)](http://delivery.acm.org/10.1145/2820000/2815410/p425-teixeira.pdf?ip=222.195.68.252&id=2815410&acc=OPENTOC&key=BF85BBA5741FDC6E%2EA4F9C023AC60E700%2E4D4702B0C3E38B35%2E9F04A3A78F7D3B8D&__acm__=1571129497_d7c2b24f90623254ad2b1c0e79d31eb2)针对这个问题，优化了分布式场景下这些*中间候选集*的存储。但是即使经过这些优化，Arabesque依然没有能力处理大规模的图，因为需要*具体化候选集*和*不断在机器间交互候选集数据*。Arabesque在一个由20个256GB内存的机器组成的分布式集群中，统计一个1B个节点的图中的*3节点图模式*，依然需要10个小时。\n\n#### 采样近似计算\n在很多模式挖掘应用中，经常并不需要精确的答案。比如FSM通常只需要输出频繁访问子图出现次数的顺序，图形计数（motif counting）也只需要输出一个指定图形出现的次数。在这些场景下，给出一个近似的答案就已足够。\n\n大数据分析场景下的近似分析已经引起一些关注，这些近似系统的基本思想是：在一小部分抽象的样本数据上执行精确的算法，并根据统计特性进行误差分析。这些系统的一个基础假设是：可以算法的准确性可以由样本的大小决定，并且计算的误差可以推导。\n\n但是，这种假设应用到*图模式挖掘算法*时并不成立。作者通过实验发现，通过减少样本的大小，计算误差和运行效率之间并没有明显的关系，而且即使样本数量设置很大，依然会有很大的计算误差，例如50%的边抽样就会带来大概80%计算误差（详细参见paper中的Figure 1）。\n\n#### 邻居采样\n\n现有的图计算理论中，已经有一些针对特定图模式的近似技术。比如要统计图中三角形的个数，可以从图中随机抽样三条边，看这三条边是否能构成一个三角形，是的话估计值就是$$m^3$$，其中m是图的总边数，否则估计值就是0，通过大量抽样就可以计算平均估计值。这种采样计数理论上确实能达到无偏估计，但是由于m在实际中是很大的，所以随机抽样三条边能构成三角形的概率很小，所以这种采样技术计算的方差非常大，想要达到比较高的近似计算的准确度，需要非常多的抽样估计，从而带来很大的计算和内存开销。\n\n[邻居采样（Neighborhood sampling, VLDB 2013）](http://www.doc88.com/p-3734516936384.html)是最近提出的一种针对*三角形计数（triangle counting）*的近似计算方案。它的基本思想是（边数据以流的形式输入）：\n\n（1）首先从全图随机采样一条边$$l_0$$，采样概率是$$Pr(l_0)=1/m$$；\n\n（2）均匀的从$$l_0$$的邻居边中采样第二条边$$l_1$$，边数据流中，$$l_1$$在$$l_0$$的后面，采样概率是$$Pr(l_1|l_0)=1/c$$，c为边数据流中出现在$$l_0$$后面的$$l_0$$的边邻居数；\n\n（3）在边数据流的$$l_1$$的后面所有边中，找到一条能与$$l_0$$和$$l_1$$构成一个三角形的边$$l_2$$，如果能找到，则这个三角形被采样到的概率是$$Pr(l_0 \\cap l_1 \\cap l_2)=1/mc$$。\n\n上述过程称为一次采样尝试，如果成功采样到一个三角形，则设这次采样计算的图中三角形的个数的估计值为$$e_i=mc$$，否则为0。多次采样，计算平均值（paper中的Figure 2展示了一个五节点完全图的例子）。\n\n#### 依然存在的挑战\n\n1.邻居采样算法只针对一种特定的图模式（三角形），需要扩展到通用的邻居采样方法，使之也能采样其他模式。\n\n2.邻居采样算法是假定图存放在单机的基础上，想要进行大规模的图模式挖掘，需要扩展到分布式图处理。\n\n3.邻居采样算法没有考虑到*属性图*，而现实生活的图模式挖掘通常是针对*属性图*，即节点和边都有类型和属性，因为通常需要*谓词匹配*。\n\n4.需要允许终端用户进行*准确性*和*延迟*之间的权衡。\n\n\n## ASAP中的近似模式挖掘\n\nASAP(A Swift Approximate Pattern-miner)是一个快速、可扩展的分布式近似图模式挖掘系统（paper中的Figure 3展示了ASAP的系统架构）。\n\n### 扩展到通用模式\nASAP推广邻居采样算法到通用的图模式，由两个阶段组成：\n\n（1）采样阶段，在有序的边流中依次采样几条边，分别统计采样概率。\n\n（2）闭合阶段，等待剩下的一条或多条边来构成一个完整的图模式，如果能成功构成，则计算采样到完整图模型的概率，进而计算估计值，否则估计值为0.\n\n对于大于三节点的图模式，有多种采样构成完整图模式的方式，采样概率取决于开发者选择的采样阶段形成的初始模式（paper中的Figure 4展示了采样4-cliques的两种方式）。\n\n#### 通用模式分析\n设$$p*$$为一个$$k$$-节点的图模式，$$p*$$的抽样概率取决于$$k$$和用邻居采样技术采样图模式的不同方式。\n\n* 当$$k=2$$, $$Pr(p=p*,k=2)=1/m$$。\n\n* 当$$k=3$$, $$Pr(p=p*,k=3)=1/m \\cdot c_1$$。\n\n* 当$$k=4$$, $$Pr(p=p*,k=4)=1/m^2$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=4)=1/m \\cdot c_1 \\cdot c_2$$(type 2)。\n\n* 当$$k=5$$, $$Pr(p=p*,k=5)=1/m^2 \\cdot c_1$$(type 1)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m^2 \\cdot c_2$$(type 2)\n$$\\quad \\quad \\quad$$ or $$\\quad Pr(p=p*,k=5)=1/m \\cdot c_1 \\cdot c_2 \\cdot c_3$$(type 3)\n\n#### 编程接口\n\n* SampleVertex\n\n* SampleEdge\n\n* ConditionalSampleVertex\n\n* ConditionalSampleEdge(subgraph)\n\n* ConditionalClose(subgraph, subgraph)\n\n### 应用到分布式场景\n\nASAP通过2步，将上述图模式挖掘过程扩展到分布式场景：\n\n（1）**并行化采样过程**，由于采样过程中的边数据流没有排序的要求，所以ASAP随机均匀划分节点，使得各个机器上的节点数和边数都尽量均匀。计算时，在多个机器上执行估算任务的多个副本，然后聚合计算结果。\n\n（2）**结合各个机器上的输出结果，修正误差**，由于在分布式集群上计算时，机器之间的边没有办法采样到，所以会导致计算误差。ASAP通过分析误差损失，加权求和纠正误差：$$c=f(w)\\sum^{w-1}_{i=0}{c_i}$$，其中$$w$$为机器个数，$$f(w)$$为纠正权重。以*三角形计数*为例，在全图采样到的所有三角形的三个节点都在同一个机器上的概率是$$1/w^2$$，所以统计三角形个数时，$$f(w)=w^2$$。类似的，统计4-clique时，$$f(w)=w^3$$。\n\n### 属性图中的模式挖掘\n\n#### Predicate Matching\n\n现实生活的图模式挖掘通常是针对*属性图*，因为需要匹配的模式满足一些*谓词*。例如，一个*谓词查询*任务可能会要求统计图中的4-clique，其中clique中每个节点都属于某种特定的类型。ASAP支持两种谓词类型：\n\n（1）**all** ，匹配的模式中*每个*节点和边都满足某个属性。\n（2）**atleast-one**，匹配的模式中*至少有一个*节点和边都满足某个属性。\n\n#### Motif mining\n另一种查询模式是，查找某个特定节点数量的所有模式，称为* motif queries*。\n\n* 3-motif query有2种模式，链式和三角形。\n\n* 4-motif query有6种模式。\n\n其中，有几个模式会有相同的*基础构建块（underlying building block）*。针对这种情况，ASAP节省采样阶段*基础构建块*的构建。\n\n#### 精炼准确度\n有些对图数据的探索性分析场景，需要迭代地完善查询任务。针对这种场景，ASAP保留上一轮的抽样估计结果，在新一轮只需要补充差额。\n\n### 误差延迟配置\n\nASAP提供了两种用户接口，允许用户在准确性和误差之间做权衡，进行误差延迟配置（Error-Latency Profile, ELP）。\n\n* Building Estimator vs. Time Profile。用户指定一个时间预算$$T$$，ASAP返回一个时间$$T$$以内能计算出的最准确的答案，给出误差率保证$$\\epsilon$$和可配置的自信等级（默认95%）。\n\n* Building Estimator vs. Error Profile。用户指定一个误差预算$$\\epsilon$$，ASAP计算出能在最短时间内达到误差范围的答案。\n\n* ASAP也可以实现在动态图场景下快速重建ELP。\n\n\n## 实验\n\n### 实验设置\n\n#### 实现\nASAP部署在Apache Spark上，使用了GraphX中图数据流操作的实现（只使用了简单的map和reduce操作）。ASAP可以实现于任何数据流引擎。\n\n#### 数据集和对比系统\n\n* 数据集：共使用了7个数据集，最大的为UK（106M个节点，3.7B个边）。\n\n* 实验环境：16个Amazon EC2 r4.2xlarge的集群，每个机器有8个虚拟cpu和61GB内存。尽管图能放下一个机器的内存，但是产生的中间状态大大增大了计算的复杂度。\n\n* 使用的模式和指标：3-motifs（2种模式），4-motifs（6种模式），4-cliques。\n\n* 对比系统：Arabesque。\n\n### 对比实验\n\n（1）Overall Performance\n\n* Comparison with Arabesque.\n\n* Scalability on Larger Graphs.\n\n（2）Advanced Pattern Mining\n\n* Motif mining.\n\n* Predicate Matching. \n\n（3）Effectiveness of ELP Techniques\n\n* Time Profile. \n\n* Error Profile. \n\n* Error rate Confidence. \n\n* ELP Building Time. \n\n（4）Scaling ASAP on a Cluster\n\n（5）More Complex Patterns\n\n## 相关工作\n图处理系统\n\n图挖掘系统\n\n近似分析系统\n\n近似图算法\n\n<!-- ## 思考\n思考：分布式图处理系统对网络方面有什么需求?\n\n* 缓存，现有的分布式图计算系统大多数采用*迭代式的计算模型*，一轮计算结束后，机器之间交互信息，然后进行下一轮计算。这一轮传输的信息中可能与上一轮中传输的数据有重合，所以可以考虑缓存？ -->","tags":["distribute graph processing system","graph pattern mining"]},{"title":"Markov chain","url":"/2019/10/14/Markov-chain/","content":"\n本文针对非数学专业出生的，对理论分析不熟悉的同学，从通俗的角度及图的立场解释马尔科夫过程和它的稳态分布。\n\n### 马尔科夫链\n\n### 马尔科夫链能收敛得到稳态分布的必要条件\n\n#### 随机性\n\n#### 不可约性\n\n其实我们从不可约的英文单词irreducible的本意就可以知道他的含义，irreducible=ir+reducible=不+可减少的=不可减少的，不可简化的。\n而不可约的数学定义是“如果从C 中任一状态出发经有限步转移到另一状态的概率都大于0,则称C为不可约闭集”，即如果全部状态转移概率均大于0，表示任意一种状态都可能转化到任意另外一种状态，即不存在多余的状态（可减少的状态），是的其它状态不能转换到此状态。如果存在这样的状态，它的一步转移概率应当为0.\n\n### 稳态分布","tags":["random walks"]},{"title":"CNARW Journal扩展","url":"/2019/10/14/CNARW-Journal扩展/"},{"title":"Hexo的配置和使用","url":"/2019/10/10/Hexo的配置和使用/","content":"\n博客搭建，GitHub Page和Hexo的使用\n\nhttps://www.cnblogs.com/ryanleee/p/8274314.html\n\nHexo 和 Markdown 的基本使用规则\n\nhttps://www.jianshu.com/p/56d99a3049a5\n\n在HEXO主题中添加数学公式支持\n\nhttps://www.cnblogs.com/zhyantao/p/10424874.html\n\nMarkDown公式查阅\n\nhttps://blog.csdn.net/EchoWenyu/article/details/95046618\n\nGitment：使用 GitHub Issues 搭建评论系统\n\nhttps://imsun.net/posts/gitment-introduction/\n\n解决gitment无法登录的问题\n\nhttps://cloud.tencent.com/developer/news/316368","tags":["hexo"]},{"title":"IMM(SAN) Journal扩展 -- TKDE","url":"/2019/10/10/IMM-SAN-Journal扩展-TKDE/","content":"\n这篇工作开始发表于[DASFAA 2017](https://link.springer.com/content/pdf/10.1007%2F978-3-319-55699-4_20.pdf).\n\n* Pengpeng Zhao, Yongkun Li*, Hong Xie, Zhiyong Wu, Yinlong Xu, John C. S. Lui. \"Measuring and Maximizing Influence via Random Walk in Social Activity Networks.\"The 22nd International Conference on Database Systems for Advanced Applications (DASFAA 2017), Suzhou, China, March 2017.\n\n## IMM(SAN) Journal扩展 -- TKDE\n\n### 会议版本论文大纲\n\n1.**用户活动网络图（SAN），**考虑在线社交网络图（OSN）中用户社交活动的影响，比如对同一个产品的点赞、评论等，基于此提出用户活动网络图（SAN），并提出一种“超图”的概念来表示SAN， 其中一条t型的“超边”连接多个用户，代表这几个用户都参与某种t型活动，比如都对某产品点赞或评高分。\n\n2.**基于RW的影响力中心性，**考虑SAN场景下的影响力最大化问题（IMP(SAN)），采用基于Random Walk的方式来近似估算SAN中大小为k的种子节点集S的影响力，定义为影响力中心性（influence centrality），估算在超图中从每个节点出发进行大量random walks，其中能到达种子节点集S的击中概率（decayed hitting probability）。\n\n3.**贪心算法计算IMP(SAN)，**为计算SAN中的影响力最大化问题（IMP(SAN)），本文采用Monte Carlo框架来估算SAN中的影响力中心性，并提出一种贪心的迭代算法，每一轮选出一个能够带来最大影响力增量的节点，加入到种子节点集S中，具体实现：每一轮，计算每个节点u能够带来的影响力增量，在超图中每个节点出发进行R条L步的random walks，计算这些walks能够访问到$$S\\cup{u}$$的hitting probability。时间复杂度为$$\\omicron(kn^2RL)$$。\n\n4.**算法优化1——并行计算，**每一轮，计算图中每个节点的影响力增量都需要从全图每个节点出发R条L步的random walks，其实这些walk可以共用，即一次性从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，这样可以将时间复杂度优化到$$\\omicron(knRL)$$。\n\n5.**算法优化2——walk复用，**每一轮都需要从全图每个节点出发R条L步的random walks，同时计算图中每个节点带来的影响力增量，其实第一轮轮的walk信息可以一直被复用到下一轮中，这样可以将时间复杂度优化到$$\\omicron(nRL)$$，这其中会带来walk更新的问题，详细参加paper 5.2。\n\n6.**实验对比，**本文在三个真实世界的数据集上对比了加入用户活动后带来的在独立级联模型（independent cascade model，IC）的影响力传播模型下影响力的增长，以及对比最新的OSN上的影响力最大化问题的最新算法IMM在不同用户活动权重和不同种子节点集大小的配置下效率的改进和能带来的影响力传播。\n\n\n<!-- ### Journal扩展点\n\n1.**从无权图扩展到加权图，** (1)加权图的应用场景，（2）在加权图上的RW需求，（3）加权图上进行一步RW转发的执行过程，（4）时间复杂度分析，（5）利用二分查找优化加权图上的RW过程以及优化后的时间复杂度。实验章节添加从无权图生成加权图的过程。\n\n2.**增加LT模型下的影响力传播,** 6.4 添加对LT模型的介绍以及在LT模型下的实验。\n\n3.**增加一组多种用户和活动类型的实验,**（1）一种用户一种活动，（2）两种用户一种活动，（3）一种用户两种活动。6.4 添加上述三种场景下的实验结果。 -->\n"},{"title":"Hexo部署错误","url":"/2019/10/09/Hexo部署错误/","content":"\n## Hexo部署错误\n\n生成和本地测试都能通过\n\n``` bash\n$ hexo g\n$ hexo s\n```\n\n但是部署时出错\n\n``` bash\n$ hexo d\n```\n\n错误提示如下：\n\n>...\n>\n>Connection reset by 13.250.177.223 port 22\n>\n>fatal: Could not read from remote repository. &emsp;\n>\n>Please make sure you have the correct access rights and the repository exists.\n>\n>FATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\n>\n>Error: Spawn failed\n>\n>...\n\n搜索相关信息发现应该是GitHub中SSH没有连接上，测试ssh连接GitHub\n\n``` bash\n$ ssh -T git@github.com\n```\n\n连接不成功：\n\n>Connection reset by 13.229.188.59 port 22\n\n## 尝试过的方法\n\n*新建SSH KEY*\n\n*设置防火墙*\n\n都还是不行。\n\n## 最终解决方案\n\n**校园网网络通端口号切换到1号口**","tags":["hexo","github","ssh"]},{"title":"Test Blog","url":"/2019/10/08/test-blog/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### 测试中文\n\n中文测试","tags":["testTag"]},{"title":"Hello World","url":"/2019/10/08/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"}]